{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "\n",
    "# Note: I do this so that I can import files across folders\n",
    "# See this discussion: https://stackoverflow.com/questions/75990606/automatically-add-project-to-sys-path-in-vs-code-like-pycharm-spyder-do\n",
    "sys.path.insert(1, '/Users/ryanstevens/Documents/github/torch_practice')     \n",
    "sys.path.insert(0, '/Users/ryanstevens/Documents/github/torch_practice')     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# Autoencoders Tutorial\n",
       "\n",
       "At work, we've been starting to explore different approaches to anomaly detection. I'm creating a series of posts to clarify my understanding of autoencoders. A lot of this material will be fairly basic for many readers, but I want to start with the basics and build up. \n",
       "\n",
       "## Why do we need autoencoders? \n",
       "\n",
       "The key idea is lossless compression. Below shows the process of compressing and uncompressing a set of data points from $\\mathbb{R}^{2} \\to \\mathbb{R}^{1}$ and back to $\\mathbb{R}^{1} \\to \\mathbb{R}^{2}$. In the example, we have three sets of data points:\n",
       "* Input: $\\bold{x} \\in \\mathbb{R}^{2}$\n",
       "* Compressed by map $g_{\\theta_{z}}$: $\\bold{z} \\in \\mathbb{R}^{1}$\n",
       "* Reconstructed by map $f_{\\theta_{x}}$: $\\bold{\\tilde{x}} \\in \\mathbb{R}^{2}$\n",
       "\n",
       "\n",
       "Above we have a graphical representation of transformations. To arrive at these transformations, we can define any mappings we desire. An example could be a neural network, that has this structure:\n",
       "\n",
       "The goal of autoencoders is to find the mappings to minimize reconstruction loss. Formally, we try to solve the following problem:\n",
       "\n",
       "$$\n",
       "\\begin{aligned}\n",
       "\\min_{(\\theta_{x}, \\theta_{z})} &\\Big\\| \\bold{x} - f_{\\theta_x}(g_{\\theta_{z}}(\\bold{x})) \\Big\\|  \\\\\n",
       "&\\text{s.t.} \\\\\n",
       "&g_{\\theta_{z}} : \\mathbb{R}^{n} \\to \\mathbb{R}^{m} &(\\text{encoder}) \\\\\n",
       "&f_{\\theta_{x}} : \\mathbb{R}^{m} \\to \\mathbb{R}^{n} &(\\text{decoder})\n",
       "\\end{aligned}\n",
       "$$\n",
       "\n",
       "## Defining notation\n",
       "\n",
       "At this point, let's clarify notation. For any matrix, $y \\in \\mathbb{R}^{m\\text{ x }n}$, we do the following:\n",
       "\n",
       "* Superscripts define the unit: $y^{k}$ is the kth unit, $k \\in (1...K)$\n",
       "* Subscripts define the row, column within a unit: $y^{k}_{i, j}$ is the $i$th row and $j$th column for unit $k$, $(i \\in (1...I), j \\in (1...J))$\n",
       "\n",
       "Our problem is focused on images, thus each image, indexed by $k$, we define as two-dimensional matrix, $\\bold{x}^{k} \\in \\mathbb{R}^{I\\text{ x }J}$.\n",
       "\n",
       "# Toy Problem: Identifying Anomalous Images\n",
       "\n",
       "We will be investigating a toy problem to show the different approaches in code. We will use images of handwritten digits from the MNIST dataset. We choose this dataset because it's easy to download from pytorch. \n",
       "\n",
       "## What is our problem?\n",
       "\n",
       "Our goal is to identify \"anomalous images\", we will define \"anomalous\" more precisely below. We have a two-step process for \"anomaly detection\":\n",
       "\n",
       "1. Train an autoencoder $(\\hat{\\theta_{x}}, \\hat{\\theta_{z}})$ on a training dataset, minimizing reconstruction loss.\n",
       "2. Pass through a test image, $\\bold{x}^{k}$ to generate a reconstructed image $\\tilde{\\bold{x}}^{k}$\n",
       "3. Define some function, $A$ and threshold, $t$ of the test image and it's reconstruction loss to determine anomalies: $A(\\bold{x}^{k}, \\tilde{\\bold{x}}^{k}) \\geq t$. \n",
       "\n",
       "## What is our raw data?\n",
       "\n",
       "Our dataset consists of 2 dimensional images in gray scale. An image represents a digit, where a label `l^{k} = I` is an integer, `I`, between 0 and 9. \n",
       "\n",
       "To use this for `anomaly detection`, we split our data into two groups based on Integer. \n",
       "* `inliers`: integers we train our autoencoder on. Note, we further split this group into a `train` and `test` set.\n",
       "* `outliers`: integers we want our autoencoder to identify as anomalous. This group doesn't exist in our `train` set, and therfore only exists in our test set\n",
       "\n",
       "Basically, we train our autoencoder on \"normal\" images (`train - inliers`). We then pass through a series of `test` images, which are a combination of `inliers` and `outliers`.\n",
       "\n",
       "To keep this document terse, I will not present the code on generating our `train` and `test` sets. The code and dataset are available in this public repo. \n",
       "\n",
       "## What is our data preprocessing?\n",
       "\n",
       "we start with images, defined as 2 dimensional matrices $\\bold{x} \\in \\mathbb{R}^{2}$. We do two preprocessing steps:\n",
       "* Convert each pixel to value between 0 and 1\n",
       "* Vertically stack columns to transform two-dimensional $x \\in \\mathbb{R}^{I\\text{ x }J}$ to one-dimension $x \\in \\mathbb{R}^{IJ}$\n",
       "\n",
       "There are two notes with our approach:\n",
       "* We will still keep the subscript indexing the same $x_{i, j}$ even though we've vertically stacked our observations\n",
       "* Vertical stacking was a simplification: instead of vertically stacking we could do a convolutional NN approach, we choose not to for this exposition. \n",
       "\n",
       "## What is our approcah?\n",
       "\n",
       "The approach used will be to do unsupervised training of our autoencoder. Given that we converted each our pixels to values between 0 and 1, we will use a binary cross-entropy (logloss) objective function:\n",
       "\n",
       "$$\n",
       "\\begin{aligned}\n",
       "\\sum_{k} \\sum_{i, j} log(\\tilde{x}^{k}_{i, j})*x^{k}_{i, j} + log(1-\\tilde{x}^{k}_{i, j})*(1-x^{k}_{i, j})\n",
       "\\end{aligned}\n",
       "$$\n",
       "\n",
       "# Exploring Autoencoders\n",
       "\n",
       "## Loading data\n",
       "\n",
       "We will load data that we will use throughout this tutorial.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%markdown\n",
    "\n",
    "# Static Autoencoder Tutorial\n",
    "\n",
    "At work, we've been starting to explore different approaches to anomaly detection. I'm creating a series of posts to clarify my understanding of autoencoders, and how to use them for anomaly detection. I am going to start\n",
    "\n",
    "This post will focus on a very simple setup, a static autoencoder trying to identify anomalous images in the `MNIST` hand-written digit dataset. \n",
    "\n",
    "## Why do we need autoencoders? \n",
    "\n",
    "The key idea is lossless compression. Below shows the process of compressing and uncompressing a set of data points from $\\mathbb{R}^{2} \\to \\mathbb{R}^{1}$ and back to $\\mathbb{R}^{1} \\to \\mathbb{R}^{2}$. In the example, we have three sets of data points:\n",
    "* Input: $\\bold{x} \\in \\mathbb{R}^{2}$\n",
    "* Compressed by map $g_{\\theta_{z}}$: $\\bold{z} \\in \\mathbb{R}^{1}$\n",
    "* Reconstructed by map $f_{\\theta_{x}}$: $\\bold{\\tilde{x}} \\in \\mathbb{R}^{2}$\n",
    "\n",
    "![]('/Users/ryanstevens/Documents/github/torch_practice/data/images/simple_encoder_decoder_graph.png')\n",
    "\n",
    "Above we have a graphical representation of a simple structure, we encode (compress) data using the function $g(x)$, and then decode (uncompress) data using the inverse, $f(x)=g^{-1}(x)$. To arrive at these transformations, we can define any mappings we desire. We don't have to use simple linear transformations, $g(x)$ and $f(x)$ can be any mapping we want (i.e. a complex neural network). \n",
    "\n",
    "The goal of autoencoders is to find the mappings to minimize reconstruction loss. Formally, we try to solve the following problem:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\min_{(\\theta_{x}, \\theta_{z})} &\\Big\\| \\bold{x} - f_{\\theta_x}(g_{\\theta_{z}}(\\bold{x})) \\Big\\|  \\\\\n",
    "&\\text{s.t.} \\\\\n",
    "&g_{\\theta_{z}} : \\mathbb{R}^{n} \\to \\mathbb{R}^{m} &(\\text{encoder}) \\\\\n",
    "&f_{\\theta_{x}} : \\mathbb{R}^{m} \\to \\mathbb{R}^{n} &(\\text{decoder})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "## Connection to Principal Component Analysis\n",
    "\n",
    "It's useful at this point to make a connection to PCA. PCA is a common dimensionality reduction technique. The intuitive idea behind PCA is that the \"directions\" of high variation are good candidates for basis to project a high-dimensional vector down to. \n",
    "\n",
    "A linear PCA is one class of encoder-decoder functions (linear functions), with a specific reconstruction loss (l2-norm). Specifically, the following functional form:\n",
    "\n",
    "$$ \n",
    "\\begin{align*}\n",
    "f(x) = Wx \\;&;\\; g(z) = Vz \\\\\n",
    "\\min_{W, V} \\frac{1}{N} \\sum_{k} &\\lVert x^{k} - g(f(x^{k})) \\rVert \n",
    "\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "All our general encoder-decoder architecture allows us to do is to do non-linear mappings for $g$ and $f$ and potentially use different reconstruction losses. \n",
    "\n",
    "## Notation\n",
    "\n",
    "At this point, let's clarify notation. For any matrix, $y \\in \\mathbb{R}^{m\\text{ x }n}$, we do the following:\n",
    "\n",
    "* Superscripts define the unit: $y^{k}$ is the kth unit, $k \\in (1...K)$\n",
    "* Subscripts define the row, column within a unit: $y^{k}_{i, j}$ is the $i$th row and $j$th column for unit $k$, $(i \\in (1...I), j \\in (1...J))$\n",
    "\n",
    "Our problem is focused on images, thus each image, indexed by $k$, we define as two-dimensional matrix, $\\bold{x}^{k} \\in \\mathbb{R}^{I\\text{ x }J}$.\n",
    "\n",
    "# Toy Problem: Identifying Anomalous Images\n",
    "\n",
    "We will be investigating a toy problem to show the different approaches in code. We will use images of handwritten digits from the MNIST dataset. We choose this dataset because it's easy to download from pytorch. Below we show an example of a typical image:\n",
    "\n",
    "## What is our problem?\n",
    "\n",
    "Our goal is to identify \"anomalous images\", we will define \"anomalous\" more precisely below. We have a two-step process for \"anomaly detection\":\n",
    "\n",
    "1. Train an autoencoder $(\\hat{\\theta_{x}}, \\hat{\\theta_{z}})$ on a training dataset, minimizing reconstruction loss.\n",
    "2. Pass through a test image, $\\bold{x}^{k}$ to generate a reconstructed image $\\tilde{\\bold{x}}^{k}$\n",
    "3. Define some function, $A$ and threshold, $t$ of the test image and it's reconstruction loss to determine anomalies: $A(\\bold{x}^{k}, \\tilde{\\bold{x}}^{k}) \\geq t$. \n",
    "\n",
    "## The Data\n",
    "\n",
    "### Raw Data\n",
    "\n",
    "Our dataset consists of 2 dimensional images in gray scale. An image represents a digit, where a label `l^{k} = I` is an integer, `I`, between 0 and 9. \n",
    "\n",
    "To use this for `anomaly detection`, we split our data into two groups based on Integer. \n",
    "* `inliers`: integers we train our autoencoder on. Note, we further split this group into a `train` and `test` set.\n",
    "* `outliers`: integers we want our autoencoder to identify as anomalous. This group doesn't exist in our `train` set, and therfore only exists in our test set\n",
    "\n",
    "Basically, we train our autoencoder on \"normal\" images (`train - inliers`). We then pass through a series of `test` images, which are a combination of `inliers` and `outliers`.\n",
    "\n",
    "To keep this document terse, I will not present the code on generating our `train` and `test` sets. The code and dataset are available in this public repo. \n",
    "\n",
    "### Data Preprocessing \n",
    "\n",
    "we start with images, defined as 2 dimensional matrices $\\bold{x} \\in \\mathbb{R}^{2}$. We do two preprocessing steps:\n",
    "* Convert each pixel to value between 0 and 1\n",
    "* Vertically stack columns to transform two-dimensional $x \\in \\mathbb{R}^{I\\text{ x }J}$ to one-dimension $x \\in \\mathbb{R}^{IJ}$\n",
    "\n",
    "There are two notes with our approach:\n",
    "* We will still keep the subscript indexing the same $x_{i, j}$ even though we've vertically stacked our observations\n",
    "* Vertical stacking was a simplification: instead of vertically stacking we could do a convolutional NN approach, we choose not to for this exposition. \n",
    "\n",
    "## Training our AutoEncoder\n",
    "\n",
    "The approach used will be to do unsupervised training of our autoencoder. Given that we converted each our pixels to values between 0 and 1, we will use a binary cross-entropy (logloss) objective function:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\sum_{k} \\sum_{i, j} log(\\tilde{x}^{k}_{i, j})*x^{k}_{i, j} + log(1-\\tilde{x}^{k}_{i, j})*(1-x^{k}_{i, j})\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Autoencoders\n",
    "\n",
    "## Exploring Bottleneck Layer\n",
    "\n",
    "The key choice for the autoencoder, the size of the latent dimension (or bottleneck layer). In our terminology, it's the dimension of the target space ($m$) of our encoder, $g_{\\theta_{z}} : \\mathbb{R}^{n} \\to \\mathbb{R}^{m}$.\n",
    "\n",
    "Below shows an example vanilla architecture that has a single hidden layer that maps $\\mathbb{R}^{8} \\to \\mathbb{R}^{4}$. Note, we only have one single hidden unit. Like any NN we can increase the depth by adding more hidden units.\n",
    "\n",
    "![](/Users/ryanstevens/Documents/github/torch_practice/data/images/vanilla_autoencoder.png)\n",
    "\n",
    "\n",
    "The main choice with a vanilla autoencoder is the size of the bottleneck layer (i.e. $m$). To build intuition, the key is to think about two polar opposite scenarios:\n",
    "* `dim(z) = 1`: this reduces all our dimension a single scalar. This highly compresses the data, which would lead to poor generalization error if `dim(x)` is large\n",
    "* `dim(z) = dim(x)`: there is no compression, thus the training error will be 0, as it simply \"memorizes\" the data, thus poor generationalization error.\n",
    "\n",
    "In fact, we could roughly think about generalization error as some convex function between these two poles:\n",
    "\n",
    "![Generalization Error and Latent Space Size](/Users/ryanstevens/Documents/github/torch_practice/notebooks/blog_posts/images/generalization_error.png)\n",
    "\n",
    "### Code\n",
    "\n",
    "We now define this in code. We create a class `VanillaEncoderDecoder` to make it easier to define our vanilla architecture, specifically looping through different bottleneck layer sizes. \n",
    "\n",
    "Let's print out the architecture for one example, just so we can see the full architecture. We use `ReLU` units, `dropout(p=0.5)`, and a sigmoid activation unit for the final head layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules \n",
    "import torch.nn as nn\n",
    "from src.helpers import models\n",
    "from torchview import draw_graph\n",
    "\n",
    "# Example vanilla autoencoder\n",
    "vanilla_model_example = models.StaticEncoderDecoder(\n",
    "    input_dim=28*28,\n",
    "    latent_dim=4,\n",
    "    head_layer=nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# Plot graph\n",
    "model_graph = draw_graph(vanilla_model_example, input_size=(1, 28*28))\n",
    "model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%markdown\n",
    "\n",
    "## Examining Bottleneck Layer\n",
    "\n",
    "We will now explore the impact of changing the size of the bottleneck layer. We will train different `VanillaEncoderDecoder` varying only the `latent_dim` parameter. We will explore some interesting statistics and plots around this. Note, I built a helper function `data.load_and_preprocess_data()` to load, preprocess and split our data into `train`, `val`, `test` sets. It's all available in this part of our repo:...\n",
    "\n",
    "\n",
    "# References\n",
    "\n",
    "* [Pytorch Tutorials of AutoEncoder Papers](https://github.com/SethHWeidman/pytorch-seq2seq/blob/master/1%20-%20Sequence%20to%20Sequence%20Learning%20with%20Neural%20Networks.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 646.289490  [    1/ 1184]\n",
      "train loss: 605.166626  [  101/ 1184]\n",
      "train loss: 687.562195  [  201/ 1184]\n",
      "train loss: 614.589233  [  301/ 1184]\n",
      "train loss: 621.595764  [  401/ 1184]\n",
      "train loss: 623.302063  [  501/ 1184]\n",
      "train loss: 603.255981  [  601/ 1184]\n",
      "train loss: 553.200500  [  701/ 1184]\n",
      "train loss: 650.619873  [  801/ 1184]\n",
      "train loss: 630.767456  [  901/ 1184]\n",
      "train loss: 602.992310  [ 1001/ 1184]\n",
      "train loss: 644.702332  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 18:56:10.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:10.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:12.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:12.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [630.306884765625, 655.218505859375, 562.4224853515625, 611.0111083984375, 590.0322875976562]\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:12.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mbest_score is None, saving best score...\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:12.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (inf --> 613.896164).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 653.765137  [    1/ 1184]\n",
      "train loss: 656.082642  [  101/ 1184]\n",
      "train loss: 638.029602  [  201/ 1184]\n",
      "train loss: 589.501099  [  301/ 1184]\n",
      "train loss: 730.439758  [  401/ 1184]\n",
      "train loss: 620.834656  [  501/ 1184]\n",
      "train loss: 614.702271  [  601/ 1184]\n",
      "train loss: 617.128601  [  701/ 1184]\n",
      "train loss: 678.677673  [  801/ 1184]\n",
      "train loss: 554.435059  [  901/ 1184]\n",
      "train loss: 629.238525  [ 1001/ 1184]\n",
      "train loss: 636.730042  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 18:56:23.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:23.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:25.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:25.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [626.5169677734375, 651.0533447265625, 558.7174072265625, 607.8361206054688, 585.4027709960938]\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:25.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -609.5198641620104 is higher than -613.8961639017998, setting new best score to -609.5198641620104\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:25.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (613.896164 --> 609.519864).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 570.642456  [    1/ 1184]\n",
      "train loss: 601.864319  [  101/ 1184]\n",
      "train loss: 682.532104  [  201/ 1184]\n",
      "train loss: 594.178528  [  301/ 1184]\n",
      "train loss: 580.658875  [  401/ 1184]\n",
      "train loss: 527.713989  [  501/ 1184]\n",
      "train loss: 591.174072  [  601/ 1184]\n",
      "train loss: 593.221436  [  701/ 1184]\n",
      "train loss: 693.059387  [  801/ 1184]\n",
      "train loss: 579.752014  [  901/ 1184]\n",
      "train loss: 658.743958  [ 1001/ 1184]\n",
      "train loss: 667.921082  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 18:56:35.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:35.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:37.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:37.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [624.997802734375, 649.50244140625, 557.2469482421875, 606.2987060546875, 583.6919555664062]\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:37.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -607.8220526200306 is higher than -609.5198641620104, setting new best score to -607.8220526200306\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:37.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (609.519864 --> 607.822053).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 606.956177  [    1/ 1184]\n",
      "train loss: 618.776855  [  101/ 1184]\n",
      "train loss: 589.223328  [  201/ 1184]\n",
      "train loss: 649.569824  [  301/ 1184]\n",
      "train loss: 592.121643  [  401/ 1184]\n",
      "train loss: 561.532959  [  501/ 1184]\n",
      "train loss: 651.976562  [  601/ 1184]\n",
      "train loss: 579.212769  [  701/ 1184]\n",
      "train loss: 601.089172  [  801/ 1184]\n",
      "train loss: 557.771240  [  901/ 1184]\n",
      "train loss: 609.739502  [ 1001/ 1184]\n",
      "train loss: 591.208984  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 18:56:48.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:48.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:50.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:50.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [623.7188720703125, 648.8412475585938, 556.3232421875, 605.1786499023438, 582.7166748046875]\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:50.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -606.8974354418018 is higher than -607.8220526200306, setting new best score to -606.8974354418018\u001b[0m\n",
      "\u001b[32m2023-11-26 18:56:50.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (607.822053 --> 606.897435).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 616.119873  [    1/ 1184]\n",
      "train loss: 552.835632  [  101/ 1184]\n",
      "train loss: 651.310486  [  201/ 1184]\n",
      "train loss: 563.111206  [  301/ 1184]\n",
      "train loss: 630.645142  [  401/ 1184]\n",
      "train loss: 614.072510  [  501/ 1184]\n",
      "train loss: 588.263550  [  601/ 1184]\n",
      "train loss: 591.656006  [  701/ 1184]\n",
      "train loss: 675.233215  [  801/ 1184]\n",
      "train loss: 629.639282  [  901/ 1184]\n",
      "train loss: 612.585754  [ 1001/ 1184]\n",
      "train loss: 617.655334  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 18:57:01.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:01.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:03.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:03.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [623.3526000976562, 648.7211303710938, 556.1259155273438, 604.7281494140625, 582.4434204101562]\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:03.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -606.5468139648438 is higher than -606.8974354418018, setting new best score to -606.5468139648438\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:03.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (606.897435 --> 606.546814).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 527.457458  [    1/ 1184]\n",
      "train loss: 640.120789  [  101/ 1184]\n",
      "train loss: 565.252808  [  201/ 1184]\n",
      "train loss: 634.425049  [  301/ 1184]\n",
      "train loss: 704.048828  [  401/ 1184]\n",
      "train loss: 624.945007  [  501/ 1184]\n",
      "train loss: 581.568726  [  601/ 1184]\n",
      "train loss: 616.878540  [  701/ 1184]\n",
      "train loss: 594.719299  [  801/ 1184]\n",
      "train loss: 633.977173  [  901/ 1184]\n",
      "train loss: 602.246155  [ 1001/ 1184]\n",
      "train loss: 582.481934  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 18:57:15.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:15.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:16.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:16.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [623.174560546875, 648.3958740234375, 555.9427490234375, 604.4816284179688, 582.2993774414062]\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:16.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -606.3456564601464 is higher than -606.5468139648438, setting new best score to -606.3456564601464\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:16.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (606.546814 --> 606.345656).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 620.247986  [    1/ 1184]\n",
      "train loss: 603.676270  [  101/ 1184]\n",
      "train loss: 583.378418  [  201/ 1184]\n",
      "train loss: 579.789490  [  301/ 1184]\n",
      "train loss: 585.908325  [  401/ 1184]\n",
      "train loss: 545.083374  [  501/ 1184]\n",
      "train loss: 581.951416  [  601/ 1184]\n",
      "train loss: 592.600464  [  701/ 1184]\n",
      "train loss: 623.123047  [  801/ 1184]\n",
      "train loss: 700.626770  [  901/ 1184]\n",
      "train loss: 645.442810  [ 1001/ 1184]\n",
      "train loss: 615.597839  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 18:57:28.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:28.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:30.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:30.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [623.1571044921875, 647.87158203125, 555.8178100585938, 604.2955322265625, 582.2576293945312]\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:30.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -606.1462673525267 is higher than -606.3456564601464, setting new best score to -606.1462673525267\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:30.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (606.345656 --> 606.146267).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 586.258118  [    1/ 1184]\n",
      "train loss: 535.543884  [  101/ 1184]\n",
      "train loss: 652.152161  [  201/ 1184]\n",
      "train loss: 593.612915  [  301/ 1184]\n",
      "train loss: 583.508179  [  401/ 1184]\n",
      "train loss: 622.045898  [  501/ 1184]\n",
      "train loss: 626.572754  [  601/ 1184]\n",
      "train loss: 623.954956  [  701/ 1184]\n",
      "train loss: 583.579102  [  801/ 1184]\n",
      "train loss: 606.218933  [  901/ 1184]\n",
      "train loss: 584.528748  [ 1001/ 1184]\n",
      "train loss: 645.587097  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 18:57:42.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:42.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:44.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:44.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [622.95361328125, 647.077880859375, 555.3707275390625, 603.9192504882812, 581.7454223632812]\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:44.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -605.5576848669897 is higher than -606.1462673525267, setting new best score to -605.5576848669897\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:44.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (606.146267 --> 605.557685).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 631.136902  [    1/ 1184]\n",
      "train loss: 552.733093  [  101/ 1184]\n",
      "train loss: 648.189453  [  201/ 1184]\n",
      "train loss: 589.944336  [  301/ 1184]\n",
      "train loss: 571.613831  [  401/ 1184]\n",
      "train loss: 577.559021  [  501/ 1184]\n",
      "train loss: 655.331543  [  601/ 1184]\n",
      "train loss: 662.279541  [  701/ 1184]\n",
      "train loss: 593.650574  [  801/ 1184]\n",
      "train loss: 604.756226  [  901/ 1184]\n",
      "train loss: 639.654907  [ 1001/ 1184]\n",
      "train loss: 606.988586  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 18:57:57.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:57.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:58.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:58.646\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [622.8424682617188, 646.7183837890625, 555.1267700195312, 603.7168579101562, 581.467529296875]\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:58.647\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -605.3090004450158 is higher than -605.5576848669897, setting new best score to -605.3090004450158\u001b[0m\n",
      "\u001b[32m2023-11-26 18:57:58.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (605.557685 --> 605.309000).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 611.053406  [    1/ 1184]\n",
      "train loss: 621.178467  [  101/ 1184]\n",
      "train loss: 565.184143  [  201/ 1184]\n",
      "train loss: 571.717896  [  301/ 1184]\n",
      "train loss: 639.506897  [  401/ 1184]\n",
      "train loss: 629.153992  [  501/ 1184]\n",
      "train loss: 583.588074  [  601/ 1184]\n",
      "train loss: 636.283447  [  701/ 1184]\n",
      "train loss: 583.047852  [  801/ 1184]\n",
      "train loss: 560.012573  [  901/ 1184]\n",
      "train loss: 636.345703  [ 1001/ 1184]\n",
      "train loss: 597.001465  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 18:58:09.101\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 18:58:09.102\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 18:58:10.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 18:58:10.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [622.6070556640625, 646.233154296875, 554.862060546875, 603.4803466796875, 581.2291259765625]\u001b[0m\n",
      "\u001b[32m2023-11-26 18:58:10.667\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -605.039557271064 is higher than -605.3090004450158, setting new best score to -605.039557271064\u001b[0m\n",
      "\u001b[32m2023-11-26 18:58:10.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (605.309000 --> 605.039557).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 654.014038  [    1/ 1184]\n",
      "train loss: 598.632935  [  101/ 1184]\n",
      "train loss: 592.096069  [  201/ 1184]\n",
      "train loss: 538.780090  [  301/ 1184]\n",
      "train loss: 707.035217  [  401/ 1184]\n",
      "train loss: 636.588440  [  501/ 1184]\n",
      "train loss: 593.843933  [  601/ 1184]\n",
      "train loss: 616.961060  [  701/ 1184]\n",
      "train loss: 628.415955  [  801/ 1184]\n",
      "train loss: 583.992310  [  901/ 1184]\n",
      "train loss: 647.774658  [ 1001/ 1184]\n",
      "train loss: 689.153503  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 19:04:56.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 19:04:56.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 19:04:58.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 19:04:58.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [622.384033203125, 645.769775390625, 554.4973754882812, 603.07421875, 580.862060546875]\u001b[0m\n",
      "\u001b[32m2023-11-26 19:04:58.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -604.7011739610117 is higher than -605.039557271064, setting new best score to -604.7011739610117\u001b[0m\n",
      "\u001b[32m2023-11-26 19:04:58.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (605.039557 --> 604.701174).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 644.645813  [    1/ 1184]\n",
      "train loss: 621.831238  [  101/ 1184]\n",
      "train loss: 573.228821  [  201/ 1184]\n",
      "train loss: 678.300659  [  301/ 1184]\n",
      "train loss: 602.786011  [  401/ 1184]\n",
      "train loss: 617.242310  [  501/ 1184]\n",
      "train loss: 661.512817  [  601/ 1184]\n",
      "train loss: 632.392700  [  701/ 1184]\n",
      "train loss: 678.507507  [  801/ 1184]\n",
      "train loss: 651.099304  [  901/ 1184]\n",
      "train loss: 580.600403  [ 1001/ 1184]\n",
      "train loss: 508.819244  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 19:13:36.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 19:13:36.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 19:13:38.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 19:13:38.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [622.070068359375, 645.6175537109375, 554.2666625976562, 602.7837524414062, 580.724853515625]\u001b[0m\n",
      "\u001b[32m2023-11-26 19:13:38.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -604.4789482020125 is higher than -604.7011739610117, setting new best score to -604.4789482020125\u001b[0m\n",
      "\u001b[32m2023-11-26 19:13:38.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (604.701174 --> 604.478948).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 591.819458  [    1/ 1184]\n",
      "train loss: 627.101379  [  101/ 1184]\n",
      "train loss: 578.825317  [  201/ 1184]\n",
      "train loss: 600.518616  [  301/ 1184]\n",
      "train loss: 600.706299  [  401/ 1184]\n",
      "train loss: 586.339172  [  501/ 1184]\n",
      "train loss: 686.042358  [  601/ 1184]\n",
      "train loss: 558.659363  [  701/ 1184]\n",
      "train loss: 545.779114  [  801/ 1184]\n",
      "train loss: 621.159302  [  901/ 1184]\n",
      "train loss: 631.200806  [ 1001/ 1184]\n",
      "train loss: 593.426147  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 19:22:41.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 19:22:41.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 19:22:43.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 19:22:43.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [621.8155517578125, 645.3970336914062, 554.1666259765625, 602.5885620117188, 580.319091796875]\u001b[0m\n",
      "\u001b[32m2023-11-26 19:22:43.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -604.2789699119858 is higher than -604.4789482020125, setting new best score to -604.2789699119858\u001b[0m\n",
      "\u001b[32m2023-11-26 19:22:43.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (604.478948 --> 604.278970).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 584.861694  [    1/ 1184]\n",
      "train loss: 631.775391  [  101/ 1184]\n",
      "train loss: 544.808350  [  201/ 1184]\n",
      "train loss: 649.738892  [  301/ 1184]\n",
      "train loss: 614.410889  [  401/ 1184]\n",
      "train loss: 599.114624  [  501/ 1184]\n",
      "train loss: 632.919678  [  601/ 1184]\n",
      "train loss: 568.667480  [  701/ 1184]\n",
      "train loss: 535.563354  [  801/ 1184]\n",
      "train loss: 623.884888  [  901/ 1184]\n",
      "train loss: 626.395874  [ 1001/ 1184]\n",
      "train loss: 627.896301  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 19:41:05.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 19:41:05.220\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 19:41:07.680\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 19:41:07.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [621.7748413085938, 645.4217529296875, 554.1590576171875, 602.5640869140625, 580.210693359375]\u001b[0m\n",
      "\u001b[32m2023-11-26 19:41:07.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -604.2374425187895 is higher than -604.2789699119858, setting new best score to -604.2374425187895\u001b[0m\n",
      "\u001b[32m2023-11-26 19:41:07.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (604.278970 --> 604.237443).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 574.687317  [    1/ 1184]\n",
      "train loss: 644.545044  [  101/ 1184]\n",
      "train loss: 613.465210  [  201/ 1184]\n",
      "train loss: 556.844482  [  301/ 1184]\n",
      "train loss: 640.218628  [  401/ 1184]\n",
      "train loss: 593.688049  [  501/ 1184]\n",
      "train loss: 648.364258  [  601/ 1184]\n",
      "train loss: 648.158691  [  701/ 1184]\n",
      "train loss: 643.432007  [  801/ 1184]\n",
      "train loss: 590.337341  [  901/ 1184]\n",
      "train loss: 593.638855  [ 1001/ 1184]\n",
      "train loss: 639.580444  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 19:49:39.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 19:49:39.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 19:49:41.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 19:49:41.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [621.5797729492188, 645.1958618164062, 554.0153198242188, 602.4949340820312, 580.1214599609375]\u001b[0m\n",
      "\u001b[32m2023-11-26 19:49:41.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -604.1048655835888 is higher than -604.2374425187895, setting new best score to -604.1048655835888\u001b[0m\n",
      "\u001b[32m2023-11-26 19:49:41.225\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (604.237443 --> 604.104866).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 557.004028  [    1/ 1184]\n",
      "train loss: 590.107422  [  101/ 1184]\n",
      "train loss: 562.256958  [  201/ 1184]\n",
      "train loss: 603.552124  [  301/ 1184]\n",
      "train loss: 583.063477  [  401/ 1184]\n",
      "train loss: 621.245728  [  501/ 1184]\n",
      "train loss: 612.363892  [  601/ 1184]\n",
      "train loss: 573.454773  [  701/ 1184]\n",
      "train loss: 593.764648  [  801/ 1184]\n",
      "train loss: 536.106201  [  901/ 1184]\n",
      "train loss: 648.413269  [ 1001/ 1184]\n",
      "train loss: 650.717529  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 19:58:45.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 19:58:45.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 19:58:47.063\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 19:58:47.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [621.4700927734375, 645.1354370117188, 553.900146484375, 602.428955078125, 579.944580078125]\u001b[0m\n",
      "\u001b[32m2023-11-26 19:58:47.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -603.9738543932951 is higher than -604.1048655835888, setting new best score to -603.9738543932951\u001b[0m\n",
      "\u001b[32m2023-11-26 19:58:47.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (604.104866 --> 603.973854).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 609.668579  [    1/ 1184]\n",
      "train loss: 645.594727  [  101/ 1184]\n",
      "train loss: 569.046448  [  201/ 1184]\n",
      "train loss: 577.464783  [  301/ 1184]\n",
      "train loss: 581.283936  [  401/ 1184]\n",
      "train loss: 593.481567  [  501/ 1184]\n",
      "train loss: 677.771118  [  601/ 1184]\n",
      "train loss: 557.707520  [  701/ 1184]\n",
      "train loss: 626.007690  [  801/ 1184]\n",
      "train loss: 615.588379  [  901/ 1184]\n",
      "train loss: 600.229370  [ 1001/ 1184]\n",
      "train loss: 621.131531  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 19:59:56.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 19:59:56.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 19:59:58.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 19:59:58.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [621.2910766601562, 644.9352416992188, 553.7490234375, 602.2635498046875, 579.68798828125]\u001b[0m\n",
      "\u001b[32m2023-11-26 19:59:58.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -603.8024434922617 is higher than -603.9738543932951, setting new best score to -603.8024434922617\u001b[0m\n",
      "\u001b[32m2023-11-26 19:59:58.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (603.973854 --> 603.802443).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 594.166992  [    1/ 1184]\n",
      "train loss: 587.160950  [  101/ 1184]\n",
      "train loss: 656.356262  [  201/ 1184]\n",
      "train loss: 560.067688  [  301/ 1184]\n",
      "train loss: 634.900879  [  401/ 1184]\n",
      "train loss: 588.549683  [  501/ 1184]\n",
      "train loss: 612.492188  [  601/ 1184]\n",
      "train loss: 629.453979  [  701/ 1184]\n",
      "train loss: 528.257446  [  801/ 1184]\n",
      "train loss: 543.579529  [  901/ 1184]\n",
      "train loss: 634.782227  [ 1001/ 1184]\n",
      "train loss: 606.885986  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:00:10.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:10.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:12.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:12.098\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [621.1492919921875, 644.8555908203125, 553.5653076171875, 602.1554565429688, 579.591796875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:12.099\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -603.6922167814231 is higher than -603.8024434922617, setting new best score to -603.6922167814231\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:12.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (603.802443 --> 603.692217).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 610.568604  [    1/ 1184]\n",
      "train loss: 581.328125  [  101/ 1184]\n",
      "train loss: 595.133484  [  201/ 1184]\n",
      "train loss: 643.601074  [  301/ 1184]\n",
      "train loss: 641.483276  [  401/ 1184]\n",
      "train loss: 643.921631  [  501/ 1184]\n",
      "train loss: 649.791077  [  601/ 1184]\n",
      "train loss: 584.736145  [  701/ 1184]\n",
      "train loss: 602.649719  [  801/ 1184]\n",
      "train loss: 615.104919  [  901/ 1184]\n",
      "train loss: 595.387329  [ 1001/ 1184]\n",
      "train loss: 615.713684  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:00:23.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:23.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:25.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:25.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [621.1443481445312, 644.7836303710938, 553.4525756835938, 602.1028442382812, 579.504638671875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:25.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -603.599063998838 is higher than -603.6922167814231, setting new best score to -603.599063998838\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:25.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (603.692217 --> 603.599064).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 543.256348  [    1/ 1184]\n",
      "train loss: 618.371826  [  101/ 1184]\n",
      "train loss: 577.750183  [  201/ 1184]\n",
      "train loss: 565.834229  [  301/ 1184]\n",
      "train loss: 595.907349  [  401/ 1184]\n",
      "train loss: 608.280273  [  501/ 1184]\n",
      "train loss: 570.601624  [  601/ 1184]\n",
      "train loss: 615.675293  [  701/ 1184]\n",
      "train loss: 562.553345  [  801/ 1184]\n",
      "train loss: 623.577026  [  901/ 1184]\n",
      "train loss: 630.192566  [ 1001/ 1184]\n",
      "train loss: 637.135376  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:00:36.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:36.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:38.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:38.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [621.063232421875, 644.620361328125, 553.3187255859375, 602.0037841796875, 579.41650390625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:38.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -603.4745421590684 is higher than -603.599063998838, setting new best score to -603.4745421590684\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:38.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (603.599064 --> 603.474542).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 605.670166  [    1/ 1184]\n",
      "train loss: 632.080811  [  101/ 1184]\n",
      "train loss: 630.852173  [  201/ 1184]\n",
      "train loss: 638.122864  [  301/ 1184]\n",
      "train loss: 598.933838  [  401/ 1184]\n",
      "train loss: 589.130066  [  501/ 1184]\n",
      "train loss: 590.838074  [  601/ 1184]\n",
      "train loss: 571.391907  [  701/ 1184]\n",
      "train loss: 611.507446  [  801/ 1184]\n",
      "train loss: 623.833862  [  901/ 1184]\n",
      "train loss: 644.920410  [ 1001/ 1184]\n",
      "train loss: 594.328125  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:00:49.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:49.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:51.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:51.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [620.9193115234375, 644.60302734375, 553.1412353515625, 601.8565063476562, 579.2406616210938]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:51.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -603.3615938210789 is higher than -603.4745421590684, setting new best score to -603.3615938210789\u001b[0m\n",
      "\u001b[32m2023-11-26 20:00:51.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (603.474542 --> 603.361594).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 692.930847  [    1/ 1184]\n",
      "train loss: 654.766541  [  101/ 1184]\n",
      "train loss: 593.505859  [  201/ 1184]\n",
      "train loss: 627.225647  [  301/ 1184]\n",
      "train loss: 596.273254  [  401/ 1184]\n",
      "train loss: 602.183594  [  501/ 1184]\n",
      "train loss: 572.607727  [  601/ 1184]\n",
      "train loss: 606.290222  [  701/ 1184]\n",
      "train loss: 575.519958  [  801/ 1184]\n",
      "train loss: 608.704163  [  901/ 1184]\n",
      "train loss: 663.649536  [ 1001/ 1184]\n",
      "train loss: 608.529175  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:01:02.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:02.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:04.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:04.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [620.8790893554688, 644.5098876953125, 553.0892944335938, 601.8041381835938, 579.3026733398438]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:04.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -603.2934455195559 is higher than -603.3615938210789, setting new best score to -603.2934455195559\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:04.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (603.361594 --> 603.293446).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 534.813416  [    1/ 1184]\n",
      "train loss: 645.804077  [  101/ 1184]\n",
      "train loss: 547.512573  [  201/ 1184]\n",
      "train loss: 581.580627  [  301/ 1184]\n",
      "train loss: 617.692078  [  401/ 1184]\n",
      "train loss: 601.026123  [  501/ 1184]\n",
      "train loss: 629.947510  [  601/ 1184]\n",
      "train loss: 630.043884  [  701/ 1184]\n",
      "train loss: 584.613342  [  801/ 1184]\n",
      "train loss: 557.242371  [  901/ 1184]\n",
      "train loss: 681.190430  [ 1001/ 1184]\n",
      "train loss: 621.949463  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:01:15.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:15.234\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:16.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:16.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [620.7770385742188, 644.5198364257812, 553.0787963867188, 601.5629272460938, 579.2555541992188]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:16.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -603.2096220764932 is higher than -603.2934455195559, setting new best score to -603.2096220764932\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:16.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (603.293446 --> 603.209622).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 593.752319  [    1/ 1184]\n",
      "train loss: 606.430115  [  101/ 1184]\n",
      "train loss: 551.101074  [  201/ 1184]\n",
      "train loss: 590.714233  [  301/ 1184]\n",
      "train loss: 564.015137  [  401/ 1184]\n",
      "train loss: 639.405396  [  501/ 1184]\n",
      "train loss: 637.633606  [  601/ 1184]\n",
      "train loss: 597.697266  [  701/ 1184]\n",
      "train loss: 614.264282  [  801/ 1184]\n",
      "train loss: 568.302124  [  901/ 1184]\n",
      "train loss: 635.637756  [ 1001/ 1184]\n",
      "train loss: 582.627625  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:01:28.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:28.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:29.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:29.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [620.7150268554688, 644.3878173828125, 552.9407958984375, 601.47119140625, 579.0753173828125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:29.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -603.0858701295491 is higher than -603.2096220764932, setting new best score to -603.0858701295491\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:29.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (603.209622 --> 603.085870).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 564.435425  [    1/ 1184]\n",
      "train loss: 579.855713  [  101/ 1184]\n",
      "train loss: 649.050049  [  201/ 1184]\n",
      "train loss: 548.569397  [  301/ 1184]\n",
      "train loss: 616.450195  [  401/ 1184]\n",
      "train loss: 570.960449  [  501/ 1184]\n",
      "train loss: 600.261902  [  601/ 1184]\n",
      "train loss: 678.463623  [  701/ 1184]\n",
      "train loss: 568.298706  [  801/ 1184]\n",
      "train loss: 591.513184  [  901/ 1184]\n",
      "train loss: 640.223389  [ 1001/ 1184]\n",
      "train loss: 640.429199  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:01:40.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:40.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:42.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:42.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [620.55126953125, 644.3034057617188, 552.8510131835938, 601.3404541015625, 579.0170288085938]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:42.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -603.0054923914656 is higher than -603.0858701295491, setting new best score to -603.0054923914656\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:42.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (603.085870 --> 603.005492).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 555.624390  [    1/ 1184]\n",
      "train loss: 522.561279  [  101/ 1184]\n",
      "train loss: 651.864563  [  201/ 1184]\n",
      "train loss: 599.138733  [  301/ 1184]\n",
      "train loss: 666.386230  [  401/ 1184]\n",
      "train loss: 618.767151  [  501/ 1184]\n",
      "train loss: 699.859009  [  601/ 1184]\n",
      "train loss: 618.680908  [  701/ 1184]\n",
      "train loss: 644.243896  [  801/ 1184]\n",
      "train loss: 562.006714  [  901/ 1184]\n",
      "train loss: 547.376160  [ 1001/ 1184]\n",
      "train loss: 585.652588  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:01:54.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:54.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:55.648\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:55.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [620.5531616210938, 644.2826538085938, 552.7530517578125, 601.2610473632812, 578.8922119140625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:55.649\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.9111882849585 is higher than -603.0054923914656, setting new best score to -602.9111882849585\u001b[0m\n",
      "\u001b[32m2023-11-26 20:01:55.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (603.005492 --> 602.911188).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 576.343750  [    1/ 1184]\n",
      "train loss: 579.143799  [  101/ 1184]\n",
      "train loss: 542.134949  [  201/ 1184]\n",
      "train loss: 630.647461  [  301/ 1184]\n",
      "train loss: 575.331177  [  401/ 1184]\n",
      "train loss: 621.529297  [  501/ 1184]\n",
      "train loss: 592.863037  [  601/ 1184]\n",
      "train loss: 603.349609  [  701/ 1184]\n",
      "train loss: 696.487793  [  801/ 1184]\n",
      "train loss: 585.766235  [  901/ 1184]\n",
      "train loss: 548.553772  [ 1001/ 1184]\n",
      "train loss: 578.493774  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:02:06.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:06.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:09.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:09.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [620.46728515625, 644.2247924804688, 552.6153564453125, 601.2032470703125, 578.9127197265625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:09.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.8398075924644 is higher than -602.9111882849585, setting new best score to -602.8398075924644\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:09.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.911188 --> 602.839808).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 569.264709  [    1/ 1184]\n",
      "train loss: 639.151855  [  101/ 1184]\n",
      "train loss: 676.342896  [  201/ 1184]\n",
      "train loss: 606.853149  [  301/ 1184]\n",
      "train loss: 644.753540  [  401/ 1184]\n",
      "train loss: 553.368347  [  501/ 1184]\n",
      "train loss: 628.797485  [  601/ 1184]\n",
      "train loss: 584.705933  [  701/ 1184]\n",
      "train loss: 514.464600  [  801/ 1184]\n",
      "train loss: 581.508179  [  901/ 1184]\n",
      "train loss: 576.115601  [ 1001/ 1184]\n",
      "train loss: 591.593811  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:02:22.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:22.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:23.862\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:23.863\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [620.4742431640625, 644.2129516601562, 552.577392578125, 601.1297607421875, 578.8331298828125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:23.864\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.7978052839449 is higher than -602.8398075924644, setting new best score to -602.7978052839449\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:23.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.839808 --> 602.797805).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 569.507751  [    1/ 1184]\n",
      "train loss: 574.061768  [  101/ 1184]\n",
      "train loss: 599.321899  [  201/ 1184]\n",
      "train loss: 668.338684  [  301/ 1184]\n",
      "train loss: 575.550476  [  401/ 1184]\n",
      "train loss: 640.266113  [  501/ 1184]\n",
      "train loss: 665.164978  [  601/ 1184]\n",
      "train loss: 630.499695  [  701/ 1184]\n",
      "train loss: 544.648987  [  801/ 1184]\n",
      "train loss: 598.678833  [  901/ 1184]\n",
      "train loss: 569.578552  [ 1001/ 1184]\n",
      "train loss: 604.558960  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:02:35.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:35.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:37.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:37.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [620.3341064453125, 644.0478515625, 552.400390625, 601.0776977539062, 578.8026123046875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:37.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.7154242020619 is higher than -602.7978052839449, setting new best score to -602.7154242020619\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:37.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.797805 --> 602.715424).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 655.953003  [    1/ 1184]\n",
      "train loss: 570.411926  [  101/ 1184]\n",
      "train loss: 641.757812  [  201/ 1184]\n",
      "train loss: 603.971741  [  301/ 1184]\n",
      "train loss: 622.056702  [  401/ 1184]\n",
      "train loss: 555.767090  [  501/ 1184]\n",
      "train loss: 601.150635  [  601/ 1184]\n",
      "train loss: 610.400085  [  701/ 1184]\n",
      "train loss: 642.397278  [  801/ 1184]\n",
      "train loss: 646.694275  [  901/ 1184]\n",
      "train loss: 595.834106  [ 1001/ 1184]\n",
      "train loss: 566.611938  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:02:55.578\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:55.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:58.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:58.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [620.2410888671875, 644.0399169921875, 552.4019775390625, 601.0805053710938, 578.719970703125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:58.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.6662811665595 is higher than -602.7154242020619, setting new best score to -602.6662811665595\u001b[0m\n",
      "\u001b[32m2023-11-26 20:02:58.597\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.715424 --> 602.666281).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 506.596008  [    1/ 1184]\n",
      "train loss: 636.130981  [  101/ 1184]\n",
      "train loss: 628.023438  [  201/ 1184]\n",
      "train loss: 611.850769  [  301/ 1184]\n",
      "train loss: 678.659485  [  401/ 1184]\n",
      "train loss: 582.534668  [  501/ 1184]\n",
      "train loss: 546.044495  [  601/ 1184]\n",
      "train loss: 558.945862  [  701/ 1184]\n",
      "train loss: 603.515747  [  801/ 1184]\n",
      "train loss: 587.569458  [  901/ 1184]\n",
      "train loss: 614.439148  [ 1001/ 1184]\n",
      "train loss: 571.848083  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:03:23.044\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:03:23.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:03:25.390\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:03:25.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [620.2144165039062, 643.9212036132812, 552.3751831054688, 600.9466552734375, 578.6730346679688]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:03:25.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.6020381879202 is higher than -602.6662811665595, setting new best score to -602.6020381879202\u001b[0m\n",
      "\u001b[32m2023-11-26 20:03:25.396\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.666281 --> 602.602038).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 555.036621  [    1/ 1184]\n",
      "train loss: 637.564575  [  101/ 1184]\n",
      "train loss: 599.779358  [  201/ 1184]\n",
      "train loss: 672.151794  [  301/ 1184]\n",
      "train loss: 636.415955  [  401/ 1184]\n",
      "train loss: 671.222290  [  501/ 1184]\n",
      "train loss: 600.733215  [  601/ 1184]\n",
      "train loss: 605.090332  [  701/ 1184]\n",
      "train loss: 598.357117  [  801/ 1184]\n",
      "train loss: 639.197754  [  901/ 1184]\n",
      "train loss: 556.969604  [ 1001/ 1184]\n",
      "train loss: 647.831543  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:03:47.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:03:47.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:03:50.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:03:50.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [620.0808715820312, 643.970458984375, 552.3572998046875, 600.9644165039062, 578.7239990234375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:03:50.470\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.5647218342069 is higher than -602.6020381879202, setting new best score to -602.5647218342069\u001b[0m\n",
      "\u001b[32m2023-11-26 20:03:50.471\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.602038 --> 602.564722).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 572.296997  [    1/ 1184]\n",
      "train loss: 649.105591  [  101/ 1184]\n",
      "train loss: 643.346069  [  201/ 1184]\n",
      "train loss: 617.037720  [  301/ 1184]\n",
      "train loss: 576.280762  [  401/ 1184]\n",
      "train loss: 599.189209  [  501/ 1184]\n",
      "train loss: 636.826843  [  601/ 1184]\n",
      "train loss: 576.795898  [  701/ 1184]\n",
      "train loss: 659.777954  [  801/ 1184]\n",
      "train loss: 660.537354  [  901/ 1184]\n",
      "train loss: 623.553345  [ 1001/ 1184]\n",
      "train loss: 623.129150  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:04:06.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:04:06.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:04:09.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:04:09.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [620.0773315429688, 643.8231201171875, 552.2672119140625, 600.9727783203125, 578.5864868164062]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:04:09.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.5088375043265 is higher than -602.5647218342069, setting new best score to -602.5088375043265\u001b[0m\n",
      "\u001b[32m2023-11-26 20:04:09.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.564722 --> 602.508838).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 624.371887  [    1/ 1184]\n",
      "train loss: 612.034973  [  101/ 1184]\n",
      "train loss: 597.735596  [  201/ 1184]\n",
      "train loss: 596.360718  [  301/ 1184]\n",
      "train loss: 598.332275  [  401/ 1184]\n",
      "train loss: 561.049683  [  501/ 1184]\n",
      "train loss: 643.933716  [  601/ 1184]\n",
      "train loss: 608.416687  [  701/ 1184]\n",
      "train loss: 601.873840  [  801/ 1184]\n",
      "train loss: 605.429199  [  901/ 1184]\n",
      "train loss: 566.781921  [ 1001/ 1184]\n",
      "train loss: 605.759949  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:04:28.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:04:28.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:04:31.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:04:31.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [620.0289916992188, 643.8407592773438, 552.2201538085938, 600.81201171875, 578.5267333984375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:04:31.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.450830078125 is higher than -602.5088375043265, setting new best score to -602.450830078125\u001b[0m\n",
      "\u001b[32m2023-11-26 20:04:31.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.508838 --> 602.450830).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 571.323669  [    1/ 1184]\n",
      "train loss: 624.128906  [  101/ 1184]\n",
      "train loss: 645.632324  [  201/ 1184]\n",
      "train loss: 647.173340  [  301/ 1184]\n",
      "train loss: 625.637268  [  401/ 1184]\n",
      "train loss: 605.016541  [  501/ 1184]\n",
      "train loss: 651.679321  [  601/ 1184]\n",
      "train loss: 655.740356  [  701/ 1184]\n",
      "train loss: 597.069519  [  801/ 1184]\n",
      "train loss: 640.824463  [  901/ 1184]\n",
      "train loss: 585.607727  [ 1001/ 1184]\n",
      "train loss: 529.184570  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:04:46.329\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:04:46.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:04:48.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:04:48.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.9903564453125, 643.7772216796875, 552.2855834960938, 600.8472900390625, 578.4695434570312]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:04:48.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.4081203026108 is higher than -602.450830078125, setting new best score to -602.4081203026108\u001b[0m\n",
      "\u001b[32m2023-11-26 20:04:48.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.450830 --> 602.408120).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 560.365356  [    1/ 1184]\n",
      "train loss: 547.938599  [  101/ 1184]\n",
      "train loss: 614.771179  [  201/ 1184]\n",
      "train loss: 616.553345  [  301/ 1184]\n",
      "train loss: 616.797058  [  401/ 1184]\n",
      "train loss: 580.166931  [  501/ 1184]\n",
      "train loss: 596.430359  [  601/ 1184]\n",
      "train loss: 567.802551  [  701/ 1184]\n",
      "train loss: 640.308167  [  801/ 1184]\n",
      "train loss: 541.725098  [  901/ 1184]\n",
      "train loss: 601.582336  [ 1001/ 1184]\n",
      "train loss: 620.526489  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:05:07.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:05:07.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:05:10.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:05:10.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.954833984375, 643.6461181640625, 552.2755126953125, 600.8621826171875, 578.4891967773438]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:05:10.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.3465767775909 is higher than -602.4081203026108, setting new best score to -602.3465767775909\u001b[0m\n",
      "\u001b[32m2023-11-26 20:05:10.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.408120 --> 602.346577).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 642.012451  [    1/ 1184]\n",
      "train loss: 626.460510  [  101/ 1184]\n",
      "train loss: 579.912659  [  201/ 1184]\n",
      "train loss: 651.723572  [  301/ 1184]\n",
      "train loss: 661.464783  [  401/ 1184]\n",
      "train loss: 534.025757  [  501/ 1184]\n",
      "train loss: 595.349609  [  601/ 1184]\n",
      "train loss: 639.331787  [  701/ 1184]\n",
      "train loss: 590.929138  [  801/ 1184]\n",
      "train loss: 598.405640  [  901/ 1184]\n",
      "train loss: 650.337280  [ 1001/ 1184]\n",
      "train loss: 546.129517  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:05:26.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:05:26.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:05:28.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:05:28.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.8124389648438, 643.6130981445312, 552.3031616210938, 600.8143310546875, 578.3648681640625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:05:28.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.3006696870056 is higher than -602.3465767775909, setting new best score to -602.3006696870056\u001b[0m\n",
      "\u001b[32m2023-11-26 20:05:28.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.346577 --> 602.300670).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 612.204041  [    1/ 1184]\n",
      "train loss: 589.839905  [  101/ 1184]\n",
      "train loss: 574.143555  [  201/ 1184]\n",
      "train loss: 652.822510  [  301/ 1184]\n",
      "train loss: 618.412170  [  401/ 1184]\n",
      "train loss: 669.342957  [  501/ 1184]\n",
      "train loss: 647.462524  [  601/ 1184]\n",
      "train loss: 652.806580  [  701/ 1184]\n",
      "train loss: 663.659058  [  801/ 1184]\n",
      "train loss: 573.829224  [  901/ 1184]\n",
      "train loss: 614.851685  [ 1001/ 1184]\n",
      "train loss: 624.994751  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:05:44.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:05:44.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:05:46.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:05:46.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.8138427734375, 643.6824951171875, 552.276611328125, 600.77880859375, 578.3555908203125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:05:46.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.2863944910749 is higher than -602.3006696870056, setting new best score to -602.2863944910749\u001b[0m\n",
      "\u001b[32m2023-11-26 20:05:46.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.300670 --> 602.286394).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 584.510742  [    1/ 1184]\n",
      "train loss: 616.358521  [  101/ 1184]\n",
      "train loss: 566.124451  [  201/ 1184]\n",
      "train loss: 579.897034  [  301/ 1184]\n",
      "train loss: 637.368042  [  401/ 1184]\n",
      "train loss: 639.558228  [  501/ 1184]\n",
      "train loss: 566.175232  [  601/ 1184]\n",
      "train loss: 570.399292  [  701/ 1184]\n",
      "train loss: 607.465637  [  801/ 1184]\n",
      "train loss: 634.448120  [  901/ 1184]\n",
      "train loss: 614.135498  [ 1001/ 1184]\n",
      "train loss: 647.477722  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:06:00.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:00.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:02.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:03.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.7346801757812, 643.6054077148438, 552.19189453125, 600.75634765625, 578.3450927734375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:03.001\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.207123652591 is higher than -602.2863944910749, setting new best score to -602.207123652591\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:03.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.286394 --> 602.207124).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 564.348938  [    1/ 1184]\n",
      "train loss: 602.558472  [  101/ 1184]\n",
      "train loss: 637.140015  [  201/ 1184]\n",
      "train loss: 610.409973  [  301/ 1184]\n",
      "train loss: 606.311523  [  401/ 1184]\n",
      "train loss: 476.425873  [  501/ 1184]\n",
      "train loss: 569.498840  [  601/ 1184]\n",
      "train loss: 654.946045  [  701/ 1184]\n",
      "train loss: 578.947754  [  801/ 1184]\n",
      "train loss: 551.951904  [  901/ 1184]\n",
      "train loss: 636.196655  [ 1001/ 1184]\n",
      "train loss: 599.732361  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:06:17.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:17.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:19.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:19.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.7384033203125, 643.5686645507812, 552.1845703125, 600.777587890625, 578.3250732421875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:19.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -602.2074900180479 is lower than -602.207123652591, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:19.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 644.180237  [    1/ 1184]\n",
      "train loss: 644.311951  [  101/ 1184]\n",
      "train loss: 604.055664  [  201/ 1184]\n",
      "train loss: 663.145752  [  301/ 1184]\n",
      "train loss: 600.515137  [  401/ 1184]\n",
      "train loss: 544.454651  [  501/ 1184]\n",
      "train loss: 591.587402  [  601/ 1184]\n",
      "train loss: 609.826904  [  701/ 1184]\n",
      "train loss: 614.371155  [  801/ 1184]\n",
      "train loss: 587.986511  [  901/ 1184]\n",
      "train loss: 579.169067  [ 1001/ 1184]\n",
      "train loss: 574.319458  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:06:34.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:34.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:36.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:36.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.6318359375, 643.453125, 552.104736328125, 600.605712890625, 578.3009033203125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:36.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.1317325640329 is higher than -602.207123652591, setting new best score to -602.1317325640329\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:36.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.207124 --> 602.131733).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 594.414490  [    1/ 1184]\n",
      "train loss: 589.472778  [  101/ 1184]\n",
      "train loss: 597.960510  [  201/ 1184]\n",
      "train loss: 649.509827  [  301/ 1184]\n",
      "train loss: 517.927551  [  401/ 1184]\n",
      "train loss: 606.956909  [  501/ 1184]\n",
      "train loss: 608.307983  [  601/ 1184]\n",
      "train loss: 561.886902  [  701/ 1184]\n",
      "train loss: 622.825439  [  801/ 1184]\n",
      "train loss: 622.418274  [  901/ 1184]\n",
      "train loss: 607.015015  [ 1001/ 1184]\n",
      "train loss: 566.156799  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:06:50.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:50.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:52.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:52.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.64111328125, 643.4227905273438, 552.0675048828125, 600.5565795898438, 578.32568359375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:52.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.1083572580844 is higher than -602.1317325640329, setting new best score to -602.1083572580844\u001b[0m\n",
      "\u001b[32m2023-11-26 20:06:52.894\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.131733 --> 602.108357).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 588.575439  [    1/ 1184]\n",
      "train loss: 653.809631  [  101/ 1184]\n",
      "train loss: 583.881958  [  201/ 1184]\n",
      "train loss: 615.322937  [  301/ 1184]\n",
      "train loss: 593.956848  [  401/ 1184]\n",
      "train loss: 622.101746  [  501/ 1184]\n",
      "train loss: 618.113098  [  601/ 1184]\n",
      "train loss: 574.836548  [  701/ 1184]\n",
      "train loss: 604.433594  [  801/ 1184]\n",
      "train loss: 656.450073  [  901/ 1184]\n",
      "train loss: 602.029358  [ 1001/ 1184]\n",
      "train loss: 640.934204  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:07:07.037\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:07.038\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:09.009\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:09.010\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.625244140625, 643.3388061523438, 552.05029296875, 600.5816040039062, 578.3009033203125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:09.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.091975653926 is higher than -602.1083572580844, setting new best score to -602.091975653926\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:09.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.108357 --> 602.091976).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 568.050476  [    1/ 1184]\n",
      "train loss: 615.641541  [  101/ 1184]\n",
      "train loss: 614.739868  [  201/ 1184]\n",
      "train loss: 651.622131  [  301/ 1184]\n",
      "train loss: 568.697937  [  401/ 1184]\n",
      "train loss: 605.705444  [  501/ 1184]\n",
      "train loss: 619.342773  [  601/ 1184]\n",
      "train loss: 564.892517  [  701/ 1184]\n",
      "train loss: 552.553589  [  801/ 1184]\n",
      "train loss: 594.803833  [  901/ 1184]\n",
      "train loss: 651.839783  [ 1001/ 1184]\n",
      "train loss: 583.205994  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:07:22.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:22.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:24.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:24.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.539306640625, 643.3614501953125, 552.0487060546875, 600.491943359375, 578.2403564453125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:24.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.0159839485265 is higher than -602.091975653926, setting new best score to -602.0159839485265\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:24.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.091976 --> 602.015984).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 604.635498  [    1/ 1184]\n",
      "train loss: 582.447144  [  101/ 1184]\n",
      "train loss: 608.167480  [  201/ 1184]\n",
      "train loss: 628.749573  [  301/ 1184]\n",
      "train loss: 593.622437  [  401/ 1184]\n",
      "train loss: 601.196777  [  501/ 1184]\n",
      "train loss: 618.995850  [  601/ 1184]\n",
      "train loss: 591.087097  [  701/ 1184]\n",
      "train loss: 607.180420  [  801/ 1184]\n",
      "train loss: 584.381592  [  901/ 1184]\n",
      "train loss: 563.347290  [ 1001/ 1184]\n",
      "train loss: 655.948364  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:07:38.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:38.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:40.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:40.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.49755859375, 643.2472534179688, 551.87939453125, 600.437255859375, 578.065673828125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:40.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.9433814712718 is higher than -602.0159839485265, setting new best score to -601.9433814712718\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:40.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.015984 --> 601.943381).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 566.658203  [    1/ 1184]\n",
      "train loss: 597.567078  [  101/ 1184]\n",
      "train loss: 674.281128  [  201/ 1184]\n",
      "train loss: 646.474915  [  301/ 1184]\n",
      "train loss: 579.540466  [  401/ 1184]\n",
      "train loss: 539.176025  [  501/ 1184]\n",
      "train loss: 614.288513  [  601/ 1184]\n",
      "train loss: 571.860107  [  701/ 1184]\n",
      "train loss: 584.967651  [  801/ 1184]\n",
      "train loss: 622.469849  [  901/ 1184]\n",
      "train loss: 618.786743  [ 1001/ 1184]\n",
      "train loss: 631.320557  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:07:54.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:54.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:56.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:56.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.4259643554688, 643.2128295898438, 551.9232177734375, 600.348388671875, 578.038330078125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:56.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.9276384957229 is higher than -601.9433814712718, setting new best score to -601.9276384957229\u001b[0m\n",
      "\u001b[32m2023-11-26 20:07:56.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.943381 --> 601.927638).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 629.092773  [    1/ 1184]\n",
      "train loss: 636.157593  [  101/ 1184]\n",
      "train loss: 585.084961  [  201/ 1184]\n",
      "train loss: 593.628357  [  301/ 1184]\n",
      "train loss: 632.028992  [  401/ 1184]\n",
      "train loss: 611.837830  [  501/ 1184]\n",
      "train loss: 565.477539  [  601/ 1184]\n",
      "train loss: 641.799805  [  701/ 1184]\n",
      "train loss: 610.278870  [  801/ 1184]\n",
      "train loss: 574.930298  [  901/ 1184]\n",
      "train loss: 756.905518  [ 1001/ 1184]\n",
      "train loss: 568.954590  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:08:10.852\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:08:10.853\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:08:12.756\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:08:12.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.424560546875, 643.1881103515625, 551.8499755859375, 600.343994140625, 578.0869750976562]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:08:12.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.8908367688143 is higher than -601.9276384957229, setting new best score to -601.8908367688143\u001b[0m\n",
      "\u001b[32m2023-11-26 20:08:12.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.927638 --> 601.890837).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 565.495544  [    1/ 1184]\n",
      "train loss: 590.841797  [  101/ 1184]\n",
      "train loss: 645.223389  [  201/ 1184]\n",
      "train loss: 565.403076  [  301/ 1184]\n",
      "train loss: 550.899414  [  401/ 1184]\n",
      "train loss: 660.774048  [  501/ 1184]\n",
      "train loss: 576.447998  [  601/ 1184]\n",
      "train loss: 569.851257  [  701/ 1184]\n",
      "train loss: 544.339600  [  801/ 1184]\n",
      "train loss: 651.222900  [  901/ 1184]\n",
      "train loss: 581.992065  [ 1001/ 1184]\n",
      "train loss: 589.687927  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:08:28.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:08:28.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:08:30.304\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:08:30.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.447998046875, 643.0253295898438, 551.75537109375, 600.267822265625, 578.1013793945312]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:08:30.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.8703944725327 is higher than -601.8908367688143, setting new best score to -601.8703944725327\u001b[0m\n",
      "\u001b[32m2023-11-26 20:08:30.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.890837 --> 601.870394).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 561.824585  [    1/ 1184]\n",
      "train loss: 588.146973  [  101/ 1184]\n",
      "train loss: 601.893005  [  201/ 1184]\n",
      "train loss: 521.636047  [  301/ 1184]\n",
      "train loss: 624.694397  [  401/ 1184]\n",
      "train loss: 571.524109  [  501/ 1184]\n",
      "train loss: 601.879761  [  601/ 1184]\n",
      "train loss: 641.239014  [  701/ 1184]\n",
      "train loss: 630.969788  [  801/ 1184]\n",
      "train loss: 623.919189  [  901/ 1184]\n",
      "train loss: 650.049011  [ 1001/ 1184]\n",
      "train loss: 594.015320  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:08:44.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:08:44.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:08:46.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:08:46.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.3640747070312, 642.9432373046875, 551.66748046875, 600.3052978515625, 578.065673828125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:08:46.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.8229536998122 is higher than -601.8703944725327, setting new best score to -601.8229536998122\u001b[0m\n",
      "\u001b[32m2023-11-26 20:08:46.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.870394 --> 601.822954).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 599.925903  [    1/ 1184]\n",
      "train loss: 672.882996  [  101/ 1184]\n",
      "train loss: 720.408569  [  201/ 1184]\n",
      "train loss: 666.255493  [  301/ 1184]\n",
      "train loss: 581.702026  [  401/ 1184]\n",
      "train loss: 605.936829  [  501/ 1184]\n",
      "train loss: 591.713135  [  601/ 1184]\n",
      "train loss: 623.217834  [  701/ 1184]\n",
      "train loss: 639.317749  [  801/ 1184]\n",
      "train loss: 564.085327  [  901/ 1184]\n",
      "train loss: 651.542969  [ 1001/ 1184]\n",
      "train loss: 647.969360  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:09:01.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:01.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:03.758\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:03.759\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.3671875, 642.9219360351562, 551.6494750976562, 600.21875, 577.994384765625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:03.760\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.7860636650762 is higher than -601.8229536998122, setting new best score to -601.7860636650762\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:03.763\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.822954 --> 601.786064).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 569.139282  [    1/ 1184]\n",
      "train loss: 631.474976  [  101/ 1184]\n",
      "train loss: 628.456909  [  201/ 1184]\n",
      "train loss: 514.919983  [  301/ 1184]\n",
      "train loss: 593.941040  [  401/ 1184]\n",
      "train loss: 563.533569  [  501/ 1184]\n",
      "train loss: 605.685974  [  601/ 1184]\n",
      "train loss: 566.082764  [  701/ 1184]\n",
      "train loss: 644.842957  [  801/ 1184]\n",
      "train loss: 534.141235  [  901/ 1184]\n",
      "train loss: 619.329163  [ 1001/ 1184]\n",
      "train loss: 597.451721  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:09:17.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:17.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:19.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:19.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.3170166015625, 642.8175048828125, 551.5598754882812, 600.1421508789062, 577.838134765625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:19.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.714493686338 is higher than -601.7860636650762, setting new best score to -601.714493686338\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:19.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.786064 --> 601.714494).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 535.851624  [    1/ 1184]\n",
      "train loss: 617.614563  [  101/ 1184]\n",
      "train loss: 621.343811  [  201/ 1184]\n",
      "train loss: 640.721191  [  301/ 1184]\n",
      "train loss: 570.019409  [  401/ 1184]\n",
      "train loss: 640.653076  [  501/ 1184]\n",
      "train loss: 603.156677  [  601/ 1184]\n",
      "train loss: 572.552124  [  701/ 1184]\n",
      "train loss: 597.247009  [  801/ 1184]\n",
      "train loss: 576.314392  [  901/ 1184]\n",
      "train loss: 636.755798  [ 1001/ 1184]\n",
      "train loss: 602.285889  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:09:34.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:34.945\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:37.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:37.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.4016723632812, 642.8348999023438, 551.5399169921875, 600.0606689453125, 577.8461303710938]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:37.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.6908910051177 is higher than -601.714493686338, setting new best score to -601.6908910051177\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:37.352\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.714494 --> 601.690891).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 560.088684  [    1/ 1184]\n",
      "train loss: 624.474243  [  101/ 1184]\n",
      "train loss: 650.738037  [  201/ 1184]\n",
      "train loss: 485.779144  [  301/ 1184]\n",
      "train loss: 595.727051  [  401/ 1184]\n",
      "train loss: 600.543335  [  501/ 1184]\n",
      "train loss: 603.228760  [  601/ 1184]\n",
      "train loss: 599.107788  [  701/ 1184]\n",
      "train loss: 613.127502  [  801/ 1184]\n",
      "train loss: 660.681274  [  901/ 1184]\n",
      "train loss: 621.601379  [ 1001/ 1184]\n",
      "train loss: 639.742126  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:09:53.078\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:53.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:55.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:55.065\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.2672729492188, 642.704833984375, 551.5133666992188, 600.0646362304688, 577.6997680664062]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:55.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.6416350159463 is higher than -601.6908910051177, setting new best score to -601.6416350159463\u001b[0m\n",
      "\u001b[32m2023-11-26 20:09:55.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.690891 --> 601.641635).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 650.527649  [    1/ 1184]\n",
      "train loss: 711.649109  [  101/ 1184]\n",
      "train loss: 616.832092  [  201/ 1184]\n",
      "train loss: 586.341736  [  301/ 1184]\n",
      "train loss: 622.903625  [  401/ 1184]\n",
      "train loss: 650.085876  [  501/ 1184]\n",
      "train loss: 661.305664  [  601/ 1184]\n",
      "train loss: 616.494324  [  701/ 1184]\n",
      "train loss: 676.526245  [  801/ 1184]\n",
      "train loss: 656.085815  [  901/ 1184]\n",
      "train loss: 614.693359  [ 1001/ 1184]\n",
      "train loss: 680.427368  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:10:09.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:10:09.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:10:11.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:10:11.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.2940673828125, 642.6078491210938, 551.47216796875, 599.9365844726562, 577.68115234375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:10:11.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.5891848793513 is higher than -601.6416350159463, setting new best score to -601.5891848793513\u001b[0m\n",
      "\u001b[32m2023-11-26 20:10:11.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.641635 --> 601.589185).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 609.478333  [    1/ 1184]\n",
      "train loss: 668.205017  [  101/ 1184]\n",
      "train loss: 546.651123  [  201/ 1184]\n",
      "train loss: 625.565552  [  301/ 1184]\n",
      "train loss: 670.526062  [  401/ 1184]\n",
      "train loss: 600.566467  [  501/ 1184]\n",
      "train loss: 579.594299  [  601/ 1184]\n",
      "train loss: 546.038025  [  701/ 1184]\n",
      "train loss: 628.911194  [  801/ 1184]\n",
      "train loss: 589.091492  [  901/ 1184]\n",
      "train loss: 566.936523  [ 1001/ 1184]\n",
      "train loss: 627.556396  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:10:26.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:10:26.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:10:28.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:10:28.055\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.2459716796875, 642.5487670898438, 551.4378662109375, 599.9242553710938, 577.7168579101562]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:10:28.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.55509566295 is higher than -601.5891848793513, setting new best score to -601.55509566295\u001b[0m\n",
      "\u001b[32m2023-11-26 20:10:28.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.589185 --> 601.555096).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 565.187012  [    1/ 1184]\n",
      "train loss: 656.698303  [  101/ 1184]\n",
      "train loss: 678.362427  [  201/ 1184]\n",
      "train loss: 606.285400  [  301/ 1184]\n",
      "train loss: 530.087830  [  401/ 1184]\n",
      "train loss: 659.602051  [  501/ 1184]\n",
      "train loss: 569.008911  [  601/ 1184]\n",
      "train loss: 565.856995  [  701/ 1184]\n",
      "train loss: 641.622803  [  801/ 1184]\n",
      "train loss: 631.875305  [  901/ 1184]\n",
      "train loss: 577.390320  [ 1001/ 1184]\n",
      "train loss: 599.253784  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:10:43.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:10:43.330\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:10:45.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:10:45.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.234130859375, 642.4091186523438, 551.3308715820312, 599.8717041015625, 577.646728515625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:10:45.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.5122010822538 is higher than -601.55509566295, setting new best score to -601.5122010822538\u001b[0m\n",
      "\u001b[32m2023-11-26 20:10:45.573\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.555096 --> 601.512201).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 600.514404  [    1/ 1184]\n",
      "train loss: 628.553650  [  101/ 1184]\n",
      "train loss: 656.898499  [  201/ 1184]\n",
      "train loss: 618.908142  [  301/ 1184]\n",
      "train loss: 592.797241  [  401/ 1184]\n",
      "train loss: 505.591644  [  501/ 1184]\n",
      "train loss: 610.750488  [  601/ 1184]\n",
      "train loss: 606.480835  [  701/ 1184]\n",
      "train loss: 573.417603  [  801/ 1184]\n",
      "train loss: 628.685486  [  901/ 1184]\n",
      "train loss: 581.686157  [ 1001/ 1184]\n",
      "train loss: 677.317261  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:11:00.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:00.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:02.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:02.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.2386474609375, 642.478271484375, 551.330078125, 599.9068603515625, 577.6671752929688]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:02.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.5056705523141 is higher than -601.5122010822538, setting new best score to -601.5056705523141\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:02.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.512201 --> 601.505671).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 582.433777  [    1/ 1184]\n",
      "train loss: 551.685364  [  101/ 1184]\n",
      "train loss: 567.843750  [  201/ 1184]\n",
      "train loss: 572.837830  [  301/ 1184]\n",
      "train loss: 644.071411  [  401/ 1184]\n",
      "train loss: 624.593201  [  501/ 1184]\n",
      "train loss: 589.559692  [  601/ 1184]\n",
      "train loss: 609.484558  [  701/ 1184]\n",
      "train loss: 659.238770  [  801/ 1184]\n",
      "train loss: 610.972778  [  901/ 1184]\n",
      "train loss: 609.799683  [ 1001/ 1184]\n",
      "train loss: 567.147461  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:11:15.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:15.809\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:17.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:17.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.1315307617188, 642.3924560546875, 551.2699584960938, 599.854736328125, 577.5713500976562]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:17.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.4594854813588 is higher than -601.5056705523141, setting new best score to -601.4594854813588\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:17.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.505671 --> 601.459485).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 636.437683  [    1/ 1184]\n",
      "train loss: 631.563599  [  101/ 1184]\n",
      "train loss: 606.842651  [  201/ 1184]\n",
      "train loss: 638.590393  [  301/ 1184]\n",
      "train loss: 538.297607  [  401/ 1184]\n",
      "train loss: 549.504395  [  501/ 1184]\n",
      "train loss: 681.686646  [  601/ 1184]\n",
      "train loss: 538.299805  [  701/ 1184]\n",
      "train loss: 536.570068  [  801/ 1184]\n",
      "train loss: 651.680115  [  901/ 1184]\n",
      "train loss: 629.354004  [ 1001/ 1184]\n",
      "train loss: 634.531433  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:11:31.865\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:31.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:33.876\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:33.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.178466796875, 642.3038330078125, 551.25537109375, 599.7860717773438, 577.448974609375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:33.877\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.4119985846024 is higher than -601.4594854813588, setting new best score to -601.4119985846024\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:33.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.459485 --> 601.411999).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 623.742249  [    1/ 1184]\n",
      "train loss: 641.913696  [  101/ 1184]\n",
      "train loss: 696.514221  [  201/ 1184]\n",
      "train loss: 591.030396  [  301/ 1184]\n",
      "train loss: 611.490662  [  401/ 1184]\n",
      "train loss: 585.428223  [  501/ 1184]\n",
      "train loss: 638.772461  [  601/ 1184]\n",
      "train loss: 600.375610  [  701/ 1184]\n",
      "train loss: 655.775269  [  801/ 1184]\n",
      "train loss: 569.584534  [  901/ 1184]\n",
      "train loss: 627.515320  [ 1001/ 1184]\n",
      "train loss: 613.146729  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:11:47.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:47.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:49.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:49.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.1737060546875, 642.3020629882812, 551.1788330078125, 599.6998291015625, 577.4639282226562]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:49.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.3786804971816 is higher than -601.4119985846024, setting new best score to -601.3786804971816\u001b[0m\n",
      "\u001b[32m2023-11-26 20:11:49.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.411999 --> 601.378680).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 599.911072  [    1/ 1184]\n",
      "train loss: 569.741760  [  101/ 1184]\n",
      "train loss: 603.194885  [  201/ 1184]\n",
      "train loss: 604.745178  [  301/ 1184]\n",
      "train loss: 550.210571  [  401/ 1184]\n",
      "train loss: 638.366760  [  501/ 1184]\n",
      "train loss: 625.120422  [  601/ 1184]\n",
      "train loss: 555.816345  [  701/ 1184]\n",
      "train loss: 669.611328  [  801/ 1184]\n",
      "train loss: 638.951904  [  901/ 1184]\n",
      "train loss: 599.444763  [ 1001/ 1184]\n",
      "train loss: 583.417236  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:12:03.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:03.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:05.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:05.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.1387939453125, 642.1738891601562, 551.1064453125, 599.694580078125, 577.39404296875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:05.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.3344768282733 is higher than -601.3786804971816, setting new best score to -601.3344768282733\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:05.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.378680 --> 601.334477).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 619.474243  [    1/ 1184]\n",
      "train loss: 589.926514  [  101/ 1184]\n",
      "train loss: 640.366333  [  201/ 1184]\n",
      "train loss: 644.878296  [  301/ 1184]\n",
      "train loss: 622.444214  [  401/ 1184]\n",
      "train loss: 685.151978  [  501/ 1184]\n",
      "train loss: 628.455444  [  601/ 1184]\n",
      "train loss: 641.101868  [  701/ 1184]\n",
      "train loss: 675.952087  [  801/ 1184]\n",
      "train loss: 546.717285  [  901/ 1184]\n",
      "train loss: 600.273499  [ 1001/ 1184]\n",
      "train loss: 617.156738  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:12:19.092\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:19.093\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:21.005\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:21.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.0017700195312, 642.005859375, 551.0645751953125, 599.5682983398438, 577.3019409179688]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:21.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.2727167443384 is higher than -601.3344768282733, setting new best score to -601.2727167443384\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:21.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.334477 --> 601.272717).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 580.126404  [    1/ 1184]\n",
      "train loss: 626.159729  [  101/ 1184]\n",
      "train loss: 544.192383  [  201/ 1184]\n",
      "train loss: 604.020691  [  301/ 1184]\n",
      "train loss: 606.240723  [  401/ 1184]\n",
      "train loss: 556.053650  [  501/ 1184]\n",
      "train loss: 575.646057  [  601/ 1184]\n",
      "train loss: 563.627502  [  701/ 1184]\n",
      "train loss: 637.016357  [  801/ 1184]\n",
      "train loss: 588.255676  [  901/ 1184]\n",
      "train loss: 618.039185  [ 1001/ 1184]\n",
      "train loss: 601.370300  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:12:35.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:35.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:37.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:37.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.1526489257812, 642.0214233398438, 551.085693359375, 599.5089721679688, 577.2743530273438]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:37.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.2485173865209 is higher than -601.2727167443384, setting new best score to -601.2485173865209\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:37.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.272717 --> 601.248517).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 606.990540  [    1/ 1184]\n",
      "train loss: 590.713379  [  101/ 1184]\n",
      "train loss: 568.125854  [  201/ 1184]\n",
      "train loss: 595.526611  [  301/ 1184]\n",
      "train loss: 600.830017  [  401/ 1184]\n",
      "train loss: 587.032837  [  501/ 1184]\n",
      "train loss: 596.405273  [  601/ 1184]\n",
      "train loss: 655.438354  [  701/ 1184]\n",
      "train loss: 632.170410  [  801/ 1184]\n",
      "train loss: 649.535767  [  901/ 1184]\n",
      "train loss: 569.576172  [ 1001/ 1184]\n",
      "train loss: 570.483521  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:12:51.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:51.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:53.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:53.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.0758056640625, 641.97509765625, 550.9647827148438, 599.5110473632812, 577.2155151367188]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:53.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.191996436783 is higher than -601.2485173865209, setting new best score to -601.191996436783\u001b[0m\n",
      "\u001b[32m2023-11-26 20:12:53.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.248517 --> 601.191996).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 592.583435  [    1/ 1184]\n",
      "train loss: 566.422852  [  101/ 1184]\n",
      "train loss: 569.782532  [  201/ 1184]\n",
      "train loss: 546.223022  [  301/ 1184]\n",
      "train loss: 550.804077  [  401/ 1184]\n",
      "train loss: 557.123901  [  501/ 1184]\n",
      "train loss: 630.735229  [  601/ 1184]\n",
      "train loss: 685.212219  [  701/ 1184]\n",
      "train loss: 645.728821  [  801/ 1184]\n",
      "train loss: 600.641663  [  901/ 1184]\n",
      "train loss: 537.716675  [ 1001/ 1184]\n",
      "train loss: 577.048889  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:13:07.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:07.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:09.637\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:09.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.1229248046875, 641.9067993164062, 550.9080810546875, 599.3746337890625, 577.1749267578125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:09.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.1438186838657 is higher than -601.191996436783, setting new best score to -601.1438186838657\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:09.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.191996 --> 601.143819).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 521.549133  [    1/ 1184]\n",
      "train loss: 595.139771  [  101/ 1184]\n",
      "train loss: 571.444702  [  201/ 1184]\n",
      "train loss: 596.392822  [  301/ 1184]\n",
      "train loss: 606.774536  [  401/ 1184]\n",
      "train loss: 596.908936  [  501/ 1184]\n",
      "train loss: 609.354248  [  601/ 1184]\n",
      "train loss: 578.441284  [  701/ 1184]\n",
      "train loss: 628.797485  [  801/ 1184]\n",
      "train loss: 647.187744  [  901/ 1184]\n",
      "train loss: 586.174683  [ 1001/ 1184]\n",
      "train loss: 627.590210  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:13:23.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:23.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:25.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:25.622\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.0574340820312, 641.8395385742188, 550.81201171875, 599.4047241210938, 577.101318359375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:25.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.08997393258 is higher than -601.1438186838657, setting new best score to -601.08997393258\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:25.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.143819 --> 601.089974).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 613.973877  [    1/ 1184]\n",
      "train loss: 603.302856  [  101/ 1184]\n",
      "train loss: 578.767212  [  201/ 1184]\n",
      "train loss: 587.560608  [  301/ 1184]\n",
      "train loss: 606.878906  [  401/ 1184]\n",
      "train loss: 594.228394  [  501/ 1184]\n",
      "train loss: 647.107849  [  601/ 1184]\n",
      "train loss: 588.909973  [  701/ 1184]\n",
      "train loss: 570.238831  [  801/ 1184]\n",
      "train loss: 591.922668  [  901/ 1184]\n",
      "train loss: 559.546143  [ 1001/ 1184]\n",
      "train loss: 604.267639  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:13:39.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:39.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:41.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:41.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.0172119140625, 641.8317260742188, 550.8363037109375, 599.258544921875, 577.0340576171875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:41.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.0455893214745 is higher than -601.08997393258, setting new best score to -601.0455893214745\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:41.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.089974 --> 601.045589).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 531.513062  [    1/ 1184]\n",
      "train loss: 626.581421  [  101/ 1184]\n",
      "train loss: 575.388367  [  201/ 1184]\n",
      "train loss: 612.304626  [  301/ 1184]\n",
      "train loss: 603.858521  [  401/ 1184]\n",
      "train loss: 635.942505  [  501/ 1184]\n",
      "train loss: 635.652527  [  601/ 1184]\n",
      "train loss: 582.326843  [  701/ 1184]\n",
      "train loss: 611.636841  [  801/ 1184]\n",
      "train loss: 565.047363  [  901/ 1184]\n",
      "train loss: 619.654053  [ 1001/ 1184]\n",
      "train loss: 632.954163  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:13:55.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:55.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:57.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:57.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.9526977539062, 641.6842651367188, 550.7291870117188, 599.2417602539062, 577.0137939453125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:57.627\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.9889385754549 is higher than -601.0455893214745, setting new best score to -600.9889385754549\u001b[0m\n",
      "\u001b[32m2023-11-26 20:13:57.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.045589 --> 600.988939).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 586.737061  [    1/ 1184]\n",
      "train loss: 604.795288  [  101/ 1184]\n",
      "train loss: 542.781738  [  201/ 1184]\n",
      "train loss: 618.955139  [  301/ 1184]\n",
      "train loss: 628.852661  [  401/ 1184]\n",
      "train loss: 616.835938  [  501/ 1184]\n",
      "train loss: 620.811707  [  601/ 1184]\n",
      "train loss: 615.859131  [  701/ 1184]\n",
      "train loss: 590.741394  [  801/ 1184]\n",
      "train loss: 622.963440  [  901/ 1184]\n",
      "train loss: 628.952087  [ 1001/ 1184]\n",
      "train loss: 600.591797  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:14:11.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:14:11.182\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:14:13.028\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:14:13.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.03857421875, 641.675537109375, 550.69287109375, 599.1181640625, 576.9763793945312]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:14:13.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.9314837878263 is higher than -600.9889385754549, setting new best score to -600.9314837878263\u001b[0m\n",
      "\u001b[32m2023-11-26 20:14:13.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.988939 --> 600.931484).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 596.507812  [    1/ 1184]\n",
      "train loss: 604.917725  [  101/ 1184]\n",
      "train loss: 569.475464  [  201/ 1184]\n",
      "train loss: 642.623901  [  301/ 1184]\n",
      "train loss: 584.985046  [  401/ 1184]\n",
      "train loss: 612.767517  [  501/ 1184]\n",
      "train loss: 630.260864  [  601/ 1184]\n",
      "train loss: 637.232178  [  701/ 1184]\n",
      "train loss: 614.440002  [  801/ 1184]\n",
      "train loss: 537.953857  [  901/ 1184]\n",
      "train loss: 636.505798  [ 1001/ 1184]\n",
      "train loss: 650.908997  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:14:26.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:14:26.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:14:28.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:14:28.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.8834228515625, 641.64599609375, 550.6043701171875, 599.0848388671875, 576.83642578125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:14:28.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.8652573211284 is higher than -600.9314837878263, setting new best score to -600.8652573211284\u001b[0m\n",
      "\u001b[32m2023-11-26 20:14:28.734\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.931484 --> 600.865257).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 636.757751  [    1/ 1184]\n",
      "train loss: 604.905212  [  101/ 1184]\n",
      "train loss: 601.387329  [  201/ 1184]\n",
      "train loss: 577.776489  [  301/ 1184]\n",
      "train loss: 635.992676  [  401/ 1184]\n",
      "train loss: 666.138306  [  501/ 1184]\n",
      "train loss: 529.397217  [  601/ 1184]\n",
      "train loss: 607.728088  [  701/ 1184]\n",
      "train loss: 616.630432  [  801/ 1184]\n",
      "train loss: 584.273560  [  901/ 1184]\n",
      "train loss: 573.032532  [ 1001/ 1184]\n",
      "train loss: 634.754395  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:14:42.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:14:42.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:14:44.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:14:44.715\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.798583984375, 641.578125, 550.563720703125, 599.0237426757812, 576.8523559570312]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:14:44.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.8076426059384 is higher than -600.8652573211284, setting new best score to -600.8076426059384\u001b[0m\n",
      "\u001b[32m2023-11-26 20:14:44.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.865257 --> 600.807643).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 634.971191  [    1/ 1184]\n",
      "train loss: 580.931091  [  101/ 1184]\n",
      "train loss: 635.192627  [  201/ 1184]\n",
      "train loss: 614.389587  [  301/ 1184]\n",
      "train loss: 607.665894  [  401/ 1184]\n",
      "train loss: 608.162048  [  501/ 1184]\n",
      "train loss: 586.860046  [  601/ 1184]\n",
      "train loss: 646.239990  [  701/ 1184]\n",
      "train loss: 662.762390  [  801/ 1184]\n",
      "train loss: 630.004517  [  901/ 1184]\n",
      "train loss: 619.053223  [ 1001/ 1184]\n",
      "train loss: 571.934937  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:14:58.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:14:58.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:00.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:00.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.7882690429688, 641.5430908203125, 550.4249267578125, 598.9034423828125, 576.7764282226562]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:00.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.7785671572142 is higher than -600.8076426059384, setting new best score to -600.7785671572142\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:00.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.807643 --> 600.778567).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 600.984009  [    1/ 1184]\n",
      "train loss: 644.460266  [  101/ 1184]\n",
      "train loss: 679.577820  [  201/ 1184]\n",
      "train loss: 595.663391  [  301/ 1184]\n",
      "train loss: 641.823425  [  401/ 1184]\n",
      "train loss: 599.733215  [  501/ 1184]\n",
      "train loss: 615.140503  [  601/ 1184]\n",
      "train loss: 597.363586  [  701/ 1184]\n",
      "train loss: 643.683716  [  801/ 1184]\n",
      "train loss: 585.094604  [  901/ 1184]\n",
      "train loss: 595.521301  [ 1001/ 1184]\n",
      "train loss: 604.104797  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:15:14.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:14.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:15.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:15.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.8245849609375, 641.4207763671875, 550.3572998046875, 598.8921508789062, 576.7159423828125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:15.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.7305005037332 is higher than -600.7785671572142, setting new best score to -600.7305005037332\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:15.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.778567 --> 600.730501).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 544.108704  [    1/ 1184]\n",
      "train loss: 600.744568  [  101/ 1184]\n",
      "train loss: 642.603394  [  201/ 1184]\n",
      "train loss: 574.722290  [  301/ 1184]\n",
      "train loss: 597.073547  [  401/ 1184]\n",
      "train loss: 654.585938  [  501/ 1184]\n",
      "train loss: 636.666260  [  601/ 1184]\n",
      "train loss: 548.102905  [  701/ 1184]\n",
      "train loss: 563.883362  [  801/ 1184]\n",
      "train loss: 628.339478  [  901/ 1184]\n",
      "train loss: 603.553223  [ 1001/ 1184]\n",
      "train loss: 640.837036  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:15:30.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:30.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:32.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:32.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.7124633789062, 641.4151611328125, 550.418212890625, 598.8717041015625, 576.5694580078125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:32.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.6906183556665 is higher than -600.7305005037332, setting new best score to -600.6906183556665\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:32.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.730501 --> 600.690618).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 571.318726  [    1/ 1184]\n",
      "train loss: 600.629700  [  101/ 1184]\n",
      "train loss: 625.951050  [  201/ 1184]\n",
      "train loss: 685.633789  [  301/ 1184]\n",
      "train loss: 622.752380  [  401/ 1184]\n",
      "train loss: 616.318359  [  501/ 1184]\n",
      "train loss: 639.382202  [  601/ 1184]\n",
      "train loss: 572.594238  [  701/ 1184]\n",
      "train loss: 596.185303  [  801/ 1184]\n",
      "train loss: 632.907410  [  901/ 1184]\n",
      "train loss: 627.037476  [ 1001/ 1184]\n",
      "train loss: 639.503845  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:15:46.096\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:46.097\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:48.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:48.075\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.5628051757812, 641.4105834960938, 550.3147583007812, 598.807861328125, 576.541015625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:48.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.6553917993473 is higher than -600.6906183556665, setting new best score to -600.6553917993473\u001b[0m\n",
      "\u001b[32m2023-11-26 20:15:48.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.690618 --> 600.655392).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 579.801453  [    1/ 1184]\n",
      "train loss: 602.126709  [  101/ 1184]\n",
      "train loss: 649.098389  [  201/ 1184]\n",
      "train loss: 585.684204  [  301/ 1184]\n",
      "train loss: 631.457947  [  401/ 1184]\n",
      "train loss: 610.412659  [  501/ 1184]\n",
      "train loss: 546.795532  [  601/ 1184]\n",
      "train loss: 625.222351  [  701/ 1184]\n",
      "train loss: 570.392700  [  801/ 1184]\n",
      "train loss: 593.988586  [  901/ 1184]\n",
      "train loss: 642.223145  [ 1001/ 1184]\n",
      "train loss: 607.396179  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:16:01.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:01.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:03.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:03.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.534912109375, 641.3167724609375, 550.2776489257812, 598.7161865234375, 576.462646484375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:03.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.6227471073971 is higher than -600.6553917993473, setting new best score to -600.6227471073971\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:03.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.655392 --> 600.622747).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 619.187500  [    1/ 1184]\n",
      "train loss: 669.087463  [  101/ 1184]\n",
      "train loss: 633.765259  [  201/ 1184]\n",
      "train loss: 595.805725  [  301/ 1184]\n",
      "train loss: 566.413574  [  401/ 1184]\n",
      "train loss: 577.763245  [  501/ 1184]\n",
      "train loss: 659.993286  [  601/ 1184]\n",
      "train loss: 633.445190  [  701/ 1184]\n",
      "train loss: 664.715881  [  801/ 1184]\n",
      "train loss: 590.492859  [  901/ 1184]\n",
      "train loss: 607.253235  [ 1001/ 1184]\n",
      "train loss: 605.847412  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:16:17.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:17.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:19.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:19.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.496337890625, 641.319580078125, 550.2105712890625, 598.5858764648438, 576.447021484375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:19.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.5863798117335 is higher than -600.6227471073971, setting new best score to -600.5863798117335\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:19.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.622747 --> 600.586380).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 611.800720  [    1/ 1184]\n",
      "train loss: 612.458252  [  101/ 1184]\n",
      "train loss: 572.291199  [  201/ 1184]\n",
      "train loss: 629.457458  [  301/ 1184]\n",
      "train loss: 556.626953  [  401/ 1184]\n",
      "train loss: 541.085571  [  501/ 1184]\n",
      "train loss: 618.185303  [  601/ 1184]\n",
      "train loss: 583.769165  [  701/ 1184]\n",
      "train loss: 658.248962  [  801/ 1184]\n",
      "train loss: 588.020020  [  901/ 1184]\n",
      "train loss: 624.775452  [ 1001/ 1184]\n",
      "train loss: 582.096985  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:16:33.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:33.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:35.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:35.504\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.5139770507812, 641.185546875, 550.1643676757812, 598.5488891601562, 576.3297119140625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:35.505\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.5461884703817 is higher than -600.5863798117335, setting new best score to -600.5461884703817\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:35.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.586380 --> 600.546188).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 652.912415  [    1/ 1184]\n",
      "train loss: 661.410706  [  101/ 1184]\n",
      "train loss: 633.971741  [  201/ 1184]\n",
      "train loss: 634.772827  [  301/ 1184]\n",
      "train loss: 632.290771  [  401/ 1184]\n",
      "train loss: 596.960693  [  501/ 1184]\n",
      "train loss: 604.599243  [  601/ 1184]\n",
      "train loss: 588.551392  [  701/ 1184]\n",
      "train loss: 625.564514  [  801/ 1184]\n",
      "train loss: 655.225159  [  901/ 1184]\n",
      "train loss: 593.364868  [ 1001/ 1184]\n",
      "train loss: 589.649292  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:16:48.952\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:48.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:50.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:50.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.305908203125, 641.2695922851562, 550.0567016601562, 598.4603881835938, 576.2210083007812]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:50.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.4909909018987 is higher than -600.5461884703817, setting new best score to -600.4909909018987\u001b[0m\n",
      "\u001b[32m2023-11-26 20:16:50.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.546188 --> 600.490991).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 610.684143  [    1/ 1184]\n",
      "train loss: 559.200928  [  101/ 1184]\n",
      "train loss: 641.913147  [  201/ 1184]\n",
      "train loss: 588.799255  [  301/ 1184]\n",
      "train loss: 636.960083  [  401/ 1184]\n",
      "train loss: 650.890625  [  501/ 1184]\n",
      "train loss: 599.194397  [  601/ 1184]\n",
      "train loss: 572.718994  [  701/ 1184]\n",
      "train loss: 569.692566  [  801/ 1184]\n",
      "train loss: 594.590210  [  901/ 1184]\n",
      "train loss: 650.494324  [ 1001/ 1184]\n",
      "train loss: 602.225708  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:17:04.586\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:04.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:06.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:06.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.283447265625, 641.0774536132812, 549.9976196289062, 598.4422607421875, 576.1685180664062]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:06.614\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.4569379975524 is higher than -600.4909909018987, setting new best score to -600.4569379975524\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:06.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.490991 --> 600.456938).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 612.441223  [    1/ 1184]\n",
      "train loss: 599.967346  [  101/ 1184]\n",
      "train loss: 667.380310  [  201/ 1184]\n",
      "train loss: 624.646851  [  301/ 1184]\n",
      "train loss: 611.526489  [  401/ 1184]\n",
      "train loss: 626.328735  [  501/ 1184]\n",
      "train loss: 570.557434  [  601/ 1184]\n",
      "train loss: 594.119507  [  701/ 1184]\n",
      "train loss: 605.491638  [  801/ 1184]\n",
      "train loss: 615.052551  [  901/ 1184]\n",
      "train loss: 568.967834  [ 1001/ 1184]\n",
      "train loss: 544.682556  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:17:19.925\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:19.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:21.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:21.773\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.2284545898438, 641.0391235351562, 550.0079345703125, 598.3626708984375, 576.1640014648438]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:21.774\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.430261153209 is higher than -600.4569379975524, setting new best score to -600.430261153209\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:21.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.456938 --> 600.430261).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 642.924316  [    1/ 1184]\n",
      "train loss: 664.920715  [  101/ 1184]\n",
      "train loss: 577.552185  [  201/ 1184]\n",
      "train loss: 564.289307  [  301/ 1184]\n",
      "train loss: 651.026733  [  401/ 1184]\n",
      "train loss: 569.902222  [  501/ 1184]\n",
      "train loss: 632.315979  [  601/ 1184]\n",
      "train loss: 538.108337  [  701/ 1184]\n",
      "train loss: 603.862305  [  801/ 1184]\n",
      "train loss: 653.878296  [  901/ 1184]\n",
      "train loss: 650.913574  [ 1001/ 1184]\n",
      "train loss: 632.530701  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:17:34.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:34.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:36.815\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:36.816\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.2240600585938, 641.1094970703125, 549.989501953125, 598.2513427734375, 576.2079467773438]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:36.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.4097733509691 is higher than -600.430261153209, setting new best score to -600.4097733509691\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:36.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.430261 --> 600.409773).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 594.412964  [    1/ 1184]\n",
      "train loss: 661.606323  [  101/ 1184]\n",
      "train loss: 639.626160  [  201/ 1184]\n",
      "train loss: 617.459351  [  301/ 1184]\n",
      "train loss: 587.177429  [  401/ 1184]\n",
      "train loss: 657.408752  [  501/ 1184]\n",
      "train loss: 673.733276  [  601/ 1184]\n",
      "train loss: 623.325745  [  701/ 1184]\n",
      "train loss: 598.794556  [  801/ 1184]\n",
      "train loss: 569.125122  [  901/ 1184]\n",
      "train loss: 624.948303  [ 1001/ 1184]\n",
      "train loss: 592.403259  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:17:50.240\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:50.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:52.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:52.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.2286987304688, 641.0354614257812, 549.9619140625, 598.319580078125, 576.161865234375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:52.081\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.3920726920985 is higher than -600.4097733509691, setting new best score to -600.3920726920985\u001b[0m\n",
      "\u001b[32m2023-11-26 20:17:52.082\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.409773 --> 600.392073).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 642.044434  [    1/ 1184]\n",
      "train loss: 605.556091  [  101/ 1184]\n",
      "train loss: 575.565369  [  201/ 1184]\n",
      "train loss: 625.831116  [  301/ 1184]\n",
      "train loss: 571.505981  [  401/ 1184]\n",
      "train loss: 621.210632  [  501/ 1184]\n",
      "train loss: 607.193420  [  601/ 1184]\n",
      "train loss: 629.651794  [  701/ 1184]\n",
      "train loss: 546.816895  [  801/ 1184]\n",
      "train loss: 571.488831  [  901/ 1184]\n",
      "train loss: 603.780579  [ 1001/ 1184]\n",
      "train loss: 609.737976  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:18:05.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:05.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:06.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:06.965\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.1531982421875, 640.94873046875, 549.9205932617188, 598.210693359375, 576.0303955078125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:06.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.3254970115952 is higher than -600.3920726920985, setting new best score to -600.3254970115952\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:06.967\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.392073 --> 600.325497).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 660.664856  [    1/ 1184]\n",
      "train loss: 622.373901  [  101/ 1184]\n",
      "train loss: 620.280334  [  201/ 1184]\n",
      "train loss: 593.988403  [  301/ 1184]\n",
      "train loss: 621.328613  [  401/ 1184]\n",
      "train loss: 611.426453  [  501/ 1184]\n",
      "train loss: 623.747681  [  601/ 1184]\n",
      "train loss: 590.310425  [  701/ 1184]\n",
      "train loss: 584.532837  [  801/ 1184]\n",
      "train loss: 618.576904  [  901/ 1184]\n",
      "train loss: 602.965942  [ 1001/ 1184]\n",
      "train loss: 583.994080  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:18:20.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:20.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:22.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:22.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.0955810546875, 640.9254760742188, 549.8558349609375, 598.2797241210938, 576.0428466796875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:22.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.3226133708713 is higher than -600.3254970115952, setting new best score to -600.3226133708713\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:22.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.325497 --> 600.322613).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 573.118530  [    1/ 1184]\n",
      "train loss: 682.847229  [  101/ 1184]\n",
      "train loss: 603.484863  [  201/ 1184]\n",
      "train loss: 663.320251  [  301/ 1184]\n",
      "train loss: 570.236450  [  401/ 1184]\n",
      "train loss: 606.970764  [  501/ 1184]\n",
      "train loss: 639.110229  [  601/ 1184]\n",
      "train loss: 561.528992  [  701/ 1184]\n",
      "train loss: 503.047272  [  801/ 1184]\n",
      "train loss: 588.001892  [  901/ 1184]\n",
      "train loss: 604.145142  [ 1001/ 1184]\n",
      "train loss: 608.651733  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:18:35.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:35.859\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:37.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:37.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.048095703125, 640.8385009765625, 549.8519287109375, 598.1608276367188, 576.0036010742188]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:37.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.2710673271855 is higher than -600.3226133708713, setting new best score to -600.2710673271855\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:37.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.322613 --> 600.271067).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 630.904663  [    1/ 1184]\n",
      "train loss: 589.590210  [  101/ 1184]\n",
      "train loss: 550.130310  [  201/ 1184]\n",
      "train loss: 611.049377  [  301/ 1184]\n",
      "train loss: 691.301941  [  401/ 1184]\n",
      "train loss: 586.367798  [  501/ 1184]\n",
      "train loss: 643.612549  [  601/ 1184]\n",
      "train loss: 583.674377  [  701/ 1184]\n",
      "train loss: 545.243591  [  801/ 1184]\n",
      "train loss: 610.447876  [  901/ 1184]\n",
      "train loss: 597.374634  [ 1001/ 1184]\n",
      "train loss: 635.938843  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:18:51.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:51.112\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:52.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:52.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.077880859375, 640.834228515625, 549.7975463867188, 598.178955078125, 575.9418334960938]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:52.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.2450114189824 is higher than -600.2710673271855, setting new best score to -600.2450114189824\u001b[0m\n",
      "\u001b[32m2023-11-26 20:18:53.000\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.271067 --> 600.245011).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 538.644104  [    1/ 1184]\n",
      "train loss: 634.797974  [  101/ 1184]\n",
      "train loss: 603.708923  [  201/ 1184]\n",
      "train loss: 612.155823  [  301/ 1184]\n",
      "train loss: 586.849182  [  401/ 1184]\n",
      "train loss: 571.102722  [  501/ 1184]\n",
      "train loss: 628.581177  [  601/ 1184]\n",
      "train loss: 555.814270  [  701/ 1184]\n",
      "train loss: 602.651978  [  801/ 1184]\n",
      "train loss: 588.780518  [  901/ 1184]\n",
      "train loss: 594.608215  [ 1001/ 1184]\n",
      "train loss: 620.436340  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:19:06.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:06.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:08.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:08.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.001953125, 640.8123779296875, 549.7527465820312, 598.0160522460938, 575.8865356445312]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:08.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.2124514036541 is higher than -600.2450114189824, setting new best score to -600.2124514036541\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:08.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.245011 --> 600.212451).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 591.318481  [    1/ 1184]\n",
      "train loss: 622.116028  [  101/ 1184]\n",
      "train loss: 616.737854  [  201/ 1184]\n",
      "train loss: 658.392273  [  301/ 1184]\n",
      "train loss: 648.645630  [  401/ 1184]\n",
      "train loss: 584.895691  [  501/ 1184]\n",
      "train loss: 596.435974  [  601/ 1184]\n",
      "train loss: 631.321350  [  701/ 1184]\n",
      "train loss: 651.156494  [  801/ 1184]\n",
      "train loss: 624.940552  [  901/ 1184]\n",
      "train loss: 608.946533  [ 1001/ 1184]\n",
      "train loss: 627.828857  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:19:21.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:21.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:23.650\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:23.651\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.9995727539062, 640.7930297851562, 549.8012084960938, 598.0667724609375, 575.9501953125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:23.652\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.1957735085789 is higher than -600.2124514036541, setting new best score to -600.1957735085789\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:23.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.212451 --> 600.195774).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 574.492371  [    1/ 1184]\n",
      "train loss: 564.078491  [  101/ 1184]\n",
      "train loss: 646.360229  [  201/ 1184]\n",
      "train loss: 577.602844  [  301/ 1184]\n",
      "train loss: 604.892578  [  401/ 1184]\n",
      "train loss: 644.643433  [  501/ 1184]\n",
      "train loss: 646.607727  [  601/ 1184]\n",
      "train loss: 674.114807  [  701/ 1184]\n",
      "train loss: 647.643372  [  801/ 1184]\n",
      "train loss: 630.133362  [  901/ 1184]\n",
      "train loss: 663.969971  [ 1001/ 1184]\n",
      "train loss: 618.618835  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:19:36.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:36.003\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:37.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:37.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.0198974609375, 640.7911987304688, 549.795654296875, 597.9947509765625, 575.9088745117188]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:37.613\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.1802097755142 is higher than -600.1957735085789, setting new best score to -600.1802097755142\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:37.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.195774 --> 600.180210).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 619.991577  [    1/ 1184]\n",
      "train loss: 594.262085  [  101/ 1184]\n",
      "train loss: 623.587524  [  201/ 1184]\n",
      "train loss: 544.957031  [  301/ 1184]\n",
      "train loss: 563.182617  [  401/ 1184]\n",
      "train loss: 588.555359  [  501/ 1184]\n",
      "train loss: 604.938171  [  601/ 1184]\n",
      "train loss: 666.504456  [  701/ 1184]\n",
      "train loss: 560.288940  [  801/ 1184]\n",
      "train loss: 672.882935  [  901/ 1184]\n",
      "train loss: 593.448608  [ 1001/ 1184]\n",
      "train loss: 655.106384  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:19:49.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:49.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:50.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:50.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.9324340820312, 640.689208984375, 549.804931640625, 597.9647216796875, 575.8261108398438]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:50.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.1424376668809 is higher than -600.1802097755142, setting new best score to -600.1424376668809\u001b[0m\n",
      "\u001b[32m2023-11-26 20:19:50.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.180210 --> 600.142438).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 600.434387  [    1/ 1184]\n",
      "train loss: 591.386536  [  101/ 1184]\n",
      "train loss: 645.386536  [  201/ 1184]\n",
      "train loss: 626.687256  [  301/ 1184]\n",
      "train loss: 594.832336  [  401/ 1184]\n",
      "train loss: 593.357788  [  501/ 1184]\n",
      "train loss: 559.100220  [  601/ 1184]\n",
      "train loss: 597.996826  [  701/ 1184]\n",
      "train loss: 554.505554  [  801/ 1184]\n",
      "train loss: 665.712769  [  901/ 1184]\n",
      "train loss: 648.144775  [ 1001/ 1184]\n",
      "train loss: 570.226135  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:20:02.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:02.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:04.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:04.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.8345947265625, 640.6870727539062, 549.782470703125, 597.938720703125, 575.8133544921875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:04.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.113074425806 is higher than -600.1424376668809, setting new best score to -600.113074425806\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:04.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.142438 --> 600.113074).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 564.453979  [    1/ 1184]\n",
      "train loss: 584.738892  [  101/ 1184]\n",
      "train loss: 574.128784  [  201/ 1184]\n",
      "train loss: 590.849182  [  301/ 1184]\n",
      "train loss: 617.083252  [  401/ 1184]\n",
      "train loss: 634.034668  [  501/ 1184]\n",
      "train loss: 587.402954  [  601/ 1184]\n",
      "train loss: 618.222534  [  701/ 1184]\n",
      "train loss: 615.984375  [  801/ 1184]\n",
      "train loss: 629.047485  [  901/ 1184]\n",
      "train loss: 632.235229  [ 1001/ 1184]\n",
      "train loss: 666.952454  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:20:16.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:16.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:17.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:17.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.8003540039062, 640.6142578125, 549.6740112304688, 597.8302612304688, 575.8145751953125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:17.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.07844802277 is higher than -600.113074425806, setting new best score to -600.07844802277\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:17.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.113074 --> 600.078448).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 632.541504  [    1/ 1184]\n",
      "train loss: 605.958130  [  101/ 1184]\n",
      "train loss: 591.627502  [  201/ 1184]\n",
      "train loss: 582.492249  [  301/ 1184]\n",
      "train loss: 637.807190  [  401/ 1184]\n",
      "train loss: 536.513245  [  501/ 1184]\n",
      "train loss: 568.722046  [  601/ 1184]\n",
      "train loss: 570.543457  [  701/ 1184]\n",
      "train loss: 606.721069  [  801/ 1184]\n",
      "train loss: 652.254272  [  901/ 1184]\n",
      "train loss: 703.901978  [ 1001/ 1184]\n",
      "train loss: 606.510376  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:20:29.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:29.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:31.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:31.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.7481079101562, 640.65771484375, 549.7317504882812, 597.84765625, 575.7485961914062]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:31.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.0632905984227 is higher than -600.07844802277, setting new best score to -600.0632905984227\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:31.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.078448 --> 600.063291).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 608.682861  [    1/ 1184]\n",
      "train loss: 637.294983  [  101/ 1184]\n",
      "train loss: 608.040405  [  201/ 1184]\n",
      "train loss: 578.914001  [  301/ 1184]\n",
      "train loss: 613.569763  [  401/ 1184]\n",
      "train loss: 621.131897  [  501/ 1184]\n",
      "train loss: 531.260498  [  601/ 1184]\n",
      "train loss: 576.541016  [  701/ 1184]\n",
      "train loss: 591.753723  [  801/ 1184]\n",
      "train loss: 578.817139  [  901/ 1184]\n",
      "train loss: 527.579773  [ 1001/ 1184]\n",
      "train loss: 590.908386  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:20:42.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:42.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:44.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:44.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.7058715820312, 640.5404663085938, 549.6727294921875, 597.7305297851562, 575.69091796875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:44.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.0101142207278 is higher than -600.0632905984227, setting new best score to -600.0101142207278\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:44.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.063291 --> 600.010114).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 595.052734  [    1/ 1184]\n",
      "train loss: 567.529846  [  101/ 1184]\n",
      "train loss: 593.286377  [  201/ 1184]\n",
      "train loss: 624.929443  [  301/ 1184]\n",
      "train loss: 623.533875  [  401/ 1184]\n",
      "train loss: 581.394287  [  501/ 1184]\n",
      "train loss: 588.211304  [  601/ 1184]\n",
      "train loss: 575.364258  [  701/ 1184]\n",
      "train loss: 671.357300  [  801/ 1184]\n",
      "train loss: 606.818115  [  901/ 1184]\n",
      "train loss: 528.744019  [ 1001/ 1184]\n",
      "train loss: 575.100952  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:20:56.056\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:56.057\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:57.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:57.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.6617431640625, 640.5855102539062, 549.6739501953125, 597.7523193359375, 575.85498046875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:57.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -600.0385511181023 is lower than -600.0101142207278, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:20:57.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 628.630676  [    1/ 1184]\n",
      "train loss: 598.549316  [  101/ 1184]\n",
      "train loss: 557.237427  [  201/ 1184]\n",
      "train loss: 611.177002  [  301/ 1184]\n",
      "train loss: 560.453247  [  401/ 1184]\n",
      "train loss: 592.810547  [  501/ 1184]\n",
      "train loss: 653.772888  [  601/ 1184]\n",
      "train loss: 593.103821  [  701/ 1184]\n",
      "train loss: 643.335083  [  801/ 1184]\n",
      "train loss: 600.493286  [  901/ 1184]\n",
      "train loss: 582.131165  [ 1001/ 1184]\n",
      "train loss: 583.263367  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:21:09.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:09.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:11.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:11.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.60595703125, 640.634765625, 549.6509399414062, 597.742431640625, 575.7286376953125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:11.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.0052154927314 is higher than -600.0101142207278, setting new best score to -600.0052154927314\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:11.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.010114 --> 600.005215).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 585.730347  [    1/ 1184]\n",
      "train loss: 619.692200  [  101/ 1184]\n",
      "train loss: 654.832825  [  201/ 1184]\n",
      "train loss: 580.138489  [  301/ 1184]\n",
      "train loss: 622.946167  [  401/ 1184]\n",
      "train loss: 589.956787  [  501/ 1184]\n",
      "train loss: 663.982910  [  601/ 1184]\n",
      "train loss: 563.851074  [  701/ 1184]\n",
      "train loss: 573.780762  [  801/ 1184]\n",
      "train loss: 585.419739  [  901/ 1184]\n",
      "train loss: 660.248779  [ 1001/ 1184]\n",
      "train loss: 597.320251  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:21:22.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:22.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:24.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:24.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.6054077148438, 640.59814453125, 549.6253051757812, 597.5750732421875, 575.6912841796875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:24.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.9725139376484 is higher than -600.0052154927314, setting new best score to -599.9725139376484\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:24.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.005215 --> 599.972514).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 601.940796  [    1/ 1184]\n",
      "train loss: 545.231812  [  101/ 1184]\n",
      "train loss: 557.277954  [  201/ 1184]\n",
      "train loss: 596.860657  [  301/ 1184]\n",
      "train loss: 537.242126  [  401/ 1184]\n",
      "train loss: 630.950867  [  501/ 1184]\n",
      "train loss: 652.645935  [  601/ 1184]\n",
      "train loss: 615.920166  [  701/ 1184]\n",
      "train loss: 579.633179  [  801/ 1184]\n",
      "train loss: 595.675110  [  901/ 1184]\n",
      "train loss: 611.454651  [ 1001/ 1184]\n",
      "train loss: 595.326294  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:21:36.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:36.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:38.206\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:38.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.5980224609375, 640.5848999023438, 549.677978515625, 597.6659545898438, 575.7041625976562]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:38.207\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.963981145545 is higher than -599.9725139376484, setting new best score to -599.963981145545\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:38.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.972514 --> 599.963981).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 671.273682  [    1/ 1184]\n",
      "train loss: 548.207520  [  101/ 1184]\n",
      "train loss: 589.072693  [  201/ 1184]\n",
      "train loss: 565.494751  [  301/ 1184]\n",
      "train loss: 536.634827  [  401/ 1184]\n",
      "train loss: 644.767883  [  501/ 1184]\n",
      "train loss: 570.337280  [  601/ 1184]\n",
      "train loss: 556.952026  [  701/ 1184]\n",
      "train loss: 608.716675  [  801/ 1184]\n",
      "train loss: 644.343140  [  901/ 1184]\n",
      "train loss: 579.742615  [ 1001/ 1184]\n",
      "train loss: 648.388916  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:21:49.784\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:49.785\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:51.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:51.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.5548095703125, 640.5098876953125, 549.6597900390625, 597.62255859375, 575.6175537109375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:51.494\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.9244128263449 is higher than -599.963981145545, setting new best score to -599.9244128263449\u001b[0m\n",
      "\u001b[32m2023-11-26 20:21:51.495\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.963981 --> 599.924413).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 592.712463  [    1/ 1184]\n",
      "train loss: 561.553101  [  101/ 1184]\n",
      "train loss: 653.246155  [  201/ 1184]\n",
      "train loss: 596.882080  [  301/ 1184]\n",
      "train loss: 589.238647  [  401/ 1184]\n",
      "train loss: 542.830444  [  501/ 1184]\n",
      "train loss: 636.692261  [  601/ 1184]\n",
      "train loss: 617.460266  [  701/ 1184]\n",
      "train loss: 594.817017  [  801/ 1184]\n",
      "train loss: 559.780701  [  901/ 1184]\n",
      "train loss: 591.731689  [ 1001/ 1184]\n",
      "train loss: 559.201355  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:22:03.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:03.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:04.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:04.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.5162353515625, 640.5294189453125, 549.6390380859375, 597.6505126953125, 575.7146606445312]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:04.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.941486136521 is lower than -599.9244128263449, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:04.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 586.219666  [    1/ 1184]\n",
      "train loss: 620.235413  [  101/ 1184]\n",
      "train loss: 650.542969  [  201/ 1184]\n",
      "train loss: 526.736877  [  301/ 1184]\n",
      "train loss: 603.896545  [  401/ 1184]\n",
      "train loss: 588.002747  [  501/ 1184]\n",
      "train loss: 579.889893  [  601/ 1184]\n",
      "train loss: 608.550049  [  701/ 1184]\n",
      "train loss: 620.661743  [  801/ 1184]\n",
      "train loss: 624.902222  [  901/ 1184]\n",
      "train loss: 582.265869  [ 1001/ 1184]\n",
      "train loss: 600.065125  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:22:16.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:16.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:17.940\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:17.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.5054321289062, 640.4855346679688, 549.60595703125, 597.497314453125, 575.6906127929688]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:17.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.8992878974238 is higher than -599.9244128263449, setting new best score to -599.8992878974238\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:17.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.924413 --> 599.899288).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 590.667664  [    1/ 1184]\n",
      "train loss: 537.238647  [  101/ 1184]\n",
      "train loss: 588.675232  [  201/ 1184]\n",
      "train loss: 568.940552  [  301/ 1184]\n",
      "train loss: 617.095703  [  401/ 1184]\n",
      "train loss: 521.746643  [  501/ 1184]\n",
      "train loss: 638.656799  [  601/ 1184]\n",
      "train loss: 569.199646  [  701/ 1184]\n",
      "train loss: 634.569275  [  801/ 1184]\n",
      "train loss: 523.496887  [  901/ 1184]\n",
      "train loss: 589.579712  [ 1001/ 1184]\n",
      "train loss: 596.344177  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:22:29.584\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:29.585\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:31.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:31.336\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.5025634765625, 640.5223999023438, 549.5759887695312, 597.510009765625, 575.678955078125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:31.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.9083824447439 is lower than -599.8992878974238, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:31.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 563.266479  [    1/ 1184]\n",
      "train loss: 560.232117  [  101/ 1184]\n",
      "train loss: 601.932739  [  201/ 1184]\n",
      "train loss: 612.935669  [  301/ 1184]\n",
      "train loss: 579.416016  [  401/ 1184]\n",
      "train loss: 596.920227  [  501/ 1184]\n",
      "train loss: 658.473267  [  601/ 1184]\n",
      "train loss: 594.005798  [  701/ 1184]\n",
      "train loss: 601.822327  [  801/ 1184]\n",
      "train loss: 646.192078  [  901/ 1184]\n",
      "train loss: 637.142456  [ 1001/ 1184]\n",
      "train loss: 618.483521  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:22:43.007\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:43.008\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:44.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:44.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.4671020507812, 640.3264770507812, 549.5811767578125, 597.4646606445312, 575.7488403320312]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:44.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.8799483287183 is higher than -599.8992878974238, setting new best score to -599.8799483287183\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:44.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.899288 --> 599.879948).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 599.357300  [    1/ 1184]\n",
      "train loss: 588.648071  [  101/ 1184]\n",
      "train loss: 577.999146  [  201/ 1184]\n",
      "train loss: 629.537476  [  301/ 1184]\n",
      "train loss: 566.435242  [  401/ 1184]\n",
      "train loss: 594.361206  [  501/ 1184]\n",
      "train loss: 653.826782  [  601/ 1184]\n",
      "train loss: 597.794800  [  701/ 1184]\n",
      "train loss: 583.905945  [  801/ 1184]\n",
      "train loss: 556.184326  [  901/ 1184]\n",
      "train loss: 547.300293  [ 1001/ 1184]\n",
      "train loss: 580.392456  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:22:56.272\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:56.273\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:57.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:57.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.47119140625, 640.2946166992188, 549.48974609375, 597.4375, 575.5886840820312]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:57.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.859842498393 is higher than -599.8799483287183, setting new best score to -599.859842498393\u001b[0m\n",
      "\u001b[32m2023-11-26 20:22:57.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.879948 --> 599.859842).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 638.699707  [    1/ 1184]\n",
      "train loss: 661.212585  [  101/ 1184]\n",
      "train loss: 599.777344  [  201/ 1184]\n",
      "train loss: 600.271179  [  301/ 1184]\n",
      "train loss: 646.665955  [  401/ 1184]\n",
      "train loss: 590.802185  [  501/ 1184]\n",
      "train loss: 616.372742  [  601/ 1184]\n",
      "train loss: 602.968445  [  701/ 1184]\n",
      "train loss: 661.068665  [  801/ 1184]\n",
      "train loss: 595.920593  [  901/ 1184]\n",
      "train loss: 615.377075  [ 1001/ 1184]\n",
      "train loss: 586.007202  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:23:10.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:10.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:11.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:11.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.337890625, 640.2225341796875, 549.58154296875, 597.3190307617188, 575.6746826171875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:11.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.82899641206 is higher than -599.859842498393, setting new best score to -599.82899641206\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:11.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.859842 --> 599.828996).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 626.541199  [    1/ 1184]\n",
      "train loss: 558.169617  [  101/ 1184]\n",
      "train loss: 559.590210  [  201/ 1184]\n",
      "train loss: 600.836548  [  301/ 1184]\n",
      "train loss: 641.987793  [  401/ 1184]\n",
      "train loss: 547.778015  [  501/ 1184]\n",
      "train loss: 631.470520  [  601/ 1184]\n",
      "train loss: 582.038513  [  701/ 1184]\n",
      "train loss: 630.815063  [  801/ 1184]\n",
      "train loss: 617.977417  [  901/ 1184]\n",
      "train loss: 532.677246  [ 1001/ 1184]\n",
      "train loss: 591.749756  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:23:23.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:23.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:24.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:24.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.442626953125, 640.2742309570312, 549.495361328125, 597.3054809570312, 575.6096801757812]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:24.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.8164061727404 is higher than -599.82899641206, setting new best score to -599.8164061727404\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:24.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.828996 --> 599.816406).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 618.617188  [    1/ 1184]\n",
      "train loss: 569.115112  [  101/ 1184]\n",
      "train loss: 628.200378  [  201/ 1184]\n",
      "train loss: 584.359802  [  301/ 1184]\n",
      "train loss: 583.484680  [  401/ 1184]\n",
      "train loss: 621.041931  [  501/ 1184]\n",
      "train loss: 584.427307  [  601/ 1184]\n",
      "train loss: 652.517761  [  701/ 1184]\n",
      "train loss: 563.904358  [  801/ 1184]\n",
      "train loss: 608.884949  [  901/ 1184]\n",
      "train loss: 552.987549  [ 1001/ 1184]\n",
      "train loss: 634.521912  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:23:36.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:36.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:38.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:38.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.4444580078125, 640.2210693359375, 549.5086669921875, 597.2357177734375, 575.5480346679688]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:38.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.8039113491396 is higher than -599.8164061727404, setting new best score to -599.8039113491396\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:38.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.816406 --> 599.803911).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 559.423096  [    1/ 1184]\n",
      "train loss: 578.994507  [  101/ 1184]\n",
      "train loss: 614.047485  [  201/ 1184]\n",
      "train loss: 629.022705  [  301/ 1184]\n",
      "train loss: 592.827209  [  401/ 1184]\n",
      "train loss: 591.557312  [  501/ 1184]\n",
      "train loss: 587.163452  [  601/ 1184]\n",
      "train loss: 600.297302  [  701/ 1184]\n",
      "train loss: 698.397705  [  801/ 1184]\n",
      "train loss: 498.996704  [  901/ 1184]\n",
      "train loss: 537.259399  [ 1001/ 1184]\n",
      "train loss: 577.214233  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:23:50.121\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:50.122\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:51.754\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:51.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.4343872070312, 640.2315673828125, 549.452880859375, 597.308837890625, 575.5679321289062]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:51.756\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.7886608268641 is higher than -599.8039113491396, setting new best score to -599.7886608268641\u001b[0m\n",
      "\u001b[32m2023-11-26 20:23:51.756\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.803911 --> 599.788661).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 527.377930  [    1/ 1184]\n",
      "train loss: 616.275391  [  101/ 1184]\n",
      "train loss: 629.492371  [  201/ 1184]\n",
      "train loss: 642.740356  [  301/ 1184]\n",
      "train loss: 626.245972  [  401/ 1184]\n",
      "train loss: 612.680176  [  501/ 1184]\n",
      "train loss: 620.536987  [  601/ 1184]\n",
      "train loss: 523.505188  [  701/ 1184]\n",
      "train loss: 609.407837  [  801/ 1184]\n",
      "train loss: 636.039856  [  901/ 1184]\n",
      "train loss: 629.579468  [ 1001/ 1184]\n",
      "train loss: 574.566833  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:24:03.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:03.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:05.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:05.284\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.4005126953125, 640.1002197265625, 549.4140625, 597.2933349609375, 575.6442260742188]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:05.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.7631767948972 is higher than -599.7886608268641, setting new best score to -599.7631767948972\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:05.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.788661 --> 599.763177).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 610.624756  [    1/ 1184]\n",
      "train loss: 626.682983  [  101/ 1184]\n",
      "train loss: 641.599487  [  201/ 1184]\n",
      "train loss: 617.223083  [  301/ 1184]\n",
      "train loss: 621.531616  [  401/ 1184]\n",
      "train loss: 586.520325  [  501/ 1184]\n",
      "train loss: 602.608582  [  601/ 1184]\n",
      "train loss: 623.252075  [  701/ 1184]\n",
      "train loss: 645.077148  [  801/ 1184]\n",
      "train loss: 613.468079  [  901/ 1184]\n",
      "train loss: 616.815002  [ 1001/ 1184]\n",
      "train loss: 612.410278  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:24:16.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:16.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:18.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:18.566\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.3140869140625, 640.0928344726562, 549.3984375, 597.2837524414062, 575.593017578125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:18.567\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.7550326963014 is higher than -599.7631767948972, setting new best score to -599.7550326963014\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:18.568\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.763177 --> 599.755033).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 559.630005  [    1/ 1184]\n",
      "train loss: 560.873047  [  101/ 1184]\n",
      "train loss: 586.597107  [  201/ 1184]\n",
      "train loss: 623.388794  [  301/ 1184]\n",
      "train loss: 565.193604  [  401/ 1184]\n",
      "train loss: 612.496338  [  501/ 1184]\n",
      "train loss: 639.460205  [  601/ 1184]\n",
      "train loss: 580.392944  [  701/ 1184]\n",
      "train loss: 634.283936  [  801/ 1184]\n",
      "train loss: 586.456116  [  901/ 1184]\n",
      "train loss: 524.559265  [ 1001/ 1184]\n",
      "train loss: 635.686951  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:24:30.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:30.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:31.953\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:31.954\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.271484375, 640.1747436523438, 549.4061889648438, 597.2532348632812, 575.51953125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:31.955\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.7621495500396 is lower than -599.7550326963014, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:31.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 602.924072  [    1/ 1184]\n",
      "train loss: 522.865356  [  101/ 1184]\n",
      "train loss: 648.963318  [  201/ 1184]\n",
      "train loss: 580.678711  [  301/ 1184]\n",
      "train loss: 660.537354  [  401/ 1184]\n",
      "train loss: 542.161255  [  501/ 1184]\n",
      "train loss: 583.681763  [  601/ 1184]\n",
      "train loss: 559.031128  [  701/ 1184]\n",
      "train loss: 626.733643  [  801/ 1184]\n",
      "train loss: 628.597900  [  901/ 1184]\n",
      "train loss: 617.694763  [ 1001/ 1184]\n",
      "train loss: 587.727905  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:24:43.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:43.636\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:45.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:45.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.33349609375, 640.2002563476562, 549.4200439453125, 597.195068359375, 575.5073852539062]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:45.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.7143134394778 is higher than -599.7550326963014, setting new best score to -599.7143134394778\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:45.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.755033 --> 599.714313).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 652.235596  [    1/ 1184]\n",
      "train loss: 643.968384  [  101/ 1184]\n",
      "train loss: 599.086670  [  201/ 1184]\n",
      "train loss: 581.701843  [  301/ 1184]\n",
      "train loss: 606.511780  [  401/ 1184]\n",
      "train loss: 599.317444  [  501/ 1184]\n",
      "train loss: 578.537109  [  601/ 1184]\n",
      "train loss: 598.598083  [  701/ 1184]\n",
      "train loss: 593.661987  [  801/ 1184]\n",
      "train loss: 710.399414  [  901/ 1184]\n",
      "train loss: 599.107666  [ 1001/ 1184]\n",
      "train loss: 624.247925  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:24:57.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:57.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:58.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:58.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.39453125, 640.2249145507812, 549.3573608398438, 597.2278442382812, 575.55078125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:58.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.7517066665843 is lower than -599.7143134394778, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:24:58.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 547.927063  [    1/ 1184]\n",
      "train loss: 590.171143  [  101/ 1184]\n",
      "train loss: 625.316467  [  201/ 1184]\n",
      "train loss: 529.248596  [  301/ 1184]\n",
      "train loss: 611.502625  [  401/ 1184]\n",
      "train loss: 624.438721  [  501/ 1184]\n",
      "train loss: 628.150085  [  601/ 1184]\n",
      "train loss: 604.207153  [  701/ 1184]\n",
      "train loss: 598.483032  [  801/ 1184]\n",
      "train loss: 620.725098  [  901/ 1184]\n",
      "train loss: 588.270325  [ 1001/ 1184]\n",
      "train loss: 597.228210  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:25:10.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:10.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:12.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:12.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.2421875, 640.162109375, 549.358642578125, 597.0906982421875, 575.4766845703125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:12.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.6846814119364 is higher than -599.7143134394778, setting new best score to -599.6846814119364\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:12.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.714313 --> 599.684681).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 590.355164  [    1/ 1184]\n",
      "train loss: 583.396545  [  101/ 1184]\n",
      "train loss: 584.388733  [  201/ 1184]\n",
      "train loss: 582.226196  [  301/ 1184]\n",
      "train loss: 679.004211  [  401/ 1184]\n",
      "train loss: 607.024841  [  501/ 1184]\n",
      "train loss: 621.870361  [  601/ 1184]\n",
      "train loss: 609.816284  [  701/ 1184]\n",
      "train loss: 648.697998  [  801/ 1184]\n",
      "train loss: 616.939148  [  901/ 1184]\n",
      "train loss: 556.814819  [ 1001/ 1184]\n",
      "train loss: 643.676636  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:25:24.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:24.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:26.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:26.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.1997680664062, 640.103271484375, 549.378173828125, 597.233642578125, 575.4228515625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:26.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.6890326004994 is lower than -599.6846814119364, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:26.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 549.525879  [    1/ 1184]\n",
      "train loss: 571.049988  [  101/ 1184]\n",
      "train loss: 609.114197  [  201/ 1184]\n",
      "train loss: 579.004822  [  301/ 1184]\n",
      "train loss: 578.537598  [  401/ 1184]\n",
      "train loss: 635.756836  [  501/ 1184]\n",
      "train loss: 556.243774  [  601/ 1184]\n",
      "train loss: 597.633789  [  701/ 1184]\n",
      "train loss: 576.054016  [  801/ 1184]\n",
      "train loss: 592.068665  [  901/ 1184]\n",
      "train loss: 648.438049  [ 1001/ 1184]\n",
      "train loss: 572.230652  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:25:37.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:37.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:39.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:39.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.2340698242188, 640.093505859375, 549.322998046875, 597.2223510742188, 575.3282470703125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:39.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.6672470672221 is higher than -599.6846814119364, setting new best score to -599.6672470672221\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:39.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.684681 --> 599.667247).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 604.390381  [    1/ 1184]\n",
      "train loss: 578.139832  [  101/ 1184]\n",
      "train loss: 575.910767  [  201/ 1184]\n",
      "train loss: 593.392883  [  301/ 1184]\n",
      "train loss: 646.744385  [  401/ 1184]\n",
      "train loss: 610.691101  [  501/ 1184]\n",
      "train loss: 587.722412  [  601/ 1184]\n",
      "train loss: 582.044373  [  701/ 1184]\n",
      "train loss: 569.130310  [  801/ 1184]\n",
      "train loss: 643.770325  [  901/ 1184]\n",
      "train loss: 572.829651  [ 1001/ 1184]\n",
      "train loss: 661.386047  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:25:50.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:50.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:52.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:52.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.17333984375, 640.03759765625, 549.2938232421875, 597.0459594726562, 575.4568481445312]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:52.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.63494842143 is higher than -599.6672470672221, setting new best score to -599.63494842143\u001b[0m\n",
      "\u001b[32m2023-11-26 20:25:52.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.667247 --> 599.634948).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 654.168457  [    1/ 1184]\n",
      "train loss: 602.778931  [  101/ 1184]\n",
      "train loss: 616.926392  [  201/ 1184]\n",
      "train loss: 645.754150  [  301/ 1184]\n",
      "train loss: 631.791016  [  401/ 1184]\n",
      "train loss: 637.042786  [  501/ 1184]\n",
      "train loss: 602.005005  [  601/ 1184]\n",
      "train loss: 652.582886  [  701/ 1184]\n",
      "train loss: 587.200378  [  801/ 1184]\n",
      "train loss: 597.675415  [  901/ 1184]\n",
      "train loss: 586.458740  [ 1001/ 1184]\n",
      "train loss: 583.945862  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:26:04.015\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:04.016\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:05.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:05.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.1862182617188, 640.0106201171875, 549.2798461914062, 597.1050415039062, 575.4100341796875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:05.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.6648184860809 is lower than -599.63494842143, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:05.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 627.886902  [    1/ 1184]\n",
      "train loss: 622.029480  [  101/ 1184]\n",
      "train loss: 632.717957  [  201/ 1184]\n",
      "train loss: 610.292725  [  301/ 1184]\n",
      "train loss: 609.157837  [  401/ 1184]\n",
      "train loss: 589.861023  [  501/ 1184]\n",
      "train loss: 581.856567  [  601/ 1184]\n",
      "train loss: 573.575256  [  701/ 1184]\n",
      "train loss: 635.396240  [  801/ 1184]\n",
      "train loss: 569.449524  [  901/ 1184]\n",
      "train loss: 623.734436  [ 1001/ 1184]\n",
      "train loss: 638.833496  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:26:17.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:17.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:19.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:19.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.1748046875, 639.9951782226562, 549.2779541015625, 597.0572509765625, 575.3590698242188]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:19.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.6439514160156 is lower than -599.63494842143, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:19.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 594.495117  [    1/ 1184]\n",
      "train loss: 649.560913  [  101/ 1184]\n",
      "train loss: 517.937134  [  201/ 1184]\n",
      "train loss: 643.707397  [  301/ 1184]\n",
      "train loss: 568.488647  [  401/ 1184]\n",
      "train loss: 605.687073  [  501/ 1184]\n",
      "train loss: 632.924744  [  601/ 1184]\n",
      "train loss: 584.926331  [  701/ 1184]\n",
      "train loss: 631.172241  [  801/ 1184]\n",
      "train loss: 617.120117  [  901/ 1184]\n",
      "train loss: 576.973267  [ 1001/ 1184]\n",
      "train loss: 584.874207  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:26:30.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:30.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:32.455\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:32.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.1915283203125, 639.9846801757812, 549.2808837890625, 597.0255126953125, 575.4035034179688]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:32.456\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.6234290014339 is higher than -599.63494842143, setting new best score to -599.6234290014339\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:32.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.634948 --> 599.623429).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 567.626099  [    1/ 1184]\n",
      "train loss: 506.216370  [  101/ 1184]\n",
      "train loss: 596.354492  [  201/ 1184]\n",
      "train loss: 619.653809  [  301/ 1184]\n",
      "train loss: 651.539856  [  401/ 1184]\n",
      "train loss: 641.818298  [  501/ 1184]\n",
      "train loss: 576.110229  [  601/ 1184]\n",
      "train loss: 620.807861  [  701/ 1184]\n",
      "train loss: 570.189331  [  801/ 1184]\n",
      "train loss: 598.180664  [  901/ 1184]\n",
      "train loss: 588.513306  [ 1001/ 1184]\n",
      "train loss: 621.764648  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:26:43.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:43.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:45.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:45.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.0584716796875, 639.9857177734375, 549.1586303710938, 597.0774536132812, 575.369384765625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:45.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.6000449651405 is higher than -599.6234290014339, setting new best score to -599.6000449651405\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:45.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.623429 --> 599.600045).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 643.632935  [    1/ 1184]\n",
      "train loss: 601.532288  [  101/ 1184]\n",
      "train loss: 568.828613  [  201/ 1184]\n",
      "train loss: 583.260864  [  301/ 1184]\n",
      "train loss: 579.511169  [  401/ 1184]\n",
      "train loss: 635.734375  [  501/ 1184]\n",
      "train loss: 544.030334  [  601/ 1184]\n",
      "train loss: 601.280945  [  701/ 1184]\n",
      "train loss: 589.433594  [  801/ 1184]\n",
      "train loss: 535.693665  [  901/ 1184]\n",
      "train loss: 631.862732  [ 1001/ 1184]\n",
      "train loss: 563.302612  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:26:57.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:57.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:58.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:58.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.078125, 639.95166015625, 549.1705322265625, 597.0100708007812, 575.3399658203125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:58.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.5871009536936 is higher than -599.6000449651405, setting new best score to -599.5871009536936\u001b[0m\n",
      "\u001b[32m2023-11-26 20:26:58.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.600045 --> 599.587101).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 591.524658  [    1/ 1184]\n",
      "train loss: 622.361023  [  101/ 1184]\n",
      "train loss: 556.786377  [  201/ 1184]\n",
      "train loss: 566.145386  [  301/ 1184]\n",
      "train loss: 631.596558  [  401/ 1184]\n",
      "train loss: 564.951416  [  501/ 1184]\n",
      "train loss: 619.990662  [  601/ 1184]\n",
      "train loss: 579.494080  [  701/ 1184]\n",
      "train loss: 636.894165  [  801/ 1184]\n",
      "train loss: 617.187012  [  901/ 1184]\n",
      "train loss: 609.614502  [ 1001/ 1184]\n",
      "train loss: 625.494324  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:27:10.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:10.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:12.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:12.540\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.0802001953125, 640.0116577148438, 549.2153930664062, 597.01416015625, 575.3887329101562]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:12.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.5734005698674 is higher than -599.5871009536936, setting new best score to -599.5734005698674\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:12.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.587101 --> 599.573401).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 620.169922  [    1/ 1184]\n",
      "train loss: 649.387817  [  101/ 1184]\n",
      "train loss: 592.320374  [  201/ 1184]\n",
      "train loss: 634.763977  [  301/ 1184]\n",
      "train loss: 581.026367  [  401/ 1184]\n",
      "train loss: 610.276245  [  501/ 1184]\n",
      "train loss: 598.231384  [  601/ 1184]\n",
      "train loss: 603.190613  [  701/ 1184]\n",
      "train loss: 561.751343  [  801/ 1184]\n",
      "train loss: 584.605713  [  901/ 1184]\n",
      "train loss: 645.674500  [ 1001/ 1184]\n",
      "train loss: 619.885193  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:27:24.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:24.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:25.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:25.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.0215454101562, 639.9351806640625, 549.1270751953125, 596.9630737304688, 575.3085327148438]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:25.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.5468214590338 is higher than -599.5734005698674, setting new best score to -599.5468214590338\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:25.966\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.573401 --> 599.546821).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 630.406982  [    1/ 1184]\n",
      "train loss: 624.575623  [  101/ 1184]\n",
      "train loss: 614.470093  [  201/ 1184]\n",
      "train loss: 637.371948  [  301/ 1184]\n",
      "train loss: 625.207092  [  401/ 1184]\n",
      "train loss: 606.096985  [  501/ 1184]\n",
      "train loss: 558.692688  [  601/ 1184]\n",
      "train loss: 572.746826  [  701/ 1184]\n",
      "train loss: 684.078613  [  801/ 1184]\n",
      "train loss: 669.628784  [  901/ 1184]\n",
      "train loss: 568.339478  [ 1001/ 1184]\n",
      "train loss: 606.620850  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:27:37.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:37.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:39.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:39.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.0407104492188, 640.0615234375, 549.2413330078125, 596.973388671875, 575.2739868164062]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:39.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.5710901187945 is lower than -599.5468214590338, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:39.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 659.593262  [    1/ 1184]\n",
      "train loss: 603.932068  [  101/ 1184]\n",
      "train loss: 592.473755  [  201/ 1184]\n",
      "train loss: 641.032104  [  301/ 1184]\n",
      "train loss: 602.216003  [  401/ 1184]\n",
      "train loss: 580.400085  [  501/ 1184]\n",
      "train loss: 514.151917  [  601/ 1184]\n",
      "train loss: 576.729614  [  701/ 1184]\n",
      "train loss: 605.748169  [  801/ 1184]\n",
      "train loss: 560.637329  [  901/ 1184]\n",
      "train loss: 590.930603  [ 1001/ 1184]\n",
      "train loss: 640.930969  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:27:51.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:51.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:52.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:52.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.0107421875, 639.9619750976562, 549.1929321289062, 596.92041015625, 575.3978271484375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:52.743\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.551739038395 is lower than -599.5468214590338, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:27:52.744\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 603.808228  [    1/ 1184]\n",
      "train loss: 607.147217  [  101/ 1184]\n",
      "train loss: 611.033325  [  201/ 1184]\n",
      "train loss: 597.725830  [  301/ 1184]\n",
      "train loss: 584.357422  [  401/ 1184]\n",
      "train loss: 652.802979  [  501/ 1184]\n",
      "train loss: 570.150391  [  601/ 1184]\n",
      "train loss: 599.940430  [  701/ 1184]\n",
      "train loss: 605.870667  [  801/ 1184]\n",
      "train loss: 649.329529  [  901/ 1184]\n",
      "train loss: 620.579102  [ 1001/ 1184]\n",
      "train loss: 636.273987  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:28:04.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:04.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:05.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:05.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.0044555664062, 639.8787231445312, 549.2091064453125, 596.8677368164062, 575.2907104492188]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:05.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.5226812048803 is higher than -599.5468214590338, setting new best score to -599.5226812048803\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:05.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.546821 --> 599.522681).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 605.086304  [    1/ 1184]\n",
      "train loss: 536.147583  [  101/ 1184]\n",
      "train loss: 528.028320  [  201/ 1184]\n",
      "train loss: 534.295959  [  301/ 1184]\n",
      "train loss: 671.548218  [  401/ 1184]\n",
      "train loss: 604.463318  [  501/ 1184]\n",
      "train loss: 635.423523  [  601/ 1184]\n",
      "train loss: 527.221069  [  701/ 1184]\n",
      "train loss: 642.877197  [  801/ 1184]\n",
      "train loss: 594.537048  [  901/ 1184]\n",
      "train loss: 576.331421  [ 1001/ 1184]\n",
      "train loss: 618.725769  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:28:17.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:17.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:19.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:19.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.0784912109375, 639.8819580078125, 549.1724853515625, 596.9386596679688, 575.27587890625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:19.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.54950669687 is lower than -599.5226812048803, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:19.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 651.316467  [    1/ 1184]\n",
      "train loss: 637.081543  [  101/ 1184]\n",
      "train loss: 589.237976  [  201/ 1184]\n",
      "train loss: 628.456238  [  301/ 1184]\n",
      "train loss: 635.369385  [  401/ 1184]\n",
      "train loss: 638.584595  [  501/ 1184]\n",
      "train loss: 648.630127  [  601/ 1184]\n",
      "train loss: 520.002930  [  701/ 1184]\n",
      "train loss: 600.931641  [  801/ 1184]\n",
      "train loss: 592.321289  [  901/ 1184]\n",
      "train loss: 615.657532  [ 1001/ 1184]\n",
      "train loss: 589.024902  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:28:30.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:30.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:32.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:32.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.9580688476562, 639.8716430664062, 549.0994262695312, 596.8377685546875, 575.33984375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:32.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.5131443458267 is higher than -599.5226812048803, setting new best score to -599.5131443458267\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:32.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.522681 --> 599.513144).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 584.730713  [    1/ 1184]\n",
      "train loss: 582.222473  [  101/ 1184]\n",
      "train loss: 651.857178  [  201/ 1184]\n",
      "train loss: 622.007812  [  301/ 1184]\n",
      "train loss: 648.916016  [  401/ 1184]\n",
      "train loss: 681.493774  [  501/ 1184]\n",
      "train loss: 588.370667  [  601/ 1184]\n",
      "train loss: 627.556152  [  701/ 1184]\n",
      "train loss: 580.649292  [  801/ 1184]\n",
      "train loss: 640.676697  [  901/ 1184]\n",
      "train loss: 608.280212  [ 1001/ 1184]\n",
      "train loss: 623.538452  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:28:43.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:43.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:45.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:45.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.9078369140625, 639.883056640625, 549.1626586914062, 596.842529296875, 575.2900390625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:45.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.4932871371885 is higher than -599.5131443458267, setting new best score to -599.4932871371885\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:45.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.513144 --> 599.493287).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 573.252197  [    1/ 1184]\n",
      "train loss: 568.247314  [  101/ 1184]\n",
      "train loss: 643.622986  [  201/ 1184]\n",
      "train loss: 609.855042  [  301/ 1184]\n",
      "train loss: 629.149292  [  401/ 1184]\n",
      "train loss: 577.038940  [  501/ 1184]\n",
      "train loss: 594.855530  [  601/ 1184]\n",
      "train loss: 581.153809  [  701/ 1184]\n",
      "train loss: 624.115906  [  801/ 1184]\n",
      "train loss: 533.784790  [  901/ 1184]\n",
      "train loss: 554.251282  [ 1001/ 1184]\n",
      "train loss: 550.247559  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:28:57.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:57.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:59.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:59.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.9620971679688, 639.8486938476562, 549.1943969726562, 596.8253173828125, 575.2767333984375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:59.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.4978596747676 is lower than -599.4932871371885, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:28:59.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 597.724365  [    1/ 1184]\n",
      "train loss: 564.489807  [  101/ 1184]\n",
      "train loss: 569.718262  [  201/ 1184]\n",
      "train loss: 616.156372  [  301/ 1184]\n",
      "train loss: 575.798523  [  401/ 1184]\n",
      "train loss: 580.176575  [  501/ 1184]\n",
      "train loss: 622.478394  [  601/ 1184]\n",
      "train loss: 639.574707  [  701/ 1184]\n",
      "train loss: 621.488708  [  801/ 1184]\n",
      "train loss: 619.486450  [  901/ 1184]\n",
      "train loss: 576.790283  [ 1001/ 1184]\n",
      "train loss: 672.929932  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:29:10.660\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:10.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:12.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:12.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.9439697265625, 639.7847900390625, 549.0994873046875, 596.7861328125, 575.244140625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:12.422\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.4740663166288 is higher than -599.4932871371885, setting new best score to -599.4740663166288\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:12.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.493287 --> 599.474066).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 549.463562  [    1/ 1184]\n",
      "train loss: 592.281250  [  101/ 1184]\n",
      "train loss: 619.935059  [  201/ 1184]\n",
      "train loss: 594.971985  [  301/ 1184]\n",
      "train loss: 587.164246  [  401/ 1184]\n",
      "train loss: 625.337402  [  501/ 1184]\n",
      "train loss: 561.156250  [  601/ 1184]\n",
      "train loss: 654.080444  [  701/ 1184]\n",
      "train loss: 611.111450  [  801/ 1184]\n",
      "train loss: 640.726929  [  901/ 1184]\n",
      "train loss: 638.672668  [ 1001/ 1184]\n",
      "train loss: 585.087646  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:29:23.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:23.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:25.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:25.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.94384765625, 639.869873046875, 549.0557250976562, 596.822998046875, 575.2208251953125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:25.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.4751396082625 is lower than -599.4740663166288, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:25.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 574.181274  [    1/ 1184]\n",
      "train loss: 540.355164  [  101/ 1184]\n",
      "train loss: 603.220398  [  201/ 1184]\n",
      "train loss: 585.232117  [  301/ 1184]\n",
      "train loss: 646.297058  [  401/ 1184]\n",
      "train loss: 572.602966  [  501/ 1184]\n",
      "train loss: 608.182983  [  601/ 1184]\n",
      "train loss: 602.028748  [  701/ 1184]\n",
      "train loss: 626.237183  [  801/ 1184]\n",
      "train loss: 619.635315  [  901/ 1184]\n",
      "train loss: 561.688110  [ 1001/ 1184]\n",
      "train loss: 586.947510  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:29:37.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:37.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:38.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:38.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.8358154296875, 639.7716064453125, 549.0856323242188, 596.7527465820312, 575.2149658203125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:38.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.4476985110513 is higher than -599.4740663166288, setting new best score to -599.4476985110513\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:38.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.474066 --> 599.447699).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 577.222534  [    1/ 1184]\n",
      "train loss: 656.037659  [  101/ 1184]\n",
      "train loss: 598.028503  [  201/ 1184]\n",
      "train loss: 579.574951  [  301/ 1184]\n",
      "train loss: 566.255005  [  401/ 1184]\n",
      "train loss: 661.410706  [  501/ 1184]\n",
      "train loss: 650.016846  [  601/ 1184]\n",
      "train loss: 592.290955  [  701/ 1184]\n",
      "train loss: 658.451416  [  801/ 1184]\n",
      "train loss: 621.272888  [  901/ 1184]\n",
      "train loss: 608.518066  [ 1001/ 1184]\n",
      "train loss: 592.496338  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:29:50.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:50.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:52.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:52.394\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.939697265625, 639.8151245117188, 549.0875244140625, 596.8828735351562, 575.3204345703125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:52.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.4854927932159 is lower than -599.4476985110513, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:29:52.395\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 640.156799  [    1/ 1184]\n",
      "train loss: 593.254395  [  101/ 1184]\n",
      "train loss: 554.626038  [  201/ 1184]\n",
      "train loss: 556.549927  [  301/ 1184]\n",
      "train loss: 623.169861  [  401/ 1184]\n",
      "train loss: 579.050903  [  501/ 1184]\n",
      "train loss: 529.898621  [  601/ 1184]\n",
      "train loss: 587.703979  [  701/ 1184]\n",
      "train loss: 632.534973  [  801/ 1184]\n",
      "train loss: 623.920898  [  901/ 1184]\n",
      "train loss: 647.751221  [ 1001/ 1184]\n",
      "train loss: 523.524353  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:30:03.897\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:03.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:05.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:05.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.903076171875, 639.794189453125, 549.014892578125, 596.7601318359375, 575.1765747070312]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:05.545\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.4378575578521 is higher than -599.4476985110513, setting new best score to -599.4378575578521\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:05.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.447699 --> 599.437858).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 680.970764  [    1/ 1184]\n",
      "train loss: 551.710938  [  101/ 1184]\n",
      "train loss: 593.968750  [  201/ 1184]\n",
      "train loss: 663.411621  [  301/ 1184]\n",
      "train loss: 668.263794  [  401/ 1184]\n",
      "train loss: 619.123901  [  501/ 1184]\n",
      "train loss: 567.835693  [  601/ 1184]\n",
      "train loss: 597.078247  [  701/ 1184]\n",
      "train loss: 543.999634  [  801/ 1184]\n",
      "train loss: 535.421265  [  901/ 1184]\n",
      "train loss: 599.144714  [ 1001/ 1184]\n",
      "train loss: 637.917725  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:30:17.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:17.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:19.314\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:19.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.761474609375, 639.7315673828125, 549.033447265625, 596.8021850585938, 575.1253051757812]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:19.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.4260739097112 is higher than -599.4378575578521, setting new best score to -599.4260739097112\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:19.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.437858 --> 599.426074).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 560.300537  [    1/ 1184]\n",
      "train loss: 601.203674  [  101/ 1184]\n",
      "train loss: 510.561707  [  201/ 1184]\n",
      "train loss: 600.973633  [  301/ 1184]\n",
      "train loss: 600.483154  [  401/ 1184]\n",
      "train loss: 547.320557  [  501/ 1184]\n",
      "train loss: 613.642578  [  601/ 1184]\n",
      "train loss: 664.510437  [  701/ 1184]\n",
      "train loss: 646.834595  [  801/ 1184]\n",
      "train loss: 635.294495  [  901/ 1184]\n",
      "train loss: 606.143616  [ 1001/ 1184]\n",
      "train loss: 655.032471  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:30:31.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:31.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:33.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:33.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.7572631835938, 639.65771484375, 549.0020141601562, 596.7550048828125, 575.129638671875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:33.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.3997745562203 is higher than -599.4260739097112, setting new best score to -599.3997745562203\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:33.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.426074 --> 599.399775).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 582.553406  [    1/ 1184]\n",
      "train loss: 597.208679  [  101/ 1184]\n",
      "train loss: 567.867920  [  201/ 1184]\n",
      "train loss: 616.588074  [  301/ 1184]\n",
      "train loss: 603.113525  [  401/ 1184]\n",
      "train loss: 650.315186  [  501/ 1184]\n",
      "train loss: 620.706421  [  601/ 1184]\n",
      "train loss: 595.474182  [  701/ 1184]\n",
      "train loss: 597.732971  [  801/ 1184]\n",
      "train loss: 678.551331  [  901/ 1184]\n",
      "train loss: 595.979492  [ 1001/ 1184]\n",
      "train loss: 556.421936  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:30:44.927\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:44.928\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:46.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:46.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.7437744140625, 639.736572265625, 549.0155029296875, 596.7970581054688, 575.1621704101562]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:46.533\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.4121129289458 is lower than -599.3997745562203, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:46.534\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 598.718811  [    1/ 1184]\n",
      "train loss: 534.811401  [  101/ 1184]\n",
      "train loss: 596.381836  [  201/ 1184]\n",
      "train loss: 658.771362  [  301/ 1184]\n",
      "train loss: 580.327393  [  401/ 1184]\n",
      "train loss: 596.723389  [  501/ 1184]\n",
      "train loss: 608.385498  [  601/ 1184]\n",
      "train loss: 537.452637  [  701/ 1184]\n",
      "train loss: 596.227112  [  801/ 1184]\n",
      "train loss: 556.325012  [  901/ 1184]\n",
      "train loss: 568.119812  [ 1001/ 1184]\n",
      "train loss: 614.892273  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:30:58.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:58.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:59.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:59.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.7166748046875, 639.6957397460938, 549.0787353515625, 596.7748413085938, 575.1393432617188]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:59.833\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.40175031831 is lower than -599.3997745562203, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:30:59.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 592.932922  [    1/ 1184]\n",
      "train loss: 613.184204  [  101/ 1184]\n",
      "train loss: 645.255371  [  201/ 1184]\n",
      "train loss: 553.179871  [  301/ 1184]\n",
      "train loss: 565.368958  [  401/ 1184]\n",
      "train loss: 574.246094  [  501/ 1184]\n",
      "train loss: 590.846558  [  601/ 1184]\n",
      "train loss: 627.051575  [  701/ 1184]\n",
      "train loss: 642.342102  [  801/ 1184]\n",
      "train loss: 638.962769  [  901/ 1184]\n",
      "train loss: 624.598511  [ 1001/ 1184]\n",
      "train loss: 542.716675  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:31:11.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:11.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:13.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:13.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.76953125, 639.7122802734375, 549.0145263671875, 596.737060546875, 575.2259521484375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:13.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.39564054465 is higher than -599.3997745562203, setting new best score to -599.39564054465\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:13.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.399775 --> 599.395641).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 641.241211  [    1/ 1184]\n",
      "train loss: 604.666199  [  101/ 1184]\n",
      "train loss: 638.732483  [  201/ 1184]\n",
      "train loss: 593.712219  [  301/ 1184]\n",
      "train loss: 596.070190  [  401/ 1184]\n",
      "train loss: 643.290222  [  501/ 1184]\n",
      "train loss: 582.916138  [  601/ 1184]\n",
      "train loss: 524.695251  [  701/ 1184]\n",
      "train loss: 577.614990  [  801/ 1184]\n",
      "train loss: 621.115540  [  901/ 1184]\n",
      "train loss: 568.322693  [ 1001/ 1184]\n",
      "train loss: 624.236023  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:31:25.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:25.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:26.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:26.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.7111206054688, 639.5820922851562, 548.973388671875, 596.7213745117188, 575.2184448242188]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:26.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.3679203081734 is higher than -599.39564054465, setting new best score to -599.3679203081734\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:26.840\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.395641 --> 599.367920).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 606.556274  [    1/ 1184]\n",
      "train loss: 667.056580  [  101/ 1184]\n",
      "train loss: 561.437744  [  201/ 1184]\n",
      "train loss: 565.507935  [  301/ 1184]\n",
      "train loss: 598.229187  [  401/ 1184]\n",
      "train loss: 578.212158  [  501/ 1184]\n",
      "train loss: 583.519104  [  601/ 1184]\n",
      "train loss: 549.272583  [  701/ 1184]\n",
      "train loss: 595.587341  [  801/ 1184]\n",
      "train loss: 552.431763  [  901/ 1184]\n",
      "train loss: 578.608643  [ 1001/ 1184]\n",
      "train loss: 670.354980  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:31:38.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:38.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:40.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:40.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.7667236328125, 639.5655517578125, 548.938232421875, 596.7164306640625, 575.1412353515625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:40.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.3618568903283 is higher than -599.3679203081734, setting new best score to -599.3618568903283\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:40.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.367920 --> 599.361857).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 615.872559  [    1/ 1184]\n",
      "train loss: 654.612244  [  101/ 1184]\n",
      "train loss: 625.680603  [  201/ 1184]\n",
      "train loss: 617.219299  [  301/ 1184]\n",
      "train loss: 628.414307  [  401/ 1184]\n",
      "train loss: 612.749939  [  501/ 1184]\n",
      "train loss: 579.729614  [  601/ 1184]\n",
      "train loss: 612.610107  [  701/ 1184]\n",
      "train loss: 600.434692  [  801/ 1184]\n",
      "train loss: 593.500000  [  901/ 1184]\n",
      "train loss: 582.446899  [ 1001/ 1184]\n",
      "train loss: 647.871155  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:31:52.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:52.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:53.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:53.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.7464599609375, 639.683349609375, 548.8972778320312, 596.7083129882812, 575.069580078125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:53.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.3504153481013 is higher than -599.3618568903283, setting new best score to -599.3504153481013\u001b[0m\n",
      "\u001b[32m2023-11-26 20:31:53.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.361857 --> 599.350415).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 624.574707  [    1/ 1184]\n",
      "train loss: 671.056030  [  101/ 1184]\n",
      "train loss: 612.528137  [  201/ 1184]\n",
      "train loss: 605.063354  [  301/ 1184]\n",
      "train loss: 606.279419  [  401/ 1184]\n",
      "train loss: 624.737000  [  501/ 1184]\n",
      "train loss: 652.237061  [  601/ 1184]\n",
      "train loss: 626.827698  [  701/ 1184]\n",
      "train loss: 574.058167  [  801/ 1184]\n",
      "train loss: 584.853027  [  901/ 1184]\n",
      "train loss: 563.927612  [ 1001/ 1184]\n",
      "train loss: 651.962524  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:32:05.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:05.910\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:07.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:07.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.8195190429688, 639.5494995117188, 548.8880004882812, 596.8115234375, 575.1970825195312]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:07.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.3847048216228 is lower than -599.3504153481013, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:07.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 640.647949  [    1/ 1184]\n",
      "train loss: 614.729858  [  101/ 1184]\n",
      "train loss: 589.416504  [  201/ 1184]\n",
      "train loss: 662.355347  [  301/ 1184]\n",
      "train loss: 604.899292  [  401/ 1184]\n",
      "train loss: 618.749084  [  501/ 1184]\n",
      "train loss: 573.552979  [  601/ 1184]\n",
      "train loss: 603.730164  [  701/ 1184]\n",
      "train loss: 633.303528  [  801/ 1184]\n",
      "train loss: 648.378296  [  901/ 1184]\n",
      "train loss: 635.485962  [ 1001/ 1184]\n",
      "train loss: 606.782776  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:32:19.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:19.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:20.995\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:20.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.671142578125, 639.5760498046875, 548.9161987304688, 596.64794921875, 575.1373901367188]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:20.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.3602114134197 is lower than -599.3504153481013, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:20.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 626.042175  [    1/ 1184]\n",
      "train loss: 679.274597  [  101/ 1184]\n",
      "train loss: 586.399902  [  201/ 1184]\n",
      "train loss: 542.616577  [  301/ 1184]\n",
      "train loss: 642.110352  [  401/ 1184]\n",
      "train loss: 578.591797  [  501/ 1184]\n",
      "train loss: 648.542480  [  601/ 1184]\n",
      "train loss: 636.847351  [  701/ 1184]\n",
      "train loss: 601.457520  [  801/ 1184]\n",
      "train loss: 639.614014  [  901/ 1184]\n",
      "train loss: 592.142151  [ 1001/ 1184]\n",
      "train loss: 565.992432  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:32:32.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:32.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:34.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:34.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.7501220703125, 639.5628051757812, 548.9218139648438, 596.6168212890625, 575.143310546875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:34.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.342921930627 is higher than -599.3504153481013, setting new best score to -599.342921930627\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:34.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.350415 --> 599.342922).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 601.073486  [    1/ 1184]\n",
      "train loss: 577.691162  [  101/ 1184]\n",
      "train loss: 608.815918  [  201/ 1184]\n",
      "train loss: 576.386902  [  301/ 1184]\n",
      "train loss: 527.253784  [  401/ 1184]\n",
      "train loss: 616.638794  [  501/ 1184]\n",
      "train loss: 635.217896  [  601/ 1184]\n",
      "train loss: 612.294312  [  701/ 1184]\n",
      "train loss: 620.481140  [  801/ 1184]\n",
      "train loss: 567.950195  [  901/ 1184]\n",
      "train loss: 595.921814  [ 1001/ 1184]\n",
      "train loss: 612.446472  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:32:45.993\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:45.994\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:47.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:47.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.7078247070312, 639.501220703125, 548.8675537109375, 596.6046142578125, 575.1505126953125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:47.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.3236318853837 is higher than -599.342921930627, setting new best score to -599.3236318853837\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:47.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.342922 --> 599.323632).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 580.957764  [    1/ 1184]\n",
      "train loss: 635.599121  [  101/ 1184]\n",
      "train loss: 617.967896  [  201/ 1184]\n",
      "train loss: 567.486328  [  301/ 1184]\n",
      "train loss: 569.160278  [  401/ 1184]\n",
      "train loss: 575.617004  [  501/ 1184]\n",
      "train loss: 634.801270  [  601/ 1184]\n",
      "train loss: 563.839600  [  701/ 1184]\n",
      "train loss: 598.437012  [  801/ 1184]\n",
      "train loss: 615.700623  [  901/ 1184]\n",
      "train loss: 607.350647  [ 1001/ 1184]\n",
      "train loss: 561.153809  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:32:59.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:32:59.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:00.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:00.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.63037109375, 639.396484375, 548.8865356445312, 596.6395874023438, 575.111572265625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:00.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.310360061066 is higher than -599.3236318853837, setting new best score to -599.310360061066\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:00.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.323632 --> 599.310360).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 570.664307  [    1/ 1184]\n",
      "train loss: 602.027771  [  101/ 1184]\n",
      "train loss: 631.011719  [  201/ 1184]\n",
      "train loss: 649.429077  [  301/ 1184]\n",
      "train loss: 631.156372  [  401/ 1184]\n",
      "train loss: 622.400818  [  501/ 1184]\n",
      "train loss: 604.282532  [  601/ 1184]\n",
      "train loss: 597.091248  [  701/ 1184]\n",
      "train loss: 585.491394  [  801/ 1184]\n",
      "train loss: 596.939270  [  901/ 1184]\n",
      "train loss: 621.306274  [ 1001/ 1184]\n",
      "train loss: 568.935181  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:33:12.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:12.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:14.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:14.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.5880126953125, 639.4252319335938, 548.82177734375, 596.6176147460938, 575.1382446289062]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:14.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.2901924229875 is higher than -599.310360061066, setting new best score to -599.2901924229875\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:14.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.310360 --> 599.290192).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 601.862305  [    1/ 1184]\n",
      "train loss: 621.681335  [  101/ 1184]\n",
      "train loss: 647.131958  [  201/ 1184]\n",
      "train loss: 640.255310  [  301/ 1184]\n",
      "train loss: 661.437256  [  401/ 1184]\n",
      "train loss: 573.927734  [  501/ 1184]\n",
      "train loss: 630.384338  [  601/ 1184]\n",
      "train loss: 611.695862  [  701/ 1184]\n",
      "train loss: 612.808655  [  801/ 1184]\n",
      "train loss: 598.039673  [  901/ 1184]\n",
      "train loss: 537.872009  [ 1001/ 1184]\n",
      "train loss: 577.297119  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:33:26.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:26.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:27.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:27.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.716064453125, 639.4390869140625, 548.8263549804688, 596.5040283203125, 575.1846923828125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:27.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.2977995667277 is lower than -599.2901924229875, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:27.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 610.832581  [    1/ 1184]\n",
      "train loss: 589.281677  [  101/ 1184]\n",
      "train loss: 624.521423  [  201/ 1184]\n",
      "train loss: 632.631287  [  301/ 1184]\n",
      "train loss: 610.311951  [  401/ 1184]\n",
      "train loss: 593.946228  [  501/ 1184]\n",
      "train loss: 568.702881  [  601/ 1184]\n",
      "train loss: 564.310303  [  701/ 1184]\n",
      "train loss: 646.765564  [  801/ 1184]\n",
      "train loss: 616.907715  [  901/ 1184]\n",
      "train loss: 610.334229  [ 1001/ 1184]\n",
      "train loss: 622.437378  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:33:39.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:39.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:41.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:41.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.5253295898438, 639.4827880859375, 548.8101196289062, 596.5523681640625, 575.1324462890625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:41.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.2740116167672 is higher than -599.2901924229875, setting new best score to -599.2740116167672\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:41.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.290192 --> 599.274012).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 567.521790  [    1/ 1184]\n",
      "train loss: 584.570374  [  101/ 1184]\n",
      "train loss: 569.115784  [  201/ 1184]\n",
      "train loss: 619.753662  [  301/ 1184]\n",
      "train loss: 609.748108  [  401/ 1184]\n",
      "train loss: 713.039490  [  501/ 1184]\n",
      "train loss: 574.466370  [  601/ 1184]\n",
      "train loss: 610.708008  [  701/ 1184]\n",
      "train loss: 581.239441  [  801/ 1184]\n",
      "train loss: 578.357849  [  901/ 1184]\n",
      "train loss: 649.927734  [ 1001/ 1184]\n",
      "train loss: 598.577087  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:33:52.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:52.866\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:54.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:54.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.4644775390625, 639.460693359375, 548.7763061523438, 596.54150390625, 575.0478515625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:54.474\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.2604276632961 is higher than -599.2740116167672, setting new best score to -599.2604276632961\u001b[0m\n",
      "\u001b[32m2023-11-26 20:33:54.475\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.274012 --> 599.260428).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 542.789185  [    1/ 1184]\n",
      "train loss: 598.831055  [  101/ 1184]\n",
      "train loss: 590.149475  [  201/ 1184]\n",
      "train loss: 622.015076  [  301/ 1184]\n",
      "train loss: 550.500732  [  401/ 1184]\n",
      "train loss: 674.868164  [  501/ 1184]\n",
      "train loss: 587.014893  [  601/ 1184]\n",
      "train loss: 665.229187  [  701/ 1184]\n",
      "train loss: 618.871887  [  801/ 1184]\n",
      "train loss: 651.591125  [  901/ 1184]\n",
      "train loss: 635.997253  [ 1001/ 1184]\n",
      "train loss: 602.788757  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:34:06.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:06.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:07.842\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:07.843\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.49755859375, 639.4110717773438, 548.7462158203125, 596.548828125, 575.060302734375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:07.844\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.2612064409859 is lower than -599.2604276632961, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:07.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 616.578796  [    1/ 1184]\n",
      "train loss: 588.681641  [  101/ 1184]\n",
      "train loss: 580.748535  [  201/ 1184]\n",
      "train loss: 591.763184  [  301/ 1184]\n",
      "train loss: 623.219055  [  401/ 1184]\n",
      "train loss: 630.518494  [  501/ 1184]\n",
      "train loss: 544.810791  [  601/ 1184]\n",
      "train loss: 557.092224  [  701/ 1184]\n",
      "train loss: 601.626221  [  801/ 1184]\n",
      "train loss: 578.438477  [  901/ 1184]\n",
      "train loss: 596.894226  [ 1001/ 1184]\n",
      "train loss: 619.279114  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:34:19.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:19.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:21.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:21.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.5332641601562, 639.3148193359375, 548.8428955078125, 596.4838256835938, 575.0927124023438]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:21.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.2502228942099 is higher than -599.2604276632961, setting new best score to -599.2502228942099\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:21.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.260428 --> 599.250223).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 645.411987  [    1/ 1184]\n",
      "train loss: 565.594299  [  101/ 1184]\n",
      "train loss: 673.595947  [  201/ 1184]\n",
      "train loss: 589.533691  [  301/ 1184]\n",
      "train loss: 593.770142  [  401/ 1184]\n",
      "train loss: 622.005310  [  501/ 1184]\n",
      "train loss: 604.918701  [  601/ 1184]\n",
      "train loss: 634.462891  [  701/ 1184]\n",
      "train loss: 587.636902  [  801/ 1184]\n",
      "train loss: 612.867554  [  901/ 1184]\n",
      "train loss: 642.094971  [ 1001/ 1184]\n",
      "train loss: 662.958130  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:34:32.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:32.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:34.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:34.487\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.5322875976562, 639.3154296875, 548.7662353515625, 596.47314453125, 575.013671875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:34.488\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.2411169124555 is higher than -599.2502228942099, setting new best score to -599.2411169124555\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:34.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.250223 --> 599.241117).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 546.345215  [    1/ 1184]\n",
      "train loss: 567.625305  [  101/ 1184]\n",
      "train loss: 669.259460  [  201/ 1184]\n",
      "train loss: 656.090332  [  301/ 1184]\n",
      "train loss: 550.065613  [  401/ 1184]\n",
      "train loss: 549.698914  [  501/ 1184]\n",
      "train loss: 661.671936  [  601/ 1184]\n",
      "train loss: 649.848145  [  701/ 1184]\n",
      "train loss: 633.671692  [  801/ 1184]\n",
      "train loss: 668.953613  [  901/ 1184]\n",
      "train loss: 616.963074  [ 1001/ 1184]\n",
      "train loss: 627.048889  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:34:45.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:45.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:47.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:47.482\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.46728515625, 639.3197021484375, 548.8072509765625, 596.4619140625, 575.0477905273438]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:47.483\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.2258962896806 is higher than -599.2411169124555, setting new best score to -599.2258962896806\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:47.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.241117 --> 599.225896).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 583.253296  [    1/ 1184]\n",
      "train loss: 609.306396  [  101/ 1184]\n",
      "train loss: 650.426636  [  201/ 1184]\n",
      "train loss: 606.075012  [  301/ 1184]\n",
      "train loss: 679.090149  [  401/ 1184]\n",
      "train loss: 602.641602  [  501/ 1184]\n",
      "train loss: 626.164734  [  601/ 1184]\n",
      "train loss: 707.373230  [  701/ 1184]\n",
      "train loss: 573.813721  [  801/ 1184]\n",
      "train loss: 628.864258  [  901/ 1184]\n",
      "train loss: 647.853577  [ 1001/ 1184]\n",
      "train loss: 605.042236  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:34:58.855\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:34:58.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:00.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:00.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.3923950195312, 639.3057861328125, 548.796142578125, 596.5003051757812, 575.0592041015625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:00.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.2201380476167 is higher than -599.2258962896806, setting new best score to -599.2201380476167\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:00.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.225896 --> 599.220138).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 595.165649  [    1/ 1184]\n",
      "train loss: 559.763306  [  101/ 1184]\n",
      "train loss: 640.408325  [  201/ 1184]\n",
      "train loss: 598.414124  [  301/ 1184]\n",
      "train loss: 636.328247  [  401/ 1184]\n",
      "train loss: 630.370850  [  501/ 1184]\n",
      "train loss: 638.326477  [  601/ 1184]\n",
      "train loss: 563.159851  [  701/ 1184]\n",
      "train loss: 551.374573  [  801/ 1184]\n",
      "train loss: 621.408447  [  901/ 1184]\n",
      "train loss: 640.726990  [ 1001/ 1184]\n",
      "train loss: 598.708374  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:35:12.203\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:12.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:13.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:13.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.4570922851562, 639.1770629882812, 548.8541259765625, 596.5226440429688, 574.9823608398438]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:13.829\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.2039079497132 is higher than -599.2201380476167, setting new best score to -599.2039079497132\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:13.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.220138 --> 599.203908).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 603.255249  [    1/ 1184]\n",
      "train loss: 630.014587  [  101/ 1184]\n",
      "train loss: 567.776733  [  201/ 1184]\n",
      "train loss: 686.046692  [  301/ 1184]\n",
      "train loss: 552.295044  [  401/ 1184]\n",
      "train loss: 586.742310  [  501/ 1184]\n",
      "train loss: 584.246033  [  601/ 1184]\n",
      "train loss: 665.959290  [  701/ 1184]\n",
      "train loss: 636.354980  [  801/ 1184]\n",
      "train loss: 661.616272  [  901/ 1184]\n",
      "train loss: 602.405396  [ 1001/ 1184]\n",
      "train loss: 589.768250  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:35:25.611\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:25.612\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:27.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:27.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.5068359375, 639.203857421875, 548.7530517578125, 596.431640625, 574.9591674804688]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:27.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.2053084361403 is lower than -599.2039079497132, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:27.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 577.937012  [    1/ 1184]\n",
      "train loss: 673.828064  [  101/ 1184]\n",
      "train loss: 608.330994  [  201/ 1184]\n",
      "train loss: 562.570312  [  301/ 1184]\n",
      "train loss: 619.019043  [  401/ 1184]\n",
      "train loss: 614.244507  [  501/ 1184]\n",
      "train loss: 607.051270  [  601/ 1184]\n",
      "train loss: 617.853271  [  701/ 1184]\n",
      "train loss: 650.171143  [  801/ 1184]\n",
      "train loss: 598.897156  [  901/ 1184]\n",
      "train loss: 619.249329  [ 1001/ 1184]\n",
      "train loss: 529.200806  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:35:38.810\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:38.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:40.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:40.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.369873046875, 639.2760009765625, 548.7521362304688, 596.4420776367188, 574.9910888671875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:40.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.1970464392554 is higher than -599.2039079497132, setting new best score to -599.1970464392554\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:40.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.203908 --> 599.197046).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 544.350098  [    1/ 1184]\n",
      "train loss: 626.907898  [  101/ 1184]\n",
      "train loss: 579.714478  [  201/ 1184]\n",
      "train loss: 572.256531  [  301/ 1184]\n",
      "train loss: 613.175232  [  401/ 1184]\n",
      "train loss: 568.479736  [  501/ 1184]\n",
      "train loss: 559.583313  [  601/ 1184]\n",
      "train loss: 610.677490  [  701/ 1184]\n",
      "train loss: 569.279358  [  801/ 1184]\n",
      "train loss: 541.200012  [  901/ 1184]\n",
      "train loss: 592.980042  [ 1001/ 1184]\n",
      "train loss: 549.690308  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:35:51.811\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:51.812\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:53.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:53.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.3899536132812, 639.220947265625, 548.7412109375, 596.3425903320312, 574.9354858398438]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:53.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.1777197729183 is higher than -599.1970464392554, setting new best score to -599.1777197729183\u001b[0m\n",
      "\u001b[32m2023-11-26 20:35:53.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.197046 --> 599.177720).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 621.822021  [    1/ 1184]\n",
      "train loss: 589.604126  [  101/ 1184]\n",
      "train loss: 636.989990  [  201/ 1184]\n",
      "train loss: 506.849548  [  301/ 1184]\n",
      "train loss: 578.203796  [  401/ 1184]\n",
      "train loss: 560.558228  [  501/ 1184]\n",
      "train loss: 633.433960  [  601/ 1184]\n",
      "train loss: 633.501831  [  701/ 1184]\n",
      "train loss: 556.246704  [  801/ 1184]\n",
      "train loss: 612.576111  [  901/ 1184]\n",
      "train loss: 627.379517  [ 1001/ 1184]\n",
      "train loss: 586.900269  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:36:05.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:05.489\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:07.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:07.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.4053955078125, 639.2799072265625, 548.6661987304688, 596.3638916015625, 575.0062255859375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:07.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.1849052332625 is lower than -599.1777197729183, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:07.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 648.869141  [    1/ 1184]\n",
      "train loss: 590.484558  [  101/ 1184]\n",
      "train loss: 597.254639  [  201/ 1184]\n",
      "train loss: 582.989441  [  301/ 1184]\n",
      "train loss: 608.121277  [  401/ 1184]\n",
      "train loss: 546.664001  [  501/ 1184]\n",
      "train loss: 565.384583  [  601/ 1184]\n",
      "train loss: 624.178833  [  701/ 1184]\n",
      "train loss: 582.214355  [  801/ 1184]\n",
      "train loss: 657.338745  [  901/ 1184]\n",
      "train loss: 621.960571  [ 1001/ 1184]\n",
      "train loss: 551.308960  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:36:18.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:18.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:20.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:20.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.37158203125, 639.3085327148438, 548.6461181640625, 596.46728515625, 575.028564453125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:20.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.1799089262757 is lower than -599.1777197729183, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:20.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 642.008301  [    1/ 1184]\n",
      "train loss: 605.560852  [  101/ 1184]\n",
      "train loss: 560.169983  [  201/ 1184]\n",
      "train loss: 605.821411  [  301/ 1184]\n",
      "train loss: 616.299622  [  401/ 1184]\n",
      "train loss: 604.431152  [  501/ 1184]\n",
      "train loss: 590.615967  [  601/ 1184]\n",
      "train loss: 629.586792  [  701/ 1184]\n",
      "train loss: 578.475952  [  801/ 1184]\n",
      "train loss: 530.079346  [  901/ 1184]\n",
      "train loss: 648.515747  [ 1001/ 1184]\n",
      "train loss: 545.138245  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:36:31.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:31.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:33.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:33.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.3569946289062, 639.2055053710938, 548.6089477539062, 596.3853759765625, 574.9266357421875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:33.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.1451997781102 is higher than -599.1777197729183, setting new best score to -599.1451997781102\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:33.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.177720 --> 599.145200).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 602.577332  [    1/ 1184]\n",
      "train loss: 633.438232  [  101/ 1184]\n",
      "train loss: 637.136780  [  201/ 1184]\n",
      "train loss: 583.795349  [  301/ 1184]\n",
      "train loss: 597.611816  [  401/ 1184]\n",
      "train loss: 596.495361  [  501/ 1184]\n",
      "train loss: 543.159668  [  601/ 1184]\n",
      "train loss: 610.687744  [  701/ 1184]\n",
      "train loss: 578.937683  [  801/ 1184]\n",
      "train loss: 594.676392  [  901/ 1184]\n",
      "train loss: 597.532288  [ 1001/ 1184]\n",
      "train loss: 655.861694  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:36:44.860\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:44.861\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:46.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:46.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.3447875976562, 639.288818359375, 548.6773071289062, 596.384521484375, 574.9713134765625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:46.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.1541501588459 is lower than -599.1451997781102, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:46.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 612.930725  [    1/ 1184]\n",
      "train loss: 610.687439  [  101/ 1184]\n",
      "train loss: 571.346069  [  201/ 1184]\n",
      "train loss: 605.835938  [  301/ 1184]\n",
      "train loss: 644.538269  [  401/ 1184]\n",
      "train loss: 598.604797  [  501/ 1184]\n",
      "train loss: 640.518799  [  601/ 1184]\n",
      "train loss: 564.228638  [  701/ 1184]\n",
      "train loss: 627.760681  [  801/ 1184]\n",
      "train loss: 535.082825  [  901/ 1184]\n",
      "train loss: 600.788391  [ 1001/ 1184]\n",
      "train loss: 563.794861  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:36:58.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:58.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:59.705\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:59.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.2789306640625, 639.2732543945312, 548.628662109375, 596.3778076171875, 575.0543212890625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:59.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.1383180256131 is higher than -599.1451997781102, setting new best score to -599.1383180256131\u001b[0m\n",
      "\u001b[32m2023-11-26 20:36:59.708\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.145200 --> 599.138318).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 609.036194  [    1/ 1184]\n",
      "train loss: 588.259521  [  101/ 1184]\n",
      "train loss: 552.457703  [  201/ 1184]\n",
      "train loss: 605.066040  [  301/ 1184]\n",
      "train loss: 637.017456  [  401/ 1184]\n",
      "train loss: 572.970276  [  501/ 1184]\n",
      "train loss: 589.483398  [  601/ 1184]\n",
      "train loss: 603.237305  [  701/ 1184]\n",
      "train loss: 633.339233  [  801/ 1184]\n",
      "train loss: 633.391296  [  901/ 1184]\n",
      "train loss: 643.553772  [ 1001/ 1184]\n",
      "train loss: 602.869812  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:37:11.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:11.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:13.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:13.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.257568359375, 639.2646484375, 548.6697998046875, 596.3101806640625, 574.9608764648438]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:13.411\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.1178186344195 is higher than -599.1383180256131, setting new best score to -599.1178186344195\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:13.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.138318 --> 599.117819).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 590.171326  [    1/ 1184]\n",
      "train loss: 604.775757  [  101/ 1184]\n",
      "train loss: 589.690613  [  201/ 1184]\n",
      "train loss: 548.017883  [  301/ 1184]\n",
      "train loss: 548.553101  [  401/ 1184]\n",
      "train loss: 629.816956  [  501/ 1184]\n",
      "train loss: 549.418152  [  601/ 1184]\n",
      "train loss: 693.911682  [  701/ 1184]\n",
      "train loss: 579.930847  [  801/ 1184]\n",
      "train loss: 611.666199  [  901/ 1184]\n",
      "train loss: 591.403687  [ 1001/ 1184]\n",
      "train loss: 609.030579  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:37:24.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:24.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:26.536\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:26.537\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.3158569335938, 639.2017211914062, 548.6481323242188, 596.3160400390625, 574.9678955078125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:26.538\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.1339259666732 is lower than -599.1178186344195, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:26.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 604.214172  [    1/ 1184]\n",
      "train loss: 559.811157  [  101/ 1184]\n",
      "train loss: 564.985107  [  201/ 1184]\n",
      "train loss: 587.986328  [  301/ 1184]\n",
      "train loss: 625.672363  [  401/ 1184]\n",
      "train loss: 587.688599  [  501/ 1184]\n",
      "train loss: 597.587646  [  601/ 1184]\n",
      "train loss: 567.765381  [  701/ 1184]\n",
      "train loss: 645.411499  [  801/ 1184]\n",
      "train loss: 524.090088  [  901/ 1184]\n",
      "train loss: 650.933777  [ 1001/ 1184]\n",
      "train loss: 590.079529  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:37:38.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:38.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:39.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:39.806\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.3182373046875, 639.269775390625, 548.637939453125, 596.3319702148438, 574.9793701171875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:39.807\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.1348044866248 is lower than -599.1178186344195, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:39.808\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 552.129822  [    1/ 1184]\n",
      "train loss: 613.074280  [  101/ 1184]\n",
      "train loss: 584.384155  [  201/ 1184]\n",
      "train loss: 622.406006  [  301/ 1184]\n",
      "train loss: 566.672485  [  401/ 1184]\n",
      "train loss: 545.536865  [  501/ 1184]\n",
      "train loss: 604.412842  [  601/ 1184]\n",
      "train loss: 579.167114  [  701/ 1184]\n",
      "train loss: 657.606873  [  801/ 1184]\n",
      "train loss: 600.130859  [  901/ 1184]\n",
      "train loss: 639.053162  [ 1001/ 1184]\n",
      "train loss: 664.565918  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:37:51.391\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:51.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:52.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:52.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.2672119140625, 639.243408203125, 548.6315307617188, 596.2498779296875, 574.8942260742188]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:52.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.1151425904866 is higher than -599.1178186344195, setting new best score to -599.1151425904866\u001b[0m\n",
      "\u001b[32m2023-11-26 20:37:52.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.117819 --> 599.115143).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 561.314758  [    1/ 1184]\n",
      "train loss: 603.096252  [  101/ 1184]\n",
      "train loss: 566.100708  [  201/ 1184]\n",
      "train loss: 542.810974  [  301/ 1184]\n",
      "train loss: 488.597198  [  401/ 1184]\n",
      "train loss: 632.064392  [  501/ 1184]\n",
      "train loss: 613.982117  [  601/ 1184]\n",
      "train loss: 565.114319  [  701/ 1184]\n",
      "train loss: 659.260254  [  801/ 1184]\n",
      "train loss: 618.092834  [  901/ 1184]\n",
      "train loss: 573.749268  [ 1001/ 1184]\n",
      "train loss: 614.019836  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:38:04.601\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:04.602\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:06.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:06.213\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.2467651367188, 639.130859375, 548.6279907226562, 596.2177734375, 574.8997802734375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:06.214\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.0965188328224 is higher than -599.1151425904866, setting new best score to -599.0965188328224\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:06.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.115143 --> 599.096519).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 624.001526  [    1/ 1184]\n",
      "train loss: 618.270447  [  101/ 1184]\n",
      "train loss: 563.241821  [  201/ 1184]\n",
      "train loss: 588.320435  [  301/ 1184]\n",
      "train loss: 596.621277  [  401/ 1184]\n",
      "train loss: 562.159424  [  501/ 1184]\n",
      "train loss: 589.576294  [  601/ 1184]\n",
      "train loss: 597.783875  [  701/ 1184]\n",
      "train loss: 576.132935  [  801/ 1184]\n",
      "train loss: 618.028442  [  901/ 1184]\n",
      "train loss: 576.903137  [ 1001/ 1184]\n",
      "train loss: 604.873535  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:38:17.895\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:17.896\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:19.556\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:19.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.2725830078125, 639.0894165039062, 548.6387329101562, 596.2445068359375, 574.887939453125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:19.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.0991017015674 is lower than -599.0965188328224, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:19.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 592.760315  [    1/ 1184]\n",
      "train loss: 615.010620  [  101/ 1184]\n",
      "train loss: 602.257812  [  201/ 1184]\n",
      "train loss: 579.233276  [  301/ 1184]\n",
      "train loss: 650.428894  [  401/ 1184]\n",
      "train loss: 650.873413  [  501/ 1184]\n",
      "train loss: 567.250366  [  601/ 1184]\n",
      "train loss: 563.120422  [  701/ 1184]\n",
      "train loss: 568.576965  [  801/ 1184]\n",
      "train loss: 584.340637  [  901/ 1184]\n",
      "train loss: 606.243164  [ 1001/ 1184]\n",
      "train loss: 672.148621  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:38:31.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:31.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:32.709\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:32.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.2584228515625, 639.15771484375, 548.615478515625, 596.27978515625, 574.831787109375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:32.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.0950211537036 is higher than -599.0965188328224, setting new best score to -599.0950211537036\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:32.712\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.096519 --> 599.095021).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 660.287903  [    1/ 1184]\n",
      "train loss: 639.949463  [  101/ 1184]\n",
      "train loss: 563.594971  [  201/ 1184]\n",
      "train loss: 589.122864  [  301/ 1184]\n",
      "train loss: 606.576233  [  401/ 1184]\n",
      "train loss: 575.600769  [  501/ 1184]\n",
      "train loss: 586.106445  [  601/ 1184]\n",
      "train loss: 626.812744  [  701/ 1184]\n",
      "train loss: 608.569702  [  801/ 1184]\n",
      "train loss: 587.990173  [  901/ 1184]\n",
      "train loss: 621.393677  [ 1001/ 1184]\n",
      "train loss: 607.014893  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:38:44.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:44.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:45.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:45.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.2320556640625, 639.150390625, 548.5866088867188, 596.2387084960938, 574.8474731445312]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:45.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.0705815955054 is higher than -599.0950211537036, setting new best score to -599.0705815955054\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:45.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.095021 --> 599.070582).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 584.221924  [    1/ 1184]\n",
      "train loss: 553.054688  [  101/ 1184]\n",
      "train loss: 643.423828  [  201/ 1184]\n",
      "train loss: 582.381775  [  301/ 1184]\n",
      "train loss: 594.618896  [  401/ 1184]\n",
      "train loss: 568.386597  [  501/ 1184]\n",
      "train loss: 632.399597  [  601/ 1184]\n",
      "train loss: 628.832397  [  701/ 1184]\n",
      "train loss: 654.640198  [  801/ 1184]\n",
      "train loss: 625.618591  [  901/ 1184]\n",
      "train loss: 619.616882  [ 1001/ 1184]\n",
      "train loss: 591.349121  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:38:57.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:57.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:59.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:59.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.2310180664062, 639.2095947265625, 548.5765380859375, 596.2514038085938, 574.8548583984375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:59.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.091707717316 is lower than -599.0705815955054, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:38:59.192\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 594.374207  [    1/ 1184]\n",
      "train loss: 594.360840  [  101/ 1184]\n",
      "train loss: 633.415344  [  201/ 1184]\n",
      "train loss: 549.122009  [  301/ 1184]\n",
      "train loss: 649.495178  [  401/ 1184]\n",
      "train loss: 594.695923  [  501/ 1184]\n",
      "train loss: 635.765137  [  601/ 1184]\n",
      "train loss: 662.443481  [  701/ 1184]\n",
      "train loss: 568.144531  [  801/ 1184]\n",
      "train loss: 608.703979  [  901/ 1184]\n",
      "train loss: 630.572998  [ 1001/ 1184]\n",
      "train loss: 587.603760  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:39:10.681\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:10.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:12.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:12.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.150146484375, 639.1807861328125, 548.52001953125, 596.1934814453125, 574.8711547851562]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:12.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.0452643672122 is higher than -599.0705815955054, setting new best score to -599.0452643672122\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:12.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.070582 --> 599.045264).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 523.120972  [    1/ 1184]\n",
      "train loss: 622.432922  [  101/ 1184]\n",
      "train loss: 526.270447  [  201/ 1184]\n",
      "train loss: 612.948853  [  301/ 1184]\n",
      "train loss: 596.268066  [  401/ 1184]\n",
      "train loss: 588.704712  [  501/ 1184]\n",
      "train loss: 598.173035  [  601/ 1184]\n",
      "train loss: 622.051697  [  701/ 1184]\n",
      "train loss: 588.515015  [  801/ 1184]\n",
      "train loss: 564.098633  [  901/ 1184]\n",
      "train loss: 624.127991  [ 1001/ 1184]\n",
      "train loss: 545.308899  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:39:23.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:23.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:25.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:25.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.14794921875, 639.2002563476562, 548.6054077148438, 596.251708984375, 574.8455200195312]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:25.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.049330931072 is lower than -599.0452643672122, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:25.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 623.123840  [    1/ 1184]\n",
      "train loss: 625.083740  [  101/ 1184]\n",
      "train loss: 693.607117  [  201/ 1184]\n",
      "train loss: 597.845886  [  301/ 1184]\n",
      "train loss: 669.568665  [  401/ 1184]\n",
      "train loss: 534.952271  [  501/ 1184]\n",
      "train loss: 639.258057  [  601/ 1184]\n",
      "train loss: 555.579895  [  701/ 1184]\n",
      "train loss: 602.892761  [  801/ 1184]\n",
      "train loss: 630.319214  [  901/ 1184]\n",
      "train loss: 523.872864  [ 1001/ 1184]\n",
      "train loss: 680.529419  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:39:36.956\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:36.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:38.553\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:38.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.182861328125, 639.1822509765625, 548.6348876953125, 596.2588500976562, 574.7550659179688]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:38.555\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -599.0613046380538 is lower than -599.0452643672122, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:38.557\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 574.256958  [    1/ 1184]\n",
      "train loss: 615.610535  [  101/ 1184]\n",
      "train loss: 636.628296  [  201/ 1184]\n",
      "train loss: 652.612366  [  301/ 1184]\n",
      "train loss: 577.306274  [  401/ 1184]\n",
      "train loss: 576.328064  [  501/ 1184]\n",
      "train loss: 568.835205  [  601/ 1184]\n",
      "train loss: 605.495850  [  701/ 1184]\n",
      "train loss: 646.710266  [  801/ 1184]\n",
      "train loss: 604.397034  [  901/ 1184]\n",
      "train loss: 604.608643  [ 1001/ 1184]\n",
      "train loss: 541.747559  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:39:50.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:50.080\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:51.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:51.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.1255493164062, 639.1480712890625, 548.5472412109375, 596.262939453125, 574.773193359375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:51.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.0121502453768 is higher than -599.0452643672122, setting new best score to -599.0121502453768\u001b[0m\n",
      "\u001b[32m2023-11-26 20:39:51.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.045264 --> 599.012150).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 602.374939  [    1/ 1184]\n",
      "train loss: 636.524841  [  101/ 1184]\n",
      "train loss: 649.222412  [  201/ 1184]\n",
      "train loss: 609.490356  [  301/ 1184]\n",
      "train loss: 592.619446  [  401/ 1184]\n",
      "train loss: 602.479187  [  501/ 1184]\n",
      "train loss: 626.007874  [  601/ 1184]\n",
      "train loss: 568.143066  [  701/ 1184]\n",
      "train loss: 577.337646  [  801/ 1184]\n",
      "train loss: 593.252014  [  901/ 1184]\n",
      "train loss: 535.213989  [ 1001/ 1184]\n",
      "train loss: 588.089478  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:40:03.274\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:03.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:04.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:04.891\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.126708984375, 639.2586669921875, 548.6006469726562, 596.1627197265625, 574.7408447265625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:04.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -598.9960242935374 is higher than -599.0121502453768, setting new best score to -598.9960242935374\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:04.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.012150 --> 598.996024).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 661.918701  [    1/ 1184]\n",
      "train loss: 593.614441  [  101/ 1184]\n",
      "train loss: 570.599670  [  201/ 1184]\n",
      "train loss: 556.657654  [  301/ 1184]\n",
      "train loss: 613.391296  [  401/ 1184]\n",
      "train loss: 654.299255  [  501/ 1184]\n",
      "train loss: 616.277344  [  601/ 1184]\n",
      "train loss: 553.998413  [  701/ 1184]\n",
      "train loss: 560.213318  [  801/ 1184]\n",
      "train loss: 624.207642  [  901/ 1184]\n",
      "train loss: 603.634460  [ 1001/ 1184]\n",
      "train loss: 564.534546  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:40:16.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:16.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:18.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:18.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.16357421875, 639.1220092773438, 548.5421142578125, 596.159423828125, 574.6915283203125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:18.129\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -598.9828958632071 is higher than -598.9960242935374, setting new best score to -598.9828958632071\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:18.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (598.996024 --> 598.982896).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 580.968567  [    1/ 1184]\n",
      "train loss: 529.151855  [  101/ 1184]\n",
      "train loss: 560.844482  [  201/ 1184]\n",
      "train loss: 627.968384  [  301/ 1184]\n",
      "train loss: 651.641235  [  401/ 1184]\n",
      "train loss: 647.675049  [  501/ 1184]\n",
      "train loss: 570.439453  [  601/ 1184]\n",
      "train loss: 561.030945  [  701/ 1184]\n",
      "train loss: 573.445129  [  801/ 1184]\n",
      "train loss: 622.483337  [  901/ 1184]\n",
      "train loss: 601.679626  [ 1001/ 1184]\n",
      "train loss: 625.659912  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:40:30.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:30.140\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:31.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:31.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.083251953125, 639.0565185546875, 548.508056640625, 596.1090087890625, 574.727783203125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:31.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -598.9759449632862 is higher than -598.9828958632071, setting new best score to -598.9759449632862\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:31.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (598.982896 --> 598.975945).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 638.883057  [    1/ 1184]\n",
      "train loss: 642.504150  [  101/ 1184]\n",
      "train loss: 680.376282  [  201/ 1184]\n",
      "train loss: 584.519592  [  301/ 1184]\n",
      "train loss: 641.001465  [  401/ 1184]\n",
      "train loss: 640.151978  [  501/ 1184]\n",
      "train loss: 622.890503  [  601/ 1184]\n",
      "train loss: 601.200012  [  701/ 1184]\n",
      "train loss: 608.658875  [  801/ 1184]\n",
      "train loss: 682.399963  [  901/ 1184]\n",
      "train loss: 615.968140  [ 1001/ 1184]\n",
      "train loss: 584.518066  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:40:43.392\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:43.393\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:44.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:45.002\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.041015625, 639.13037109375, 548.5582885742188, 596.1841430664062, 574.70947265625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:45.004\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -598.9391355104084 is higher than -598.9759449632862, setting new best score to -598.9391355104084\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:45.006\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (598.975945 --> 598.939136).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 596.987305  [    1/ 1184]\n",
      "train loss: 598.146240  [  101/ 1184]\n",
      "train loss: 522.674011  [  201/ 1184]\n",
      "train loss: 572.097656  [  301/ 1184]\n",
      "train loss: 620.828674  [  401/ 1184]\n",
      "train loss: 611.978882  [  501/ 1184]\n",
      "train loss: 650.805847  [  601/ 1184]\n",
      "train loss: 591.170288  [  701/ 1184]\n",
      "train loss: 635.725342  [  801/ 1184]\n",
      "train loss: 612.936646  [  901/ 1184]\n",
      "train loss: 605.327820  [ 1001/ 1184]\n",
      "train loss: 657.230469  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:40:56.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:56.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:58.337\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:58.338\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.0120239257812, 639.0574951171875, 548.6170654296875, 596.09033203125, 574.667724609375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:58.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -598.9506764085987 is lower than -598.9391355104084, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:40:58.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 626.142517  [    1/ 1184]\n",
      "train loss: 549.383606  [  101/ 1184]\n",
      "train loss: 549.725952  [  201/ 1184]\n",
      "train loss: 596.403015  [  301/ 1184]\n",
      "train loss: 603.359863  [  401/ 1184]\n",
      "train loss: 575.343506  [  501/ 1184]\n",
      "train loss: 564.141052  [  601/ 1184]\n",
      "train loss: 545.520203  [  701/ 1184]\n",
      "train loss: 536.350281  [  801/ 1184]\n",
      "train loss: 619.284912  [  901/ 1184]\n",
      "train loss: 597.324829  [ 1001/ 1184]\n",
      "train loss: 618.765686  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:41:09.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:09.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:11.446\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:11.447\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.11474609375, 639.111083984375, 548.5562133789062, 596.0772094726562, 574.6593017578125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:11.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -598.9472456147399 is lower than -598.9391355104084, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:11.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 655.228027  [    1/ 1184]\n",
      "train loss: 594.721130  [  101/ 1184]\n",
      "train loss: 607.996216  [  201/ 1184]\n",
      "train loss: 661.235779  [  301/ 1184]\n",
      "train loss: 560.911072  [  401/ 1184]\n",
      "train loss: 586.885864  [  501/ 1184]\n",
      "train loss: 632.003479  [  601/ 1184]\n",
      "train loss: 593.958313  [  701/ 1184]\n",
      "train loss: 612.562073  [  801/ 1184]\n",
      "train loss: 633.479004  [  901/ 1184]\n",
      "train loss: 586.662048  [ 1001/ 1184]\n",
      "train loss: 646.301880  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:41:22.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:22.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:24.457\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:24.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.0476684570312, 639.0361328125, 548.5415649414062, 596.1190185546875, 574.6903686523438]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:24.458\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -598.9148622150663 is higher than -598.9391355104084, setting new best score to -598.9148622150663\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:24.459\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (598.939136 --> 598.914862).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 586.281982  [    1/ 1184]\n",
      "train loss: 650.025940  [  101/ 1184]\n",
      "train loss: 594.099182  [  201/ 1184]\n",
      "train loss: 638.945740  [  301/ 1184]\n",
      "train loss: 633.320496  [  401/ 1184]\n",
      "train loss: 608.994995  [  501/ 1184]\n",
      "train loss: 600.019531  [  601/ 1184]\n",
      "train loss: 595.395630  [  701/ 1184]\n",
      "train loss: 614.157043  [  801/ 1184]\n",
      "train loss: 613.365479  [  901/ 1184]\n",
      "train loss: 617.115723  [ 1001/ 1184]\n",
      "train loss: 574.213623  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:41:35.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:35.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:37.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:37.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.0386962890625, 639.0642700195312, 548.540283203125, 596.0963134765625, 574.6796264648438]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:37.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -598.9097630754302 is higher than -598.9148622150663, setting new best score to -598.9097630754302\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:37.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (598.914862 --> 598.909763).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 652.895569  [    1/ 1184]\n",
      "train loss: 516.618958  [  101/ 1184]\n",
      "train loss: 620.860718  [  201/ 1184]\n",
      "train loss: 574.238831  [  301/ 1184]\n",
      "train loss: 614.958069  [  401/ 1184]\n",
      "train loss: 589.049194  [  501/ 1184]\n",
      "train loss: 657.587097  [  601/ 1184]\n",
      "train loss: 567.685852  [  701/ 1184]\n",
      "train loss: 599.137756  [  801/ 1184]\n",
      "train loss: 631.009705  [  901/ 1184]\n",
      "train loss: 586.290955  [ 1001/ 1184]\n",
      "train loss: 592.186523  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:41:48.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:48.944\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:50.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:50.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.0596313476562, 639.0523071289062, 548.5257568359375, 595.9986572265625, 574.648681640625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:50.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -598.9160407343998 is lower than -598.9097630754302, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:41:50.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 630.687622  [    1/ 1184]\n",
      "train loss: 578.248352  [  101/ 1184]\n",
      "train loss: 535.665039  [  201/ 1184]\n",
      "train loss: 641.064209  [  301/ 1184]\n",
      "train loss: 641.095520  [  401/ 1184]\n",
      "train loss: 565.242004  [  501/ 1184]\n",
      "train loss: 608.465088  [  601/ 1184]\n",
      "train loss: 634.060974  [  701/ 1184]\n",
      "train loss: 564.931641  [  801/ 1184]\n",
      "train loss: 607.408630  [  901/ 1184]\n",
      "train loss: 583.992065  [ 1001/ 1184]\n",
      "train loss: 550.100159  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:42:02.119\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:02.120\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:03.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:03.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.0353393554688, 639.1217041015625, 548.524658203125, 596.0839233398438, 574.666259765625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:03.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -598.9156501093997 is lower than -598.9097630754302, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:03.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 662.152649  [    1/ 1184]\n",
      "train loss: 671.078003  [  101/ 1184]\n",
      "train loss: 600.067566  [  201/ 1184]\n",
      "train loss: 708.707764  [  301/ 1184]\n",
      "train loss: 586.179688  [  401/ 1184]\n",
      "train loss: 634.622314  [  501/ 1184]\n",
      "train loss: 548.487488  [  601/ 1184]\n",
      "train loss: 603.254395  [  701/ 1184]\n",
      "train loss: 616.633240  [  801/ 1184]\n",
      "train loss: 655.318115  [  901/ 1184]\n",
      "train loss: 657.502563  [ 1001/ 1184]\n",
      "train loss: 630.789429  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:42:15.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:15.408\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:17.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:17.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.0006713867188, 639.0604248046875, 548.5302734375, 596.09716796875, 574.6290893554688]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:17.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -598.918922520891 is lower than -598.9097630754302, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:17.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 3 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 641.830383  [    1/ 1184]\n",
      "train loss: 659.553589  [  101/ 1184]\n",
      "train loss: 592.890381  [  201/ 1184]\n",
      "train loss: 610.965454  [  301/ 1184]\n",
      "train loss: 530.673828  [  401/ 1184]\n",
      "train loss: 651.131348  [  501/ 1184]\n",
      "train loss: 604.084961  [  601/ 1184]\n",
      "train loss: 544.411499  [  701/ 1184]\n",
      "train loss: 582.658386  [  801/ 1184]\n",
      "train loss: 612.302734  [  901/ 1184]\n",
      "train loss: 585.784180  [ 1001/ 1184]\n",
      "train loss: 561.786804  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:42:28.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:28.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:30.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:30.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [615.9935913085938, 638.960205078125, 548.4871826171875, 596.0154418945312, 574.7176513671875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:30.361\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -598.8972161787975 is higher than -598.9097630754302, setting new best score to -598.8972161787975\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:30.362\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (598.909763 --> 598.897216).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 628.544678  [    1/ 1184]\n",
      "train loss: 569.150574  [  101/ 1184]\n",
      "train loss: 556.911926  [  201/ 1184]\n",
      "train loss: 602.330200  [  301/ 1184]\n",
      "train loss: 705.312378  [  401/ 1184]\n",
      "train loss: 647.577332  [  501/ 1184]\n",
      "train loss: 596.772400  [  601/ 1184]\n",
      "train loss: 602.714478  [  701/ 1184]\n",
      "train loss: 633.567627  [  801/ 1184]\n",
      "train loss: 608.126343  [  901/ 1184]\n",
      "train loss: 581.906616  [ 1001/ 1184]\n",
      "train loss: 631.808044  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:42:42.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:42.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:44.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:44.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [615.961181640625, 639.011474609375, 548.4528198242188, 596.044189453125, 574.6549072265625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:44.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -598.8871010309533 is higher than -598.8972161787975, setting new best score to -598.8871010309533\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:44.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (598.897216 --> 598.887101).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 660.591187  [    1/ 1184]\n",
      "train loss: 615.362061  [  101/ 1184]\n",
      "train loss: 574.349426  [  201/ 1184]\n",
      "train loss: 565.585876  [  301/ 1184]\n",
      "train loss: 644.242249  [  401/ 1184]\n",
      "train loss: 521.319824  [  501/ 1184]\n",
      "train loss: 628.448730  [  601/ 1184]\n",
      "train loss: 669.002625  [  701/ 1184]\n",
      "train loss: 541.862305  [  801/ 1184]\n",
      "train loss: 565.657532  [  901/ 1184]\n",
      "train loss: 555.990784  [ 1001/ 1184]\n",
      "train loss: 586.879700  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:42:55.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:55.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:57.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:57.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [615.9453735351562, 639.0321044921875, 548.5023193359375, 595.9765625, 574.6260986328125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:57.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -598.889991006972 is lower than -598.8871010309533, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:42:57.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 672.093262  [    1/ 1184]\n",
      "train loss: 612.546570  [  101/ 1184]\n",
      "train loss: 653.474976  [  201/ 1184]\n",
      "train loss: 593.487183  [  301/ 1184]\n",
      "train loss: 569.837708  [  401/ 1184]\n",
      "train loss: 604.721924  [  501/ 1184]\n",
      "train loss: 601.611938  [  601/ 1184]\n",
      "train loss: 636.514465  [  701/ 1184]\n",
      "train loss: 578.465027  [  801/ 1184]\n",
      "train loss: 624.367676  [  901/ 1184]\n",
      "train loss: 608.002258  [ 1001/ 1184]\n",
      "train loss: 514.085205  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:43:08.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:08.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:10.448\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:10.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.0515747070312, 638.9737548828125, 548.4772338867188, 595.9462280273438, 574.6642456054688]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:10.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -598.891578539112 is lower than -598.8871010309533, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:10.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 594.850098  [    1/ 1184]\n",
      "train loss: 581.683105  [  101/ 1184]\n",
      "train loss: 561.818604  [  201/ 1184]\n",
      "train loss: 615.638916  [  301/ 1184]\n",
      "train loss: 624.979736  [  401/ 1184]\n",
      "train loss: 631.417603  [  501/ 1184]\n",
      "train loss: 600.969971  [  601/ 1184]\n",
      "train loss: 575.343933  [  701/ 1184]\n",
      "train loss: 603.754822  [  801/ 1184]\n",
      "train loss: 566.341064  [  901/ 1184]\n",
      "train loss: 608.015198  [ 1001/ 1184]\n",
      "train loss: 643.063660  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:43:21.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:21.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:23.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:23.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [615.9927978515625, 639.027099609375, 548.48583984375, 595.9058227539062, 574.6602783203125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:23.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -598.8821544019481 is higher than -598.8871010309533, setting new best score to -598.8821544019481\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:23.428\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (598.887101 --> 598.882154).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 585.148865  [    1/ 1184]\n",
      "train loss: 608.285706  [  101/ 1184]\n",
      "train loss: 644.795410  [  201/ 1184]\n",
      "train loss: 639.167358  [  301/ 1184]\n",
      "train loss: 690.824768  [  401/ 1184]\n",
      "train loss: 616.579041  [  501/ 1184]\n",
      "train loss: 565.523682  [  601/ 1184]\n",
      "train loss: 604.613770  [  701/ 1184]\n",
      "train loss: 643.724670  [  801/ 1184]\n",
      "train loss: 616.029907  [  901/ 1184]\n",
      "train loss: 632.270264  [ 1001/ 1184]\n",
      "train loss: 551.289307  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:43:35.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:35.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:36.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:36.677\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [615.9503173828125, 638.99853515625, 548.478515625, 595.9482421875, 574.6133422851562]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:36.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -598.8623748392998 is higher than -598.8821544019481, setting new best score to -598.8623748392998\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:36.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (598.882154 --> 598.862375).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 573.675354  [    1/ 1184]\n",
      "train loss: 612.697754  [  101/ 1184]\n",
      "train loss: 556.364197  [  201/ 1184]\n",
      "train loss: 645.473145  [  301/ 1184]\n",
      "train loss: 571.421875  [  401/ 1184]\n",
      "train loss: 578.877075  [  501/ 1184]\n",
      "train loss: 589.664429  [  601/ 1184]\n",
      "train loss: 622.816284  [  701/ 1184]\n",
      "train loss: 617.358215  [  801/ 1184]\n",
      "train loss: 559.315491  [  901/ 1184]\n",
      "train loss: 595.160278  [ 1001/ 1184]\n",
      "train loss: 628.066406  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:43:48.171\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:48.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:49.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:49.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [615.9755859375, 638.9598388671875, 548.4550170898438, 595.9788208007812, 574.6072998046875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:49.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -598.8608873584602 is higher than -598.8623748392998, setting new best score to -598.8608873584602\u001b[0m\n",
      "\u001b[32m2023-11-26 20:43:49.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (598.862375 --> 598.860887).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 640.532471  [    1/ 1184]\n",
      "train loss: 591.624084  [  101/ 1184]\n",
      "train loss: 529.400879  [  201/ 1184]\n",
      "train loss: 563.953308  [  301/ 1184]\n",
      "train loss: 597.924133  [  401/ 1184]\n",
      "train loss: 585.199890  [  501/ 1184]\n",
      "train loss: 640.810547  [  601/ 1184]\n",
      "train loss: 569.015381  [  701/ 1184]\n",
      "train loss: 624.503052  [  801/ 1184]\n",
      "train loss: 562.893982  [  901/ 1184]\n",
      "train loss: 610.990784  [ 1001/ 1184]\n",
      "train loss: 591.921631  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:44:01.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:01.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:02.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:02.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [615.9874877929688, 638.978271484375, 548.3511352539062, 596.0264892578125, 574.61474609375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:02.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -598.8806574181665 is lower than -598.8608873584602, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:02.874\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:02.875\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mEarly stopping is set: loading best model from /Users/ryanstevens/Documents/github/torch_practice/data/models/static/latentDim=128_batchSize=32/checkpoint.pt\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 656.293030  [    1/ 1184]\n",
      "train loss: 585.780823  [  101/ 1184]\n",
      "train loss: 539.552734  [  201/ 1184]\n",
      "train loss: 612.417480  [  301/ 1184]\n",
      "train loss: 595.679321  [  401/ 1184]\n",
      "train loss: 583.868958  [  501/ 1184]\n",
      "train loss: 637.911072  [  601/ 1184]\n",
      "train loss: 602.190308  [  701/ 1184]\n",
      "train loss: 557.758301  [  801/ 1184]\n",
      "train loss: 704.610901  [  901/ 1184]\n",
      "train loss: 635.785217  [ 1001/ 1184]\n",
      "train loss: 592.436951  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:44:26.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:26.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:28.412\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:28.413\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [623.7281494140625, 647.7647094726562, 556.375732421875, 604.81884765625, 583.07275390625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:28.414\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mbest_score is None, saving best score...\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:28.415\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (inf --> 606.746155).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 573.564026  [    1/ 1184]\n",
      "train loss: 608.135803  [  101/ 1184]\n",
      "train loss: 620.161621  [  201/ 1184]\n",
      "train loss: 554.601929  [  301/ 1184]\n",
      "train loss: 645.337952  [  401/ 1184]\n",
      "train loss: 592.973511  [  501/ 1184]\n",
      "train loss: 605.573730  [  601/ 1184]\n",
      "train loss: 618.308411  [  701/ 1184]\n",
      "train loss: 691.441284  [  801/ 1184]\n",
      "train loss: 618.875916  [  901/ 1184]\n",
      "train loss: 641.364624  [ 1001/ 1184]\n",
      "train loss: 570.865417  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:44:37.678\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:37.679\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:39.441\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:39.442\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [620.4261474609375, 644.4674072265625, 553.5546875, 601.2866821289062, 579.7149658203125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:39.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -603.484171420713 is higher than -606.746155094195, setting new best score to -603.484171420713\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:39.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (606.746155 --> 603.484171).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 579.304688  [    1/ 1184]\n",
      "train loss: 669.074585  [  101/ 1184]\n",
      "train loss: 640.436951  [  201/ 1184]\n",
      "train loss: 594.292297  [  301/ 1184]\n",
      "train loss: 630.499146  [  401/ 1184]\n",
      "train loss: 635.623169  [  501/ 1184]\n",
      "train loss: 646.368652  [  601/ 1184]\n",
      "train loss: 648.855774  [  701/ 1184]\n",
      "train loss: 622.801758  [  801/ 1184]\n",
      "train loss: 624.310791  [  901/ 1184]\n",
      "train loss: 640.729858  [ 1001/ 1184]\n",
      "train loss: 546.790039  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:44:48.674\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:48.675\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:50.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:50.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [619.183349609375, 642.9256591796875, 552.1588134765625, 599.6815795898438, 578.0801391601562]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:50.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -602.1313948619215 is higher than -603.484171420713, setting new best score to -602.1313948619215\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:50.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (603.484171 --> 602.131395).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 560.384888  [    1/ 1184]\n",
      "train loss: 612.858643  [  101/ 1184]\n",
      "train loss: 572.768311  [  201/ 1184]\n",
      "train loss: 638.856506  [  301/ 1184]\n",
      "train loss: 661.630005  [  401/ 1184]\n",
      "train loss: 559.203247  [  501/ 1184]\n",
      "train loss: 586.213257  [  601/ 1184]\n",
      "train loss: 598.107300  [  701/ 1184]\n",
      "train loss: 616.710876  [  801/ 1184]\n",
      "train loss: 590.461304  [  901/ 1184]\n",
      "train loss: 617.581421  [ 1001/ 1184]\n",
      "train loss: 645.614258  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:44:59.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:44:59.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:00.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:00.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [618.374267578125, 642.0177001953125, 551.1841430664062, 598.5279541015625, 577.1972045898438]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:00.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -601.2628312122972 is higher than -602.1313948619215, setting new best score to -601.2628312122972\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:00.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (602.131395 --> 601.262831).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 586.410156  [    1/ 1184]\n",
      "train loss: 594.695374  [  101/ 1184]\n",
      "train loss: 591.936279  [  201/ 1184]\n",
      "train loss: 582.671143  [  301/ 1184]\n",
      "train loss: 578.883484  [  401/ 1184]\n",
      "train loss: 637.159607  [  501/ 1184]\n",
      "train loss: 580.345581  [  601/ 1184]\n",
      "train loss: 600.010010  [  701/ 1184]\n",
      "train loss: 560.830627  [  801/ 1184]\n",
      "train loss: 631.455200  [  901/ 1184]\n",
      "train loss: 638.080872  [ 1001/ 1184]\n",
      "train loss: 596.509155  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:45:10.031\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:10.032\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:11.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:11.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.7596435546875, 641.3424682617188, 550.5213012695312, 597.6937866210938, 576.630615234375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:11.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.5696473713163 is higher than -601.2628312122972, setting new best score to -600.5696473713163\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:11.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (601.262831 --> 600.569647).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 655.850037  [    1/ 1184]\n",
      "train loss: 569.629517  [  101/ 1184]\n",
      "train loss: 592.904419  [  201/ 1184]\n",
      "train loss: 576.182007  [  301/ 1184]\n",
      "train loss: 586.890259  [  401/ 1184]\n",
      "train loss: 616.731201  [  501/ 1184]\n",
      "train loss: 579.156616  [  601/ 1184]\n",
      "train loss: 649.820679  [  701/ 1184]\n",
      "train loss: 609.435303  [  801/ 1184]\n",
      "train loss: 631.539062  [  901/ 1184]\n",
      "train loss: 585.036804  [ 1001/ 1184]\n",
      "train loss: 543.392517  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:45:20.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:20.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:22.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:22.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [617.2421875, 640.8250122070312, 550.0140380859375, 597.0068359375, 576.0060424804688]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:22.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -600.0735132144977 is higher than -600.5696473713163, setting new best score to -600.0735132144977\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:22.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.569647 --> 600.073513).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 643.381287  [    1/ 1184]\n",
      "train loss: 705.075989  [  101/ 1184]\n",
      "train loss: 624.639465  [  201/ 1184]\n",
      "train loss: 568.258057  [  301/ 1184]\n",
      "train loss: 557.213867  [  401/ 1184]\n",
      "train loss: 607.920044  [  501/ 1184]\n",
      "train loss: 632.309631  [  601/ 1184]\n",
      "train loss: 624.830688  [  701/ 1184]\n",
      "train loss: 588.244019  [  801/ 1184]\n",
      "train loss: 554.280762  [  901/ 1184]\n",
      "train loss: 607.479431  [ 1001/ 1184]\n",
      "train loss: 593.110657  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:45:31.756\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:31.757\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:33.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:33.353\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.651123046875, 640.3717041015625, 549.4715576171875, 596.4793701171875, 575.468505859375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:33.354\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.57662508035 is higher than -600.0735132144977, setting new best score to -599.57662508035\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:33.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (600.073513 --> 599.576625).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 590.152527  [    1/ 1184]\n",
      "train loss: 618.982971  [  101/ 1184]\n",
      "train loss: 610.806030  [  201/ 1184]\n",
      "train loss: 536.769043  [  301/ 1184]\n",
      "train loss: 605.805298  [  401/ 1184]\n",
      "train loss: 621.027954  [  501/ 1184]\n",
      "train loss: 620.130981  [  601/ 1184]\n",
      "train loss: 600.460510  [  701/ 1184]\n",
      "train loss: 644.428650  [  801/ 1184]\n",
      "train loss: 600.869202  [  901/ 1184]\n",
      "train loss: 585.425659  [ 1001/ 1184]\n",
      "train loss: 593.775024  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:45:42.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:42.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:44.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:44.047\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [616.0875244140625, 639.9166259765625, 549.0159301757812, 595.9332275390625, 575.0557250976562]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:44.048\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -599.1676254079312 is higher than -599.57662508035, setting new best score to -599.1676254079312\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:44.049\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.576625 --> 599.167625).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 606.939514  [    1/ 1184]\n",
      "train loss: 604.871460  [  101/ 1184]\n",
      "train loss: 576.555054  [  201/ 1184]\n",
      "train loss: 581.835632  [  301/ 1184]\n",
      "train loss: 655.364380  [  401/ 1184]\n",
      "train loss: 542.882080  [  501/ 1184]\n",
      "train loss: 636.660645  [  601/ 1184]\n",
      "train loss: 581.339111  [  701/ 1184]\n",
      "train loss: 582.608521  [  801/ 1184]\n",
      "train loss: 599.860291  [  901/ 1184]\n",
      "train loss: 606.609741  [ 1001/ 1184]\n",
      "train loss: 638.216064  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:45:53.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:53.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:54.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:54.691\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [615.7437744140625, 639.6576538085938, 548.7357177734375, 595.6015625, 574.7149658203125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:54.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -598.8483763103244 is higher than -599.1676254079312, setting new best score to -598.8483763103244\u001b[0m\n",
      "\u001b[32m2023-11-26 20:45:54.693\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (599.167625 --> 598.848376).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 585.300049  [    1/ 1184]\n",
      "train loss: 563.769714  [  101/ 1184]\n",
      "train loss: 616.680725  [  201/ 1184]\n",
      "train loss: 645.214783  [  301/ 1184]\n",
      "train loss: 616.342651  [  401/ 1184]\n",
      "train loss: 572.273315  [  501/ 1184]\n",
      "train loss: 565.181885  [  601/ 1184]\n",
      "train loss: 583.890991  [  701/ 1184]\n",
      "train loss: 573.970154  [  801/ 1184]\n",
      "train loss: 578.952515  [  901/ 1184]\n",
      "train loss: 612.578979  [ 1001/ 1184]\n",
      "train loss: 594.306580  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:46:04.011\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:04.012\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:05.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:05.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [615.4287719726562, 639.2509155273438, 548.452880859375, 595.2200927734375, 574.4370727539062]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:05.593\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -598.6056566455696 is higher than -598.8483763103244, setting new best score to -598.6056566455696\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:05.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (598.848376 --> 598.605657).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 597.901611  [    1/ 1184]\n",
      "train loss: 553.893188  [  101/ 1184]\n",
      "train loss: 575.849060  [  201/ 1184]\n",
      "train loss: 534.755798  [  301/ 1184]\n",
      "train loss: 626.939087  [  401/ 1184]\n",
      "train loss: 642.389099  [  501/ 1184]\n",
      "train loss: 585.718018  [  601/ 1184]\n",
      "train loss: 600.039917  [  701/ 1184]\n",
      "train loss: 625.775635  [  801/ 1184]\n",
      "train loss: 608.196106  [  901/ 1184]\n",
      "train loss: 630.508545  [ 1001/ 1184]\n",
      "train loss: 655.854980  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:46:14.726\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:14.727\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:16.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:16.288\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [615.18505859375, 638.9837036132812, 548.1430053710938, 595.1137084960938, 574.2566528320312]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:16.289\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -598.4092539340635 is higher than -598.6056566455696, setting new best score to -598.4092539340635\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:16.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (598.605657 --> 598.409254).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 588.522522  [    1/ 1184]\n",
      "train loss: 562.655212  [  101/ 1184]\n",
      "train loss: 629.080078  [  201/ 1184]\n",
      "train loss: 532.672607  [  301/ 1184]\n",
      "train loss: 591.942871  [  401/ 1184]\n",
      "train loss: 633.219727  [  501/ 1184]\n",
      "train loss: 603.101379  [  601/ 1184]\n",
      "train loss: 603.777466  [  701/ 1184]\n",
      "train loss: 591.375122  [  801/ 1184]\n",
      "train loss: 583.415344  [  901/ 1184]\n",
      "train loss: 634.502014  [ 1001/ 1184]\n",
      "train loss: 614.009827  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:46:25.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:25.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:26.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:26.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [614.9075927734375, 638.5269775390625, 547.8112182617188, 594.7689819335938, 574.0153198242188]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:26.916\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -598.1510540539705 is higher than -598.4092539340635, setting new best score to -598.1510540539705\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:26.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (598.409254 --> 598.151054).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 585.465454  [    1/ 1184]\n",
      "train loss: 624.291992  [  101/ 1184]\n",
      "train loss: 622.536621  [  201/ 1184]\n",
      "train loss: 564.962158  [  301/ 1184]\n",
      "train loss: 617.998108  [  401/ 1184]\n",
      "train loss: 614.642090  [  501/ 1184]\n",
      "train loss: 622.209167  [  601/ 1184]\n",
      "train loss: 624.856689  [  701/ 1184]\n",
      "train loss: 575.086365  [  801/ 1184]\n",
      "train loss: 563.542908  [  901/ 1184]\n",
      "train loss: 546.877014  [ 1001/ 1184]\n",
      "train loss: 611.971252  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:46:36.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:36.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:37.882\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:37.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [614.6992797851562, 638.3108520507812, 547.4844970703125, 594.48291015625, 573.7479248046875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:37.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -597.9470912498764 is higher than -598.1510540539705, setting new best score to -597.9470912498764\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:37.885\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (598.151054 --> 597.947091).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 566.574768  [    1/ 1184]\n",
      "train loss: 611.711548  [  101/ 1184]\n",
      "train loss: 617.324768  [  201/ 1184]\n",
      "train loss: 592.360962  [  301/ 1184]\n",
      "train loss: 679.039612  [  401/ 1184]\n",
      "train loss: 620.433838  [  501/ 1184]\n",
      "train loss: 635.863708  [  601/ 1184]\n",
      "train loss: 611.906860  [  701/ 1184]\n",
      "train loss: 577.833740  [  801/ 1184]\n",
      "train loss: 600.478088  [  901/ 1184]\n",
      "train loss: 566.304993  [ 1001/ 1184]\n",
      "train loss: 604.037354  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:46:47.039\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:47.040\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:48.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:48.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [614.5908203125, 637.9666748046875, 547.223388671875, 594.2208862304688, 573.5740356445312]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:48.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -597.7622083446647 is higher than -597.9470912498764, setting new best score to -597.7622083446647\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:48.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (597.947091 --> 597.762208).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 535.502930  [    1/ 1184]\n",
      "train loss: 555.996338  [  101/ 1184]\n",
      "train loss: 587.357361  [  201/ 1184]\n",
      "train loss: 603.786987  [  301/ 1184]\n",
      "train loss: 600.656006  [  401/ 1184]\n",
      "train loss: 557.848999  [  501/ 1184]\n",
      "train loss: 571.401917  [  601/ 1184]\n",
      "train loss: 591.155396  [  701/ 1184]\n",
      "train loss: 592.943176  [  801/ 1184]\n",
      "train loss: 587.589111  [  901/ 1184]\n",
      "train loss: 622.373169  [ 1001/ 1184]\n",
      "train loss: 588.987061  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:46:58.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:58.134\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:59.745\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:59.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [614.4300537109375, 637.7376098632812, 546.9146728515625, 594.0125732421875, 573.5294189453125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:59.747\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -597.5969141706636 is higher than -597.7622083446647, setting new best score to -597.5969141706636\u001b[0m\n",
      "\u001b[32m2023-11-26 20:46:59.748\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (597.762208 --> 597.596914).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 582.998413  [    1/ 1184]\n",
      "train loss: 525.854187  [  101/ 1184]\n",
      "train loss: 636.361633  [  201/ 1184]\n",
      "train loss: 645.122742  [  301/ 1184]\n",
      "train loss: 611.480835  [  401/ 1184]\n",
      "train loss: 626.262695  [  501/ 1184]\n",
      "train loss: 612.676208  [  601/ 1184]\n",
      "train loss: 616.341125  [  701/ 1184]\n",
      "train loss: 602.861816  [  801/ 1184]\n",
      "train loss: 568.274536  [  901/ 1184]\n",
      "train loss: 616.525024  [ 1001/ 1184]\n",
      "train loss: 584.500061  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:47:09.429\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:09.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:11.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:11.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [614.0436401367188, 637.475341796875, 546.6781005859375, 593.755615234375, 573.3095092773438]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:11.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -597.3203315831438 is higher than -597.5969141706636, setting new best score to -597.3203315831438\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:11.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (597.596914 --> 597.320332).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 606.262085  [    1/ 1184]\n",
      "train loss: 594.017700  [  101/ 1184]\n",
      "train loss: 568.528687  [  201/ 1184]\n",
      "train loss: 614.440186  [  301/ 1184]\n",
      "train loss: 549.592896  [  401/ 1184]\n",
      "train loss: 587.442322  [  501/ 1184]\n",
      "train loss: 575.008667  [  601/ 1184]\n",
      "train loss: 635.434265  [  701/ 1184]\n",
      "train loss: 610.034485  [  801/ 1184]\n",
      "train loss: 512.427856  [  901/ 1184]\n",
      "train loss: 598.664429  [ 1001/ 1184]\n",
      "train loss: 604.825562  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:47:20.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:20.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:22.084\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:22.085\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [613.9124755859375, 637.2957763671875, 546.3982543945312, 593.6258544921875, 573.18603515625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:22.086\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -597.1830241142949 is higher than -597.3203315831438, setting new best score to -597.1830241142949\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:22.087\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (597.320332 --> 597.183024).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 605.633240  [    1/ 1184]\n",
      "train loss: 599.465881  [  101/ 1184]\n",
      "train loss: 619.053711  [  201/ 1184]\n",
      "train loss: 659.139771  [  301/ 1184]\n",
      "train loss: 509.186951  [  401/ 1184]\n",
      "train loss: 609.423645  [  501/ 1184]\n",
      "train loss: 554.503113  [  601/ 1184]\n",
      "train loss: 565.603882  [  701/ 1184]\n",
      "train loss: 601.354858  [  801/ 1184]\n",
      "train loss: 646.354797  [  901/ 1184]\n",
      "train loss: 569.947327  [ 1001/ 1184]\n",
      "train loss: 634.873840  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:47:31.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:31.389\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:32.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:32.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [613.70654296875, 637.048583984375, 546.116943359375, 593.3372192382812, 572.983154296875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:32.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -596.9598373219936 is higher than -597.1830241142949, setting new best score to -596.9598373219936\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:32.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (597.183024 --> 596.959837).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 626.320923  [    1/ 1184]\n",
      "train loss: 631.098389  [  101/ 1184]\n",
      "train loss: 603.448242  [  201/ 1184]\n",
      "train loss: 564.676636  [  301/ 1184]\n",
      "train loss: 639.587280  [  401/ 1184]\n",
      "train loss: 579.031006  [  501/ 1184]\n",
      "train loss: 585.416504  [  601/ 1184]\n",
      "train loss: 608.682556  [  701/ 1184]\n",
      "train loss: 612.920776  [  801/ 1184]\n",
      "train loss: 642.091125  [  901/ 1184]\n",
      "train loss: 629.595764  [ 1001/ 1184]\n",
      "train loss: 570.274841  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:47:42.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:42.634\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:44.326\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:44.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [613.5823974609375, 636.791015625, 545.8550415039062, 593.03662109375, 572.8701171875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:44.327\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -596.7886393486699 is higher than -596.9598373219936, setting new best score to -596.7886393486699\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:44.328\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (596.959837 --> 596.788639).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 619.867920  [    1/ 1184]\n",
      "train loss: 624.427124  [  101/ 1184]\n",
      "train loss: 624.205383  [  201/ 1184]\n",
      "train loss: 543.231812  [  301/ 1184]\n",
      "train loss: 632.047363  [  401/ 1184]\n",
      "train loss: 597.775940  [  501/ 1184]\n",
      "train loss: 646.989258  [  601/ 1184]\n",
      "train loss: 554.863525  [  701/ 1184]\n",
      "train loss: 610.077881  [  801/ 1184]\n",
      "train loss: 588.538574  [  901/ 1184]\n",
      "train loss: 622.952026  [ 1001/ 1184]\n",
      "train loss: 566.326904  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:47:53.724\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:53.725\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:55.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:55.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [613.4373168945312, 636.6634521484375, 545.6964111328125, 592.8903198242188, 572.7485961914062]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:55.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -596.629593861254 is higher than -596.7886393486699, setting new best score to -596.629593861254\u001b[0m\n",
      "\u001b[32m2023-11-26 20:47:55.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (596.788639 --> 596.629594).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 562.555298  [    1/ 1184]\n",
      "train loss: 638.467285  [  101/ 1184]\n",
      "train loss: 607.886353  [  201/ 1184]\n",
      "train loss: 602.480713  [  301/ 1184]\n",
      "train loss: 542.810730  [  401/ 1184]\n",
      "train loss: 577.990479  [  501/ 1184]\n",
      "train loss: 581.324036  [  601/ 1184]\n",
      "train loss: 593.602783  [  701/ 1184]\n",
      "train loss: 616.391541  [  801/ 1184]\n",
      "train loss: 577.547607  [  901/ 1184]\n",
      "train loss: 606.067871  [ 1001/ 1184]\n",
      "train loss: 563.956543  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:48:04.822\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:04.823\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:06.397\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:06.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [613.1376342773438, 636.3892211914062, 545.4533081054688, 592.4955444335938, 572.4683837890625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:06.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -596.4022698124753 is higher than -596.629593861254, setting new best score to -596.4022698124753\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:06.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (596.629594 --> 596.402270).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 605.957275  [    1/ 1184]\n",
      "train loss: 575.474365  [  101/ 1184]\n",
      "train loss: 594.774963  [  201/ 1184]\n",
      "train loss: 566.382446  [  301/ 1184]\n",
      "train loss: 605.471558  [  401/ 1184]\n",
      "train loss: 589.052185  [  501/ 1184]\n",
      "train loss: 550.519836  [  601/ 1184]\n",
      "train loss: 551.442444  [  701/ 1184]\n",
      "train loss: 628.242676  [  801/ 1184]\n",
      "train loss: 598.760559  [  901/ 1184]\n",
      "train loss: 583.902954  [ 1001/ 1184]\n",
      "train loss: 513.358643  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:48:15.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:15.856\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:17.420\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:17.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [612.9972534179688, 636.1970825195312, 545.3148193359375, 592.3736572265625, 572.2969970703125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:17.421\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -596.2497695343404 is higher than -596.4022698124753, setting new best score to -596.2497695343404\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:17.423\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (596.402270 --> 596.249770).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 583.407349  [    1/ 1184]\n",
      "train loss: 577.828064  [  101/ 1184]\n",
      "train loss: 659.907471  [  201/ 1184]\n",
      "train loss: 567.299438  [  301/ 1184]\n",
      "train loss: 622.271545  [  401/ 1184]\n",
      "train loss: 640.487122  [  501/ 1184]\n",
      "train loss: 561.719238  [  601/ 1184]\n",
      "train loss: 596.764160  [  701/ 1184]\n",
      "train loss: 640.764587  [  801/ 1184]\n",
      "train loss: 606.114868  [  901/ 1184]\n",
      "train loss: 551.514404  [ 1001/ 1184]\n",
      "train loss: 612.218811  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:48:27.023\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:27.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:28.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:28.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [612.8768310546875, 636.016845703125, 545.1569213867188, 592.2245483398438, 572.221435546875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:28.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -596.1241880006428 is higher than -596.2497695343404, setting new best score to -596.1241880006428\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:28.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (596.249770 --> 596.124188).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 576.732544  [    1/ 1184]\n",
      "train loss: 611.714539  [  101/ 1184]\n",
      "train loss: 585.224976  [  201/ 1184]\n",
      "train loss: 513.135315  [  301/ 1184]\n",
      "train loss: 632.221741  [  401/ 1184]\n",
      "train loss: 523.617310  [  501/ 1184]\n",
      "train loss: 545.232788  [  601/ 1184]\n",
      "train loss: 587.263977  [  701/ 1184]\n",
      "train loss: 623.303223  [  801/ 1184]\n",
      "train loss: 682.170532  [  901/ 1184]\n",
      "train loss: 620.228638  [ 1001/ 1184]\n",
      "train loss: 579.711426  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:48:38.376\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:38.377\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:39.975\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:39.976\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [612.6368408203125, 635.8355712890625, 545.0147705078125, 592.1182861328125, 572.1290893554688]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:39.977\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -596.0207908147498 is higher than -596.1241880006428, setting new best score to -596.0207908147498\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:39.978\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (596.124188 --> 596.020791).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 626.817627  [    1/ 1184]\n",
      "train loss: 593.133118  [  101/ 1184]\n",
      "train loss: 591.033691  [  201/ 1184]\n",
      "train loss: 643.131958  [  301/ 1184]\n",
      "train loss: 602.033813  [  401/ 1184]\n",
      "train loss: 524.872375  [  501/ 1184]\n",
      "train loss: 666.634583  [  601/ 1184]\n",
      "train loss: 566.306152  [  701/ 1184]\n",
      "train loss: 630.436157  [  801/ 1184]\n",
      "train loss: 593.611267  [  901/ 1184]\n",
      "train loss: 572.728455  [ 1001/ 1184]\n",
      "train loss: 595.289062  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:48:49.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:49.657\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:51.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:51.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [612.5665283203125, 635.6769409179688, 544.893798828125, 591.8724365234375, 572.0423583984375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:51.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -595.8885313396213 is higher than -596.0207908147498, setting new best score to -595.8885313396213\u001b[0m\n",
      "\u001b[32m2023-11-26 20:48:51.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (596.020791 --> 595.888531).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 599.446472  [    1/ 1184]\n",
      "train loss: 632.735107  [  101/ 1184]\n",
      "train loss: 583.273621  [  201/ 1184]\n",
      "train loss: 620.428650  [  301/ 1184]\n",
      "train loss: 566.180054  [  401/ 1184]\n",
      "train loss: 554.239746  [  501/ 1184]\n",
      "train loss: 613.389709  [  601/ 1184]\n",
      "train loss: 702.893799  [  701/ 1184]\n",
      "train loss: 626.927124  [  801/ 1184]\n",
      "train loss: 587.715637  [  901/ 1184]\n",
      "train loss: 550.139282  [ 1001/ 1184]\n",
      "train loss: 582.401794  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:49:00.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:00.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:02.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:02.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [612.4342041015625, 635.5989379882812, 544.7684326171875, 591.8487548828125, 571.9714965820312]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:02.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -595.7954217452037 is higher than -595.8885313396213, setting new best score to -595.7954217452037\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:02.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (595.888531 --> 595.795422).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 565.410156  [    1/ 1184]\n",
      "train loss: 555.190308  [  101/ 1184]\n",
      "train loss: 564.877686  [  201/ 1184]\n",
      "train loss: 603.939819  [  301/ 1184]\n",
      "train loss: 550.593018  [  401/ 1184]\n",
      "train loss: 656.738953  [  501/ 1184]\n",
      "train loss: 536.372742  [  601/ 1184]\n",
      "train loss: 558.900940  [  701/ 1184]\n",
      "train loss: 613.641235  [  801/ 1184]\n",
      "train loss: 605.747131  [  901/ 1184]\n",
      "train loss: 516.670288  [ 1001/ 1184]\n",
      "train loss: 622.123901  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:49:12.209\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:12.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:13.777\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:13.778\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [612.2807006835938, 635.48388671875, 544.596435546875, 591.6544799804688, 571.8760986328125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:13.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -595.6636140074911 is higher than -595.7954217452037, setting new best score to -595.6636140074911\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:13.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (595.795422 --> 595.663614).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 671.635132  [    1/ 1184]\n",
      "train loss: 591.936157  [  101/ 1184]\n",
      "train loss: 555.875183  [  201/ 1184]\n",
      "train loss: 545.298889  [  301/ 1184]\n",
      "train loss: 593.581543  [  401/ 1184]\n",
      "train loss: 662.327942  [  501/ 1184]\n",
      "train loss: 621.376160  [  601/ 1184]\n",
      "train loss: 572.140503  [  701/ 1184]\n",
      "train loss: 607.440796  [  801/ 1184]\n",
      "train loss: 587.723572  [  901/ 1184]\n",
      "train loss: 637.158875  [ 1001/ 1184]\n",
      "train loss: 622.614197  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:49:23.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:23.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:25.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:25.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [612.1368408203125, 635.3079223632812, 544.4470825195312, 591.5339965820312, 571.7939453125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:25.073\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -595.5412877336333 is higher than -595.6636140074911, setting new best score to -595.5412877336333\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:25.074\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (595.663614 --> 595.541288).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 578.363708  [    1/ 1184]\n",
      "train loss: 611.169128  [  101/ 1184]\n",
      "train loss: 637.789856  [  201/ 1184]\n",
      "train loss: 528.688965  [  301/ 1184]\n",
      "train loss: 598.726013  [  401/ 1184]\n",
      "train loss: 566.686646  [  501/ 1184]\n",
      "train loss: 588.187683  [  601/ 1184]\n",
      "train loss: 586.489502  [  701/ 1184]\n",
      "train loss: 666.050415  [  801/ 1184]\n",
      "train loss: 602.993652  [  901/ 1184]\n",
      "train loss: 593.690247  [ 1001/ 1184]\n",
      "train loss: 610.723389  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:49:34.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:34.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:36.526\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:36.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [611.9091796875, 635.1590576171875, 544.255126953125, 591.3551025390625, 571.55908203125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:36.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -595.4028300997577 is higher than -595.5412877336333, setting new best score to -595.4028300997577\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:36.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (595.541288 --> 595.402830).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 701.557922  [    1/ 1184]\n",
      "train loss: 605.492249  [  101/ 1184]\n",
      "train loss: 582.895935  [  201/ 1184]\n",
      "train loss: 630.709839  [  301/ 1184]\n",
      "train loss: 597.252380  [  401/ 1184]\n",
      "train loss: 611.358582  [  501/ 1184]\n",
      "train loss: 621.877686  [  601/ 1184]\n",
      "train loss: 543.799561  [  701/ 1184]\n",
      "train loss: 663.598877  [  801/ 1184]\n",
      "train loss: 637.709229  [  901/ 1184]\n",
      "train loss: 611.495605  [ 1001/ 1184]\n",
      "train loss: 583.015137  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:49:46.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:46.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:47.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:47.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [611.7890014648438, 635.0557861328125, 544.1649169921875, 591.2156372070312, 571.49755859375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:47.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -595.3201905842069 is higher than -595.4028300997577, setting new best score to -595.3201905842069\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:47.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (595.402830 --> 595.320191).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 599.035583  [    1/ 1184]\n",
      "train loss: 568.805664  [  101/ 1184]\n",
      "train loss: 601.562439  [  201/ 1184]\n",
      "train loss: 544.930420  [  301/ 1184]\n",
      "train loss: 626.317627  [  401/ 1184]\n",
      "train loss: 615.128113  [  501/ 1184]\n",
      "train loss: 554.923462  [  601/ 1184]\n",
      "train loss: 544.683960  [  701/ 1184]\n",
      "train loss: 567.402710  [  801/ 1184]\n",
      "train loss: 587.707764  [  901/ 1184]\n",
      "train loss: 561.996704  [ 1001/ 1184]\n",
      "train loss: 646.416382  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:49:57.781\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:57.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:59.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:59.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [611.5961303710938, 634.9048461914062, 543.9415893554688, 591.1138916015625, 571.3824462890625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:59.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -595.1736529772795 is higher than -595.3201905842069, setting new best score to -595.1736529772795\u001b[0m\n",
      "\u001b[32m2023-11-26 20:49:59.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (595.320191 --> 595.173653).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 566.473145  [    1/ 1184]\n",
      "train loss: 601.611023  [  101/ 1184]\n",
      "train loss: 609.127014  [  201/ 1184]\n",
      "train loss: 617.379272  [  301/ 1184]\n",
      "train loss: 589.505127  [  401/ 1184]\n",
      "train loss: 619.769775  [  501/ 1184]\n",
      "train loss: 592.495483  [  601/ 1184]\n",
      "train loss: 632.527161  [  701/ 1184]\n",
      "train loss: 697.518433  [  801/ 1184]\n",
      "train loss: 541.376709  [  901/ 1184]\n",
      "train loss: 621.142578  [ 1001/ 1184]\n",
      "train loss: 646.725708  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:50:09.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:09.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:10.661\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:10.662\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [611.4970703125, 634.7651977539062, 543.8414916992188, 591.0485229492188, 571.3966674804688]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:10.663\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -595.1116743256774 is higher than -595.1736529772795, setting new best score to -595.1116743256774\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:10.664\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (595.173653 --> 595.111674).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 584.158386  [    1/ 1184]\n",
      "train loss: 578.801208  [  101/ 1184]\n",
      "train loss: 519.791321  [  201/ 1184]\n",
      "train loss: 546.754089  [  301/ 1184]\n",
      "train loss: 550.673279  [  401/ 1184]\n",
      "train loss: 624.026855  [  501/ 1184]\n",
      "train loss: 637.990417  [  601/ 1184]\n",
      "train loss: 657.621094  [  701/ 1184]\n",
      "train loss: 590.786743  [  801/ 1184]\n",
      "train loss: 586.095276  [  901/ 1184]\n",
      "train loss: 612.114624  [ 1001/ 1184]\n",
      "train loss: 610.626953  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:50:20.531\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:20.532\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:22.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:22.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [611.4302978515625, 634.72998046875, 543.751708984375, 590.8577270507812, 571.2637329101562]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:22.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -595.0153630896459 is higher than -595.1116743256774, setting new best score to -595.0153630896459\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:22.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (595.111674 --> 595.015363).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 567.449890  [    1/ 1184]\n",
      "train loss: 604.229492  [  101/ 1184]\n",
      "train loss: 611.261597  [  201/ 1184]\n",
      "train loss: 601.978210  [  301/ 1184]\n",
      "train loss: 598.642395  [  401/ 1184]\n",
      "train loss: 526.875671  [  501/ 1184]\n",
      "train loss: 663.012817  [  601/ 1184]\n",
      "train loss: 615.488892  [  701/ 1184]\n",
      "train loss: 616.522888  [  801/ 1184]\n",
      "train loss: 543.828003  [  901/ 1184]\n",
      "train loss: 621.913513  [ 1001/ 1184]\n",
      "train loss: 521.266907  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:50:32.898\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:32.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:34.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:34.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [611.33251953125, 634.634033203125, 543.689208984375, 590.8341064453125, 571.24755859375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:34.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -594.9574976667573 is higher than -595.0153630896459, setting new best score to -594.9574976667573\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:34.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (595.015363 --> 594.957498).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 649.366394  [    1/ 1184]\n",
      "train loss: 621.757141  [  101/ 1184]\n",
      "train loss: 648.209229  [  201/ 1184]\n",
      "train loss: 571.166504  [  301/ 1184]\n",
      "train loss: 603.009583  [  401/ 1184]\n",
      "train loss: 615.800598  [  501/ 1184]\n",
      "train loss: 591.103638  [  601/ 1184]\n",
      "train loss: 553.402466  [  701/ 1184]\n",
      "train loss: 573.992798  [  801/ 1184]\n",
      "train loss: 610.614807  [  901/ 1184]\n",
      "train loss: 574.277222  [ 1001/ 1184]\n",
      "train loss: 583.603271  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:50:44.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:44.403\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:45.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:45.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [611.2620849609375, 634.5899047851562, 543.5670776367188, 590.6795654296875, 571.166015625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:45.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -594.8860265804243 is higher than -594.9574976667573, setting new best score to -594.8860265804243\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:45.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (594.957498 --> 594.886027).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 540.029846  [    1/ 1184]\n",
      "train loss: 559.916077  [  101/ 1184]\n",
      "train loss: 589.894226  [  201/ 1184]\n",
      "train loss: 611.448364  [  301/ 1184]\n",
      "train loss: 655.813538  [  401/ 1184]\n",
      "train loss: 568.595459  [  501/ 1184]\n",
      "train loss: 614.195740  [  601/ 1184]\n",
      "train loss: 532.055664  [  701/ 1184]\n",
      "train loss: 566.012268  [  801/ 1184]\n",
      "train loss: 603.193176  [  901/ 1184]\n",
      "train loss: 564.330872  [ 1001/ 1184]\n",
      "train loss: 577.958801  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:50:55.941\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:55.942\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:57.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:57.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [611.1512451171875, 634.4867553710938, 543.5225830078125, 590.5529174804688, 571.043701171875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:57.514\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -594.8277160644532 is higher than -594.8860265804243, setting new best score to -594.8277160644532\u001b[0m\n",
      "\u001b[32m2023-11-26 20:50:57.515\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (594.886027 --> 594.827716).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 628.459839  [    1/ 1184]\n",
      "train loss: 604.309998  [  101/ 1184]\n",
      "train loss: 619.986206  [  201/ 1184]\n",
      "train loss: 528.928223  [  301/ 1184]\n",
      "train loss: 607.460266  [  401/ 1184]\n",
      "train loss: 643.579590  [  501/ 1184]\n",
      "train loss: 600.229065  [  601/ 1184]\n",
      "train loss: 632.022278  [  701/ 1184]\n",
      "train loss: 583.920776  [  801/ 1184]\n",
      "train loss: 651.685974  [  901/ 1184]\n",
      "train loss: 576.156921  [ 1001/ 1184]\n",
      "train loss: 523.471436  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:51:07.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:07.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:08.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:08.907\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [611.1552124023438, 634.442626953125, 543.387451171875, 590.403564453125, 571.0169677734375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:08.908\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -594.7598445844046 is higher than -594.8277160644532, setting new best score to -594.7598445844046\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:08.909\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (594.827716 --> 594.759845).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 533.175903  [    1/ 1184]\n",
      "train loss: 635.938171  [  101/ 1184]\n",
      "train loss: 593.556946  [  201/ 1184]\n",
      "train loss: 643.870117  [  301/ 1184]\n",
      "train loss: 673.079712  [  401/ 1184]\n",
      "train loss: 628.739136  [  501/ 1184]\n",
      "train loss: 577.039185  [  601/ 1184]\n",
      "train loss: 548.769592  [  701/ 1184]\n",
      "train loss: 576.404541  [  801/ 1184]\n",
      "train loss: 550.621521  [  901/ 1184]\n",
      "train loss: 673.415222  [ 1001/ 1184]\n",
      "train loss: 599.072327  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:51:18.979\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:18.980\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:20.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:20.551\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [611.0819091796875, 634.3550415039062, 543.3623046875, 590.4530029296875, 570.9337768554688]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:20.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -594.7040896645075 is higher than -594.7598445844046, setting new best score to -594.7040896645075\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:20.552\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (594.759845 --> 594.704090).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 570.180176  [    1/ 1184]\n",
      "train loss: 631.338562  [  101/ 1184]\n",
      "train loss: 569.060608  [  201/ 1184]\n",
      "train loss: 616.905762  [  301/ 1184]\n",
      "train loss: 631.214844  [  401/ 1184]\n",
      "train loss: 624.884827  [  501/ 1184]\n",
      "train loss: 565.838745  [  601/ 1184]\n",
      "train loss: 582.947937  [  701/ 1184]\n",
      "train loss: 669.043762  [  801/ 1184]\n",
      "train loss: 614.942993  [  901/ 1184]\n",
      "train loss: 605.946960  [ 1001/ 1184]\n",
      "train loss: 572.264648  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:51:30.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:30.407\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:32.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:32.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [610.9293823242188, 634.2540283203125, 543.2156982421875, 590.24560546875, 570.8184204101562]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:32.021\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -594.5875733194472 is higher than -594.7040896645075, setting new best score to -594.5875733194472\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:32.022\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (594.704090 --> 594.587573).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 602.913086  [    1/ 1184]\n",
      "train loss: 531.193726  [  101/ 1184]\n",
      "train loss: 626.344421  [  201/ 1184]\n",
      "train loss: 611.144165  [  301/ 1184]\n",
      "train loss: 628.123047  [  401/ 1184]\n",
      "train loss: 530.485474  [  501/ 1184]\n",
      "train loss: 551.702026  [  601/ 1184]\n",
      "train loss: 604.461243  [  701/ 1184]\n",
      "train loss: 611.187256  [  801/ 1184]\n",
      "train loss: 651.301514  [  901/ 1184]\n",
      "train loss: 570.203186  [ 1001/ 1184]\n",
      "train loss: 633.905029  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:51:42.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:42.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:43.628\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:43.629\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [610.9417724609375, 634.2302856445312, 543.2316284179688, 590.2134399414062, 570.759033203125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:43.630\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -594.5526937364023 is higher than -594.5875733194472, setting new best score to -594.5526937364023\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:43.631\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (594.587573 --> 594.552694).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 538.054260  [    1/ 1184]\n",
      "train loss: 583.558044  [  101/ 1184]\n",
      "train loss: 567.977600  [  201/ 1184]\n",
      "train loss: 597.759338  [  301/ 1184]\n",
      "train loss: 573.438171  [  401/ 1184]\n",
      "train loss: 566.761047  [  501/ 1184]\n",
      "train loss: 603.462769  [  601/ 1184]\n",
      "train loss: 606.453918  [  701/ 1184]\n",
      "train loss: 624.355347  [  801/ 1184]\n",
      "train loss: 580.986084  [  901/ 1184]\n",
      "train loss: 614.249084  [ 1001/ 1184]\n",
      "train loss: 653.199829  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:51:53.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:53.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:55.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:55.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [610.8505859375, 634.1221923828125, 543.1433715820312, 590.1790161132812, 570.7879638671875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:55.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -594.5009561659415 is higher than -594.5526937364023, setting new best score to -594.5009561659415\u001b[0m\n",
      "\u001b[32m2023-11-26 20:51:55.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (594.552694 --> 594.500956).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 644.184875  [    1/ 1184]\n",
      "train loss: 548.922485  [  101/ 1184]\n",
      "train loss: 634.106628  [  201/ 1184]\n",
      "train loss: 643.228882  [  301/ 1184]\n",
      "train loss: 612.459778  [  401/ 1184]\n",
      "train loss: 617.360718  [  501/ 1184]\n",
      "train loss: 590.638123  [  601/ 1184]\n",
      "train loss: 570.204346  [  701/ 1184]\n",
      "train loss: 578.344604  [  801/ 1184]\n",
      "train loss: 571.615906  [  901/ 1184]\n",
      "train loss: 641.373047  [ 1001/ 1184]\n",
      "train loss: 580.900330  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:52:05.211\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:05.212\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:06.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:06.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [610.8528442382812, 634.0672607421875, 543.0944213867188, 590.0321655273438, 570.6788940429688]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:06.820\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -594.4373000519186 is higher than -594.5009561659415, setting new best score to -594.4373000519186\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:06.821\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (594.500956 --> 594.437300).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 552.840210  [    1/ 1184]\n",
      "train loss: 563.878540  [  101/ 1184]\n",
      "train loss: 593.655762  [  201/ 1184]\n",
      "train loss: 600.143738  [  301/ 1184]\n",
      "train loss: 603.477295  [  401/ 1184]\n",
      "train loss: 630.727417  [  501/ 1184]\n",
      "train loss: 580.512268  [  601/ 1184]\n",
      "train loss: 570.779907  [  701/ 1184]\n",
      "train loss: 573.639099  [  801/ 1184]\n",
      "train loss: 521.754211  [  901/ 1184]\n",
      "train loss: 593.598450  [ 1001/ 1184]\n",
      "train loss: 567.108276  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:52:16.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:16.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:18.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:18.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [610.7192993164062, 633.9278564453125, 542.99755859375, 589.985107421875, 570.6625366210938]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:18.347\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -594.3701973830597 is higher than -594.4373000519186, setting new best score to -594.3701973830597\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:18.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (594.437300 --> 594.370197).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 617.973389  [    1/ 1184]\n",
      "train loss: 635.096191  [  101/ 1184]\n",
      "train loss: 573.160583  [  201/ 1184]\n",
      "train loss: 570.252747  [  301/ 1184]\n",
      "train loss: 573.996460  [  401/ 1184]\n",
      "train loss: 543.426636  [  501/ 1184]\n",
      "train loss: 545.922668  [  601/ 1184]\n",
      "train loss: 657.798401  [  701/ 1184]\n",
      "train loss: 627.052612  [  801/ 1184]\n",
      "train loss: 584.291870  [  901/ 1184]\n",
      "train loss: 631.751953  [ 1001/ 1184]\n",
      "train loss: 589.239502  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:52:28.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:28.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:29.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:29.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [610.6259765625, 633.8956298828125, 542.9442138671875, 589.9157104492188, 570.54248046875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:29.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -594.3282318501533 is higher than -594.3701973830597, setting new best score to -594.3282318501533\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:29.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (594.370197 --> 594.328232).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 596.214478  [    1/ 1184]\n",
      "train loss: 579.528625  [  101/ 1184]\n",
      "train loss: 616.708679  [  201/ 1184]\n",
      "train loss: 591.486816  [  301/ 1184]\n",
      "train loss: 614.594055  [  401/ 1184]\n",
      "train loss: 669.428345  [  501/ 1184]\n",
      "train loss: 575.786621  [  601/ 1184]\n",
      "train loss: 600.738647  [  701/ 1184]\n",
      "train loss: 599.102356  [  801/ 1184]\n",
      "train loss: 618.074463  [  901/ 1184]\n",
      "train loss: 602.924072  [ 1001/ 1184]\n",
      "train loss: 579.419434  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:52:39.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:39.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:41.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:41.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [610.5577392578125, 633.8768920898438, 542.845703125, 589.8171997070312, 570.6152954101562]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:41.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -594.2838127812253 is higher than -594.3282318501533, setting new best score to -594.2838127812253\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:41.513\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (594.328232 --> 594.283813).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 558.012451  [    1/ 1184]\n",
      "train loss: 619.192017  [  101/ 1184]\n",
      "train loss: 592.074219  [  201/ 1184]\n",
      "train loss: 602.772095  [  301/ 1184]\n",
      "train loss: 634.252502  [  401/ 1184]\n",
      "train loss: 588.178894  [  501/ 1184]\n",
      "train loss: 621.868896  [  601/ 1184]\n",
      "train loss: 608.651550  [  701/ 1184]\n",
      "train loss: 599.829346  [  801/ 1184]\n",
      "train loss: 569.965332  [  901/ 1184]\n",
      "train loss: 617.836121  [ 1001/ 1184]\n",
      "train loss: 623.491455  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:52:51.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:51.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:53.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:53.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [610.567626953125, 633.8372192382812, 542.7825927734375, 589.7705078125, 570.4962158203125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:53.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -594.2267242045342 is higher than -594.2838127812253, setting new best score to -594.2267242045342\u001b[0m\n",
      "\u001b[32m2023-11-26 20:52:53.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (594.283813 --> 594.226724).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 621.896057  [    1/ 1184]\n",
      "train loss: 640.072510  [  101/ 1184]\n",
      "train loss: 538.376831  [  201/ 1184]\n",
      "train loss: 547.863525  [  301/ 1184]\n",
      "train loss: 660.944336  [  401/ 1184]\n",
      "train loss: 576.152710  [  501/ 1184]\n",
      "train loss: 616.461975  [  601/ 1184]\n",
      "train loss: 642.896362  [  701/ 1184]\n",
      "train loss: 614.899109  [  801/ 1184]\n",
      "train loss: 614.934082  [  901/ 1184]\n",
      "train loss: 628.711609  [ 1001/ 1184]\n",
      "train loss: 524.734863  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:53:03.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:03.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:04.736\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:04.737\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [610.4933471679688, 633.8286743164062, 542.7627563476562, 589.7515258789062, 570.5166625976562]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:04.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -594.2137638912925 is higher than -594.2267242045342, setting new best score to -594.2137638912925\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:04.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (594.226724 --> 594.213764).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 584.265259  [    1/ 1184]\n",
      "train loss: 629.917175  [  101/ 1184]\n",
      "train loss: 598.107849  [  201/ 1184]\n",
      "train loss: 578.018677  [  301/ 1184]\n",
      "train loss: 552.206665  [  401/ 1184]\n",
      "train loss: 606.198792  [  501/ 1184]\n",
      "train loss: 576.434692  [  601/ 1184]\n",
      "train loss: 651.401428  [  701/ 1184]\n",
      "train loss: 582.073486  [  801/ 1184]\n",
      "train loss: 570.455261  [  901/ 1184]\n",
      "train loss: 556.620117  [ 1001/ 1184]\n",
      "train loss: 597.775269  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:53:14.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:14.858\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:16.424\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:16.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [610.5223388671875, 633.727783203125, 542.69287109375, 589.637451171875, 570.3857421875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:16.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -594.1231498621687 is higher than -594.2137638912925, setting new best score to -594.1231498621687\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:16.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (594.213764 --> 594.123150).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 640.759644  [    1/ 1184]\n",
      "train loss: 662.174805  [  101/ 1184]\n",
      "train loss: 613.482910  [  201/ 1184]\n",
      "train loss: 577.519165  [  301/ 1184]\n",
      "train loss: 573.524353  [  401/ 1184]\n",
      "train loss: 594.453796  [  501/ 1184]\n",
      "train loss: 592.625000  [  601/ 1184]\n",
      "train loss: 608.751953  [  701/ 1184]\n",
      "train loss: 615.546021  [  801/ 1184]\n",
      "train loss: 615.477661  [  901/ 1184]\n",
      "train loss: 609.992615  [ 1001/ 1184]\n",
      "train loss: 579.157471  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:53:26.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:26.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:28.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:28.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [610.43701171875, 633.67041015625, 542.6520385742188, 589.5014038085938, 570.4031982421875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:28.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -594.0862408215487 is higher than -594.1231498621687, setting new best score to -594.0862408215487\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:28.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (594.123150 --> 594.086241).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 626.885986  [    1/ 1184]\n",
      "train loss: 548.202759  [  101/ 1184]\n",
      "train loss: 566.782715  [  201/ 1184]\n",
      "train loss: 598.097168  [  301/ 1184]\n",
      "train loss: 628.724915  [  401/ 1184]\n",
      "train loss: 625.040283  [  501/ 1184]\n",
      "train loss: 557.686829  [  601/ 1184]\n",
      "train loss: 572.164062  [  701/ 1184]\n",
      "train loss: 575.367004  [  801/ 1184]\n",
      "train loss: 601.518127  [  901/ 1184]\n",
      "train loss: 606.054199  [ 1001/ 1184]\n",
      "train loss: 617.530457  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:53:38.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:38.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:39.752\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:39.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [610.365234375, 633.6551513671875, 542.5671997070312, 589.4196166992188, 570.3515625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:39.754\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -594.0363355419304 is higher than -594.0862408215487, setting new best score to -594.0363355419304\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:39.755\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (594.086241 --> 594.036336).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 629.366272  [    1/ 1184]\n",
      "train loss: 583.016052  [  101/ 1184]\n",
      "train loss: 574.997009  [  201/ 1184]\n",
      "train loss: 612.250732  [  301/ 1184]\n",
      "train loss: 680.630859  [  401/ 1184]\n",
      "train loss: 606.268188  [  501/ 1184]\n",
      "train loss: 581.459290  [  601/ 1184]\n",
      "train loss: 573.305054  [  701/ 1184]\n",
      "train loss: 588.286865  [  801/ 1184]\n",
      "train loss: 622.575806  [  901/ 1184]\n",
      "train loss: 569.967957  [ 1001/ 1184]\n",
      "train loss: 578.712463  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:53:49.753\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:49.754\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:51.294\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:51.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [610.327880859375, 633.54443359375, 542.4819946289062, 589.3969116210938, 570.30126953125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:51.295\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.963213879549 is higher than -594.0363355419304, setting new best score to -593.963213879549\u001b[0m\n",
      "\u001b[32m2023-11-26 20:53:51.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (594.036336 --> 593.963214).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 575.035400  [    1/ 1184]\n",
      "train loss: 653.429504  [  101/ 1184]\n",
      "train loss: 589.419983  [  201/ 1184]\n",
      "train loss: 595.730957  [  301/ 1184]\n",
      "train loss: 657.196533  [  401/ 1184]\n",
      "train loss: 584.708130  [  501/ 1184]\n",
      "train loss: 634.778198  [  601/ 1184]\n",
      "train loss: 591.492615  [  701/ 1184]\n",
      "train loss: 635.566467  [  801/ 1184]\n",
      "train loss: 586.888489  [  901/ 1184]\n",
      "train loss: 622.105408  [ 1001/ 1184]\n",
      "train loss: 653.303711  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:54:02.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:02.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:04.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:04.275\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [610.2650756835938, 633.5364379882812, 542.493408203125, 589.406494140625, 570.2890014648438]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:04.276\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.9399427196647 is higher than -593.963213879549, setting new best score to -593.9399427196647\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:04.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.963214 --> 593.939943).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 642.168457  [    1/ 1184]\n",
      "train loss: 549.669006  [  101/ 1184]\n",
      "train loss: 543.760132  [  201/ 1184]\n",
      "train loss: 600.854858  [  301/ 1184]\n",
      "train loss: 598.590271  [  401/ 1184]\n",
      "train loss: 593.353149  [  501/ 1184]\n",
      "train loss: 616.897583  [  601/ 1184]\n",
      "train loss: 564.002075  [  701/ 1184]\n",
      "train loss: 587.018127  [  801/ 1184]\n",
      "train loss: 631.719971  [  901/ 1184]\n",
      "train loss: 584.105530  [ 1001/ 1184]\n",
      "train loss: 636.416870  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:54:14.076\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:14.077\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:15.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:15.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [610.2579956054688, 633.5304565429688, 542.3789672851562, 589.2933349609375, 570.2897338867188]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:15.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.918777040892 is higher than -593.9399427196647, setting new best score to -593.918777040892\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:15.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.939943 --> 593.918777).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 609.323303  [    1/ 1184]\n",
      "train loss: 572.939026  [  101/ 1184]\n",
      "train loss: 571.295349  [  201/ 1184]\n",
      "train loss: 526.546265  [  301/ 1184]\n",
      "train loss: 610.515015  [  401/ 1184]\n",
      "train loss: 543.480347  [  501/ 1184]\n",
      "train loss: 547.450867  [  601/ 1184]\n",
      "train loss: 591.427979  [  701/ 1184]\n",
      "train loss: 618.474060  [  801/ 1184]\n",
      "train loss: 618.721008  [  901/ 1184]\n",
      "train loss: 552.047302  [ 1001/ 1184]\n",
      "train loss: 570.192566  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:54:25.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:25.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:27.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:27.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [610.2005615234375, 633.4784545898438, 542.2907104492188, 589.1990966796875, 570.1838989257812]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:27.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.8465236229233 is higher than -593.918777040892, setting new best score to -593.8465236229233\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:27.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.918777 --> 593.846524).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 648.591858  [    1/ 1184]\n",
      "train loss: 586.961914  [  101/ 1184]\n",
      "train loss: 543.907654  [  201/ 1184]\n",
      "train loss: 579.313049  [  301/ 1184]\n",
      "train loss: 590.927917  [  401/ 1184]\n",
      "train loss: 572.187256  [  501/ 1184]\n",
      "train loss: 567.097229  [  601/ 1184]\n",
      "train loss: 584.984009  [  701/ 1184]\n",
      "train loss: 621.644836  [  801/ 1184]\n",
      "train loss: 628.821106  [  901/ 1184]\n",
      "train loss: 643.471130  [ 1001/ 1184]\n",
      "train loss: 638.308167  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:54:37.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:37.043\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:38.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:38.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [610.135498046875, 633.4013671875, 542.2518310546875, 589.117431640625, 570.1448974609375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:38.564\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.8037511125395 is higher than -593.8465236229233, setting new best score to -593.8037511125395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:38.565\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.846524 --> 593.803751).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 576.615356  [    1/ 1184]\n",
      "train loss: 584.014221  [  101/ 1184]\n",
      "train loss: 587.856445  [  201/ 1184]\n",
      "train loss: 618.033752  [  301/ 1184]\n",
      "train loss: 533.085266  [  401/ 1184]\n",
      "train loss: 620.218872  [  501/ 1184]\n",
      "train loss: 571.554932  [  601/ 1184]\n",
      "train loss: 670.231262  [  701/ 1184]\n",
      "train loss: 571.883057  [  801/ 1184]\n",
      "train loss: 639.739563  [  901/ 1184]\n",
      "train loss: 628.388184  [ 1001/ 1184]\n",
      "train loss: 590.485352  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:54:48.435\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:48.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:49.981\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:49.982\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [610.0830688476562, 633.3890380859375, 542.2056884765625, 589.11279296875, 570.1170043945312]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:49.983\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.7593039983435 is higher than -593.8037511125395, setting new best score to -593.7593039983435\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:49.984\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.803751 --> 593.759304).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 616.499329  [    1/ 1184]\n",
      "train loss: 567.745544  [  101/ 1184]\n",
      "train loss: 611.277283  [  201/ 1184]\n",
      "train loss: 601.831360  [  301/ 1184]\n",
      "train loss: 630.207458  [  401/ 1184]\n",
      "train loss: 635.511475  [  501/ 1184]\n",
      "train loss: 600.289062  [  601/ 1184]\n",
      "train loss: 596.722412  [  701/ 1184]\n",
      "train loss: 571.935425  [  801/ 1184]\n",
      "train loss: 568.974915  [  901/ 1184]\n",
      "train loss: 499.603607  [ 1001/ 1184]\n",
      "train loss: 702.629150  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:54:59.917\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:54:59.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:01.490\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:01.491\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.99462890625, 633.2772827148438, 542.146240234375, 588.9600830078125, 570.0344848632812]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:01.492\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.6975897294056 is higher than -593.7593039983435, setting new best score to -593.6975897294056\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:01.493\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.759304 --> 593.697590).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 589.484375  [    1/ 1184]\n",
      "train loss: 623.650269  [  101/ 1184]\n",
      "train loss: 649.584229  [  201/ 1184]\n",
      "train loss: 610.952271  [  301/ 1184]\n",
      "train loss: 534.500916  [  401/ 1184]\n",
      "train loss: 532.040222  [  501/ 1184]\n",
      "train loss: 627.301025  [  601/ 1184]\n",
      "train loss: 559.575500  [  701/ 1184]\n",
      "train loss: 559.397583  [  801/ 1184]\n",
      "train loss: 647.382019  [  901/ 1184]\n",
      "train loss: 605.930115  [ 1001/ 1184]\n",
      "train loss: 579.921326  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:55:11.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:11.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:12.878\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:12.879\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.90869140625, 633.2510986328125, 542.0532836914062, 588.838623046875, 570.00634765625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:12.880\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.6401392683198 is higher than -593.6975897294056, setting new best score to -593.6401392683198\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:12.881\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.697590 --> 593.640139).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 545.473877  [    1/ 1184]\n",
      "train loss: 573.028076  [  101/ 1184]\n",
      "train loss: 618.940552  [  201/ 1184]\n",
      "train loss: 560.264587  [  301/ 1184]\n",
      "train loss: 652.278687  [  401/ 1184]\n",
      "train loss: 639.956421  [  501/ 1184]\n",
      "train loss: 686.784424  [  601/ 1184]\n",
      "train loss: 604.819824  [  701/ 1184]\n",
      "train loss: 545.092896  [  801/ 1184]\n",
      "train loss: 553.552307  [  901/ 1184]\n",
      "train loss: 578.777100  [ 1001/ 1184]\n",
      "train loss: 605.003540  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:55:22.870\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:22.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:24.478\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:24.479\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.8453979492188, 633.2108764648438, 542.0048217773438, 588.9266967773438, 570.0119018554688]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:24.480\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.6202506149872 is higher than -593.6401392683198, setting new best score to -593.6202506149872\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:24.481\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.640139 --> 593.620251).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 635.969482  [    1/ 1184]\n",
      "train loss: 559.384521  [  101/ 1184]\n",
      "train loss: 647.436462  [  201/ 1184]\n",
      "train loss: 627.879944  [  301/ 1184]\n",
      "train loss: 552.924805  [  401/ 1184]\n",
      "train loss: 612.033569  [  501/ 1184]\n",
      "train loss: 581.450134  [  601/ 1184]\n",
      "train loss: 623.941895  [  701/ 1184]\n",
      "train loss: 666.843140  [  801/ 1184]\n",
      "train loss: 550.540955  [  901/ 1184]\n",
      "train loss: 619.192383  [ 1001/ 1184]\n",
      "train loss: 606.731567  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:55:34.511\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:34.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:36.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:36.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.8839111328125, 633.2686157226562, 541.9910888671875, 588.8441162109375, 570.0572509765625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:36.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.6096975592118 is higher than -593.6202506149872, setting new best score to -593.6096975592118\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:36.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.620251 --> 593.609698).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 635.240723  [    1/ 1184]\n",
      "train loss: 621.304077  [  101/ 1184]\n",
      "train loss: 634.391541  [  201/ 1184]\n",
      "train loss: 565.497681  [  301/ 1184]\n",
      "train loss: 545.900391  [  401/ 1184]\n",
      "train loss: 608.082520  [  501/ 1184]\n",
      "train loss: 613.677856  [  601/ 1184]\n",
      "train loss: 606.842651  [  701/ 1184]\n",
      "train loss: 570.204224  [  801/ 1184]\n",
      "train loss: 582.004578  [  901/ 1184]\n",
      "train loss: 597.734619  [ 1001/ 1184]\n",
      "train loss: 600.563049  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:55:46.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:46.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:47.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:47.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.8037109375, 633.140380859375, 542.0078125, 588.8221435546875, 569.9944458007812]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:47.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.5832178043414 is higher than -593.6096975592118, setting new best score to -593.5832178043414\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:47.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.609698 --> 593.583218).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 630.780273  [    1/ 1184]\n",
      "train loss: 539.402832  [  101/ 1184]\n",
      "train loss: 615.432861  [  201/ 1184]\n",
      "train loss: 606.004761  [  301/ 1184]\n",
      "train loss: 606.219421  [  401/ 1184]\n",
      "train loss: 571.128174  [  501/ 1184]\n",
      "train loss: 606.911865  [  601/ 1184]\n",
      "train loss: 619.778931  [  701/ 1184]\n",
      "train loss: 675.787842  [  801/ 1184]\n",
      "train loss: 603.893738  [  901/ 1184]\n",
      "train loss: 567.233032  [ 1001/ 1184]\n",
      "train loss: 596.449158  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:55:57.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:57.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:59.142\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:59.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.7489013671875, 633.1773681640625, 541.9415283203125, 588.7188110351562, 569.9002075195312]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:59.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.5379752243622 is higher than -593.5832178043414, setting new best score to -593.5379752243622\u001b[0m\n",
      "\u001b[32m2023-11-26 20:55:59.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.583218 --> 593.537975).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 571.102783  [    1/ 1184]\n",
      "train loss: 633.651367  [  101/ 1184]\n",
      "train loss: 600.834473  [  201/ 1184]\n",
      "train loss: 613.495056  [  301/ 1184]\n",
      "train loss: 615.776672  [  401/ 1184]\n",
      "train loss: 547.669556  [  501/ 1184]\n",
      "train loss: 584.576599  [  601/ 1184]\n",
      "train loss: 610.294434  [  701/ 1184]\n",
      "train loss: 585.890625  [  801/ 1184]\n",
      "train loss: 612.457031  [  901/ 1184]\n",
      "train loss: 557.233765  [ 1001/ 1184]\n",
      "train loss: 583.660522  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:56:09.029\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:09.030\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:10.569\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:10.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.7261962890625, 633.0655517578125, 541.8775634765625, 588.70947265625, 569.9378662109375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:10.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.5037783079509 is higher than -593.5379752243622, setting new best score to -593.5037783079509\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:10.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.537975 --> 593.503778).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 613.760742  [    1/ 1184]\n",
      "train loss: 572.148865  [  101/ 1184]\n",
      "train loss: 627.858398  [  201/ 1184]\n",
      "train loss: 595.775208  [  301/ 1184]\n",
      "train loss: 568.153687  [  401/ 1184]\n",
      "train loss: 619.613098  [  501/ 1184]\n",
      "train loss: 543.861816  [  601/ 1184]\n",
      "train loss: 545.298462  [  701/ 1184]\n",
      "train loss: 605.740662  [  801/ 1184]\n",
      "train loss: 570.153381  [  901/ 1184]\n",
      "train loss: 653.702942  [ 1001/ 1184]\n",
      "train loss: 599.789062  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:56:20.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:20.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:22.151\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:22.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.7180786132812, 633.0490112304688, 541.8397216796875, 588.6535034179688, 569.9476928710938]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:22.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.492263369017 is higher than -593.5037783079509, setting new best score to -593.492263369017\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:22.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.503778 --> 593.492263).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 585.701904  [    1/ 1184]\n",
      "train loss: 563.266846  [  101/ 1184]\n",
      "train loss: 602.552856  [  201/ 1184]\n",
      "train loss: 614.958557  [  301/ 1184]\n",
      "train loss: 586.982666  [  401/ 1184]\n",
      "train loss: 484.520355  [  501/ 1184]\n",
      "train loss: 549.377686  [  601/ 1184]\n",
      "train loss: 612.264587  [  701/ 1184]\n",
      "train loss: 659.946899  [  801/ 1184]\n",
      "train loss: 613.120911  [  901/ 1184]\n",
      "train loss: 555.992249  [ 1001/ 1184]\n",
      "train loss: 580.813843  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:56:32.068\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:32.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:33.834\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:33.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.658935546875, 633.0281982421875, 541.8297729492188, 588.551513671875, 569.8707885742188]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:33.835\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.4439571332327 is higher than -593.492263369017, setting new best score to -593.4439571332327\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:33.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.492263 --> 593.443957).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 577.162048  [    1/ 1184]\n",
      "train loss: 602.492981  [  101/ 1184]\n",
      "train loss: 521.114380  [  201/ 1184]\n",
      "train loss: 690.684814  [  301/ 1184]\n",
      "train loss: 597.059998  [  401/ 1184]\n",
      "train loss: 616.667847  [  501/ 1184]\n",
      "train loss: 578.356873  [  601/ 1184]\n",
      "train loss: 662.202759  [  701/ 1184]\n",
      "train loss: 571.629883  [  801/ 1184]\n",
      "train loss: 573.562439  [  901/ 1184]\n",
      "train loss: 659.764709  [ 1001/ 1184]\n",
      "train loss: 610.111389  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:56:44.066\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:44.067\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:45.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:45.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.6367797851562, 633.0560302734375, 541.770751953125, 588.62451171875, 569.9000244140625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:45.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -593.446054193038 is lower than -593.4439571332327, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:45.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 598.491455  [    1/ 1184]\n",
      "train loss: 620.847839  [  101/ 1184]\n",
      "train loss: 622.645142  [  201/ 1184]\n",
      "train loss: 601.041199  [  301/ 1184]\n",
      "train loss: 628.255371  [  401/ 1184]\n",
      "train loss: 548.181213  [  501/ 1184]\n",
      "train loss: 587.374878  [  601/ 1184]\n",
      "train loss: 654.641052  [  701/ 1184]\n",
      "train loss: 584.802490  [  801/ 1184]\n",
      "train loss: 559.068604  [  901/ 1184]\n",
      "train loss: 564.790283  [ 1001/ 1184]\n",
      "train loss: 616.568237  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:56:55.595\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:55.596\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:57.256\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:57.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.542724609375, 632.964111328125, 541.6946411132812, 588.5445556640625, 569.8369750976562]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:57.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.3961774222458 is higher than -593.4439571332327, setting new best score to -593.3961774222458\u001b[0m\n",
      "\u001b[32m2023-11-26 20:56:57.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.443957 --> 593.396177).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 637.431030  [    1/ 1184]\n",
      "train loss: 589.011841  [  101/ 1184]\n",
      "train loss: 609.091431  [  201/ 1184]\n",
      "train loss: 594.215698  [  301/ 1184]\n",
      "train loss: 588.414673  [  401/ 1184]\n",
      "train loss: 588.988281  [  501/ 1184]\n",
      "train loss: 613.700928  [  601/ 1184]\n",
      "train loss: 604.011597  [  701/ 1184]\n",
      "train loss: 606.448669  [  801/ 1184]\n",
      "train loss: 561.099243  [  901/ 1184]\n",
      "train loss: 608.450012  [ 1001/ 1184]\n",
      "train loss: 615.468750  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:57:07.527\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:07.528\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:09.186\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:09.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.4573364257812, 632.9192504882812, 541.7291259765625, 588.5200805664062, 569.813232421875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:09.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.3672811387461 is higher than -593.3961774222458, setting new best score to -593.3672811387461\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:09.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.396177 --> 593.367281).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 608.991333  [    1/ 1184]\n",
      "train loss: 561.166870  [  101/ 1184]\n",
      "train loss: 618.343567  [  201/ 1184]\n",
      "train loss: 584.413574  [  301/ 1184]\n",
      "train loss: 572.426147  [  401/ 1184]\n",
      "train loss: 617.278564  [  501/ 1184]\n",
      "train loss: 622.062622  [  601/ 1184]\n",
      "train loss: 605.532959  [  701/ 1184]\n",
      "train loss: 617.925476  [  801/ 1184]\n",
      "train loss: 650.005859  [  901/ 1184]\n",
      "train loss: 579.155029  [ 1001/ 1184]\n",
      "train loss: 590.966492  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:57:19.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:19.255\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:20.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:20.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.4368286132812, 632.935546875, 541.6958618164062, 588.5170288085938, 569.8303833007812]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:20.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.3486950838113 is higher than -593.3672811387461, setting new best score to -593.3486950838113\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:20.795\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.367281 --> 593.348695).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 526.514893  [    1/ 1184]\n",
      "train loss: 549.524048  [  101/ 1184]\n",
      "train loss: 585.513672  [  201/ 1184]\n",
      "train loss: 586.150513  [  301/ 1184]\n",
      "train loss: 637.287598  [  401/ 1184]\n",
      "train loss: 587.637451  [  501/ 1184]\n",
      "train loss: 602.161316  [  601/ 1184]\n",
      "train loss: 631.807861  [  701/ 1184]\n",
      "train loss: 638.697632  [  801/ 1184]\n",
      "train loss: 619.816956  [  901/ 1184]\n",
      "train loss: 628.110535  [ 1001/ 1184]\n",
      "train loss: 666.164856  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:57:30.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:30.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:32.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:32.404\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.3997192382812, 632.8195190429688, 541.61279296875, 588.4290771484375, 569.7132568359375]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:32.405\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.300625262683 is higher than -593.3486950838113, setting new best score to -593.300625262683\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:32.406\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.348695 --> 593.300625).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 584.961670  [    1/ 1184]\n",
      "train loss: 539.238647  [  101/ 1184]\n",
      "train loss: 624.058533  [  201/ 1184]\n",
      "train loss: 583.601440  [  301/ 1184]\n",
      "train loss: 641.773499  [  401/ 1184]\n",
      "train loss: 514.814697  [  501/ 1184]\n",
      "train loss: 634.716370  [  601/ 1184]\n",
      "train loss: 638.073669  [  701/ 1184]\n",
      "train loss: 587.669739  [  801/ 1184]\n",
      "train loss: 622.303223  [  901/ 1184]\n",
      "train loss: 652.187317  [ 1001/ 1184]\n",
      "train loss: 561.391846  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:57:42.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:42.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:43.970\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:43.971\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.3168334960938, 632.8347778320312, 541.6187744140625, 588.363037109375, 569.7206420898438]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:43.972\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.2804783302017 is higher than -593.300625262683, setting new best score to -593.2804783302017\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:43.973\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.300625 --> 593.280478).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 603.667969  [    1/ 1184]\n",
      "train loss: 637.808105  [  101/ 1184]\n",
      "train loss: 579.367859  [  201/ 1184]\n",
      "train loss: 649.468994  [  301/ 1184]\n",
      "train loss: 624.661377  [  401/ 1184]\n",
      "train loss: 587.848389  [  501/ 1184]\n",
      "train loss: 540.541260  [  601/ 1184]\n",
      "train loss: 629.162964  [  701/ 1184]\n",
      "train loss: 607.108276  [  801/ 1184]\n",
      "train loss: 532.770447  [  901/ 1184]\n",
      "train loss: 577.898315  [ 1001/ 1184]\n",
      "train loss: 653.641174  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:57:54.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:54.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:55.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:55.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.3219604492188, 632.8199462890625, 541.5623779296875, 588.36865234375, 569.745361328125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:55.617\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.2681809051128 is higher than -593.2804783302017, setting new best score to -593.2681809051128\u001b[0m\n",
      "\u001b[32m2023-11-26 20:57:55.618\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.280478 --> 593.268181).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 599.347168  [    1/ 1184]\n",
      "train loss: 528.362244  [  101/ 1184]\n",
      "train loss: 553.818481  [  201/ 1184]\n",
      "train loss: 645.491272  [  301/ 1184]\n",
      "train loss: 626.594971  [  401/ 1184]\n",
      "train loss: 587.732544  [  501/ 1184]\n",
      "train loss: 582.452759  [  601/ 1184]\n",
      "train loss: 605.785278  [  701/ 1184]\n",
      "train loss: 577.209778  [  801/ 1184]\n",
      "train loss: 606.372437  [  901/ 1184]\n",
      "train loss: 647.157349  [ 1001/ 1184]\n",
      "train loss: 497.723022  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:58:05.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:05.749\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:07.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:07.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.2987060546875, 632.80224609375, 541.4786376953125, 588.2666625976562, 569.7264404296875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:07.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.2436567475524 is higher than -593.2681809051128, setting new best score to -593.2436567475524\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:07.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.268181 --> 593.243657).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 567.416138  [    1/ 1184]\n",
      "train loss: 538.385376  [  101/ 1184]\n",
      "train loss: 609.985046  [  201/ 1184]\n",
      "train loss: 666.676025  [  301/ 1184]\n",
      "train loss: 672.326782  [  401/ 1184]\n",
      "train loss: 621.127625  [  501/ 1184]\n",
      "train loss: 582.389954  [  601/ 1184]\n",
      "train loss: 547.591553  [  701/ 1184]\n",
      "train loss: 674.664551  [  801/ 1184]\n",
      "train loss: 656.612000  [  901/ 1184]\n",
      "train loss: 575.606812  [ 1001/ 1184]\n",
      "train loss: 608.217407  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:58:17.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:17.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:18.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:18.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.285400390625, 632.7614135742188, 541.5029296875, 588.3141479492188, 569.7310180664062]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:18.903\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.240500534637 is higher than -593.2436567475524, setting new best score to -593.240500534637\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:18.904\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.243657 --> 593.240501).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 600.705627  [    1/ 1184]\n",
      "train loss: 627.922485  [  101/ 1184]\n",
      "train loss: 621.538513  [  201/ 1184]\n",
      "train loss: 539.055847  [  301/ 1184]\n",
      "train loss: 627.282715  [  401/ 1184]\n",
      "train loss: 565.120056  [  501/ 1184]\n",
      "train loss: 571.588074  [  601/ 1184]\n",
      "train loss: 559.599365  [  701/ 1184]\n",
      "train loss: 690.112305  [  801/ 1184]\n",
      "train loss: 619.762817  [  901/ 1184]\n",
      "train loss: 628.126465  [ 1001/ 1184]\n",
      "train loss: 609.181641  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:58:28.957\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:28.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:30.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:30.496\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.273193359375, 632.7449951171875, 541.4862670898438, 588.249267578125, 569.680908203125]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:30.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.1998474121094 is higher than -593.240500534637, setting new best score to -593.1998474121094\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:30.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.240501 --> 593.199847).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 574.778687  [    1/ 1184]\n",
      "train loss: 531.028320  [  101/ 1184]\n",
      "train loss: 626.619141  [  201/ 1184]\n",
      "train loss: 636.837280  [  301/ 1184]\n",
      "train loss: 540.042969  [  401/ 1184]\n",
      "train loss: 660.173889  [  501/ 1184]\n",
      "train loss: 590.668518  [  601/ 1184]\n",
      "train loss: 650.147461  [  701/ 1184]\n",
      "train loss: 579.896484  [  801/ 1184]\n",
      "train loss: 506.276550  [  901/ 1184]\n",
      "train loss: 617.844666  [ 1001/ 1184]\n",
      "train loss: 664.095581  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:58:40.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:40.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:42.460\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:42.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.2545776367188, 632.6974487304688, 541.4340209960938, 588.1884765625, 569.655029296875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:42.461\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.1807475029668 is higher than -593.1998474121094, setting new best score to -593.1807475029668\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:42.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.199847 --> 593.180748).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 589.120300  [    1/ 1184]\n",
      "train loss: 571.137756  [  101/ 1184]\n",
      "train loss: 579.038208  [  201/ 1184]\n",
      "train loss: 584.616516  [  301/ 1184]\n",
      "train loss: 587.996704  [  401/ 1184]\n",
      "train loss: 609.981018  [  501/ 1184]\n",
      "train loss: 532.052307  [  601/ 1184]\n",
      "train loss: 563.948364  [  701/ 1184]\n",
      "train loss: 638.453552  [  801/ 1184]\n",
      "train loss: 559.011902  [  901/ 1184]\n",
      "train loss: 585.392761  [ 1001/ 1184]\n",
      "train loss: 577.612244  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:58:52.905\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:52.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:54.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:54.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.1371459960938, 632.5780639648438, 541.3505859375, 588.0926513671875, 569.5690307617188]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:54.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.120848604999 is higher than -593.1807475029668, setting new best score to -593.120848604999\u001b[0m\n",
      "\u001b[32m2023-11-26 20:58:54.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.180748 --> 593.120849).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 576.007812  [    1/ 1184]\n",
      "train loss: 602.661011  [  101/ 1184]\n",
      "train loss: 617.831299  [  201/ 1184]\n",
      "train loss: 611.012939  [  301/ 1184]\n",
      "train loss: 653.015625  [  401/ 1184]\n",
      "train loss: 646.034668  [  501/ 1184]\n",
      "train loss: 599.517639  [  601/ 1184]\n",
      "train loss: 586.555298  [  701/ 1184]\n",
      "train loss: 560.612061  [  801/ 1184]\n",
      "train loss: 549.483154  [  901/ 1184]\n",
      "train loss: 634.390503  [ 1001/ 1184]\n",
      "train loss: 605.568726  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:59:04.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:04.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:06.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:06.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.1227416992188, 632.5989379882812, 541.3447265625, 588.0919189453125, 569.6053466796875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:06.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.1162673370748 is higher than -593.120848604999, setting new best score to -593.1162673370748\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:06.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.120849 --> 593.116267).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 601.703247  [    1/ 1184]\n",
      "train loss: 591.454712  [  101/ 1184]\n",
      "train loss: 619.054688  [  201/ 1184]\n",
      "train loss: 616.572510  [  301/ 1184]\n",
      "train loss: 590.599548  [  401/ 1184]\n",
      "train loss: 578.375916  [  501/ 1184]\n",
      "train loss: 570.452759  [  601/ 1184]\n",
      "train loss: 607.864807  [  701/ 1184]\n",
      "train loss: 583.308350  [  801/ 1184]\n",
      "train loss: 611.402771  [  901/ 1184]\n",
      "train loss: 640.910278  [ 1001/ 1184]\n",
      "train loss: 589.836365  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:59:16.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:16.292\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:17.830\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:17.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.0873413085938, 632.5285034179688, 541.337646484375, 588.0321044921875, 569.5807495117188]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:17.831\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.0817291646064 is higher than -593.1162673370748, setting new best score to -593.0817291646064\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:17.832\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.116267 --> 593.081729).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 654.325317  [    1/ 1184]\n",
      "train loss: 574.678711  [  101/ 1184]\n",
      "train loss: 597.116760  [  201/ 1184]\n",
      "train loss: 555.296631  [  301/ 1184]\n",
      "train loss: 620.986694  [  401/ 1184]\n",
      "train loss: 661.152710  [  501/ 1184]\n",
      "train loss: 616.706970  [  601/ 1184]\n",
      "train loss: 591.093262  [  701/ 1184]\n",
      "train loss: 587.476929  [  801/ 1184]\n",
      "train loss: 587.857544  [  901/ 1184]\n",
      "train loss: 618.697571  [ 1001/ 1184]\n",
      "train loss: 597.539795  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:59:27.998\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:27.999\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:29.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:29.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.0457763671875, 632.4241943359375, 541.2921752929688, 588.00537109375, 569.5620727539062]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:29.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.0707290069967 is higher than -593.0817291646064, setting new best score to -593.0707290069967\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:29.524\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.081729 --> 593.070729).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 587.032959  [    1/ 1184]\n",
      "train loss: 591.156372  [  101/ 1184]\n",
      "train loss: 640.527405  [  201/ 1184]\n",
      "train loss: 580.532471  [  301/ 1184]\n",
      "train loss: 695.933167  [  401/ 1184]\n",
      "train loss: 555.702515  [  501/ 1184]\n",
      "train loss: 618.776917  [  601/ 1184]\n",
      "train loss: 621.573120  [  701/ 1184]\n",
      "train loss: 604.739990  [  801/ 1184]\n",
      "train loss: 615.156067  [  901/ 1184]\n",
      "train loss: 644.636536  [ 1001/ 1184]\n",
      "train loss: 583.690491  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:59:39.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:39.819\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:41.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:41.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.0286865234375, 632.4906005859375, 541.2745971679688, 587.9453735351562, 569.530029296875]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:41.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -593.036706465709 is higher than -593.0707290069967, setting new best score to -593.036706465709\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:41.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.070729 --> 593.036706).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 574.677856  [    1/ 1184]\n",
      "train loss: 562.375610  [  101/ 1184]\n",
      "train loss: 579.851929  [  201/ 1184]\n",
      "train loss: 616.212097  [  301/ 1184]\n",
      "train loss: 581.381958  [  401/ 1184]\n",
      "train loss: 542.895996  [  501/ 1184]\n",
      "train loss: 614.601074  [  601/ 1184]\n",
      "train loss: 616.244812  [  701/ 1184]\n",
      "train loss: 628.292480  [  801/ 1184]\n",
      "train loss: 547.860962  [  901/ 1184]\n",
      "train loss: 534.734802  [ 1001/ 1184]\n",
      "train loss: 634.805542  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 20:59:52.124\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:52.125\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:53.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:53.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.9344482421875, 632.4451904296875, 541.2112426757812, 587.8629760742188, 569.5006103515625]\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:53.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.9920808816258 is higher than -593.036706465709, setting new best score to -592.9920808816258\u001b[0m\n",
      "\u001b[32m2023-11-26 20:59:53.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (593.036706 --> 592.992081).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 577.263916  [    1/ 1184]\n",
      "train loss: 658.509766  [  101/ 1184]\n",
      "train loss: 536.567261  [  201/ 1184]\n",
      "train loss: 595.760925  [  301/ 1184]\n",
      "train loss: 624.342041  [  401/ 1184]\n",
      "train loss: 567.978271  [  501/ 1184]\n",
      "train loss: 561.312561  [  601/ 1184]\n",
      "train loss: 580.320312  [  701/ 1184]\n",
      "train loss: 657.881958  [  801/ 1184]\n",
      "train loss: 608.887817  [  901/ 1184]\n",
      "train loss: 623.186768  [ 1001/ 1184]\n",
      "train loss: 628.532593  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:00:04.355\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:04.356\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:05.947\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:05.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [609.0242919921875, 632.4685668945312, 541.2423095703125, 587.8658447265625, 569.480712890625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:05.949\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -593.0080642893345 is lower than -592.9920808816258, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:05.950\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 579.669617  [    1/ 1184]\n",
      "train loss: 598.333313  [  101/ 1184]\n",
      "train loss: 601.854065  [  201/ 1184]\n",
      "train loss: 488.492462  [  301/ 1184]\n",
      "train loss: 525.736572  [  401/ 1184]\n",
      "train loss: 547.046692  [  501/ 1184]\n",
      "train loss: 588.072876  [  601/ 1184]\n",
      "train loss: 593.836731  [  701/ 1184]\n",
      "train loss: 585.489319  [  801/ 1184]\n",
      "train loss: 638.508240  [  901/ 1184]\n",
      "train loss: 617.606995  [ 1001/ 1184]\n",
      "train loss: 584.679138  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:00:17.196\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:17.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:18.871\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:18.872\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.9104614257812, 632.362060546875, 541.2286376953125, 587.8701171875, 569.4915771484375]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:18.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.9474174402937 is higher than -592.9920808816258, setting new best score to -592.9474174402937\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:18.873\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.992081 --> 592.947417).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 608.605530  [    1/ 1184]\n",
      "train loss: 590.400391  [  101/ 1184]\n",
      "train loss: 530.494141  [  201/ 1184]\n",
      "train loss: 624.689880  [  301/ 1184]\n",
      "train loss: 544.234863  [  401/ 1184]\n",
      "train loss: 544.095520  [  501/ 1184]\n",
      "train loss: 559.116943  [  601/ 1184]\n",
      "train loss: 596.133423  [  701/ 1184]\n",
      "train loss: 645.631104  [  801/ 1184]\n",
      "train loss: 588.436096  [  901/ 1184]\n",
      "train loss: 578.661743  [ 1001/ 1184]\n",
      "train loss: 618.966980  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:00:29.892\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:29.893\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:31.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:31.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.960205078125, 632.3223266601562, 541.2033081054688, 587.8214111328125, 569.4532470703125]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:31.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.9315932648092 is higher than -592.9474174402937, setting new best score to -592.9315932648092\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:31.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.947417 --> 592.931593).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 652.599854  [    1/ 1184]\n",
      "train loss: 639.402588  [  101/ 1184]\n",
      "train loss: 616.882202  [  201/ 1184]\n",
      "train loss: 618.893494  [  301/ 1184]\n",
      "train loss: 548.236694  [  401/ 1184]\n",
      "train loss: 632.497314  [  501/ 1184]\n",
      "train loss: 575.715698  [  601/ 1184]\n",
      "train loss: 608.110657  [  701/ 1184]\n",
      "train loss: 638.571899  [  801/ 1184]\n",
      "train loss: 581.756836  [  901/ 1184]\n",
      "train loss: 598.140137  [ 1001/ 1184]\n",
      "train loss: 588.043091  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:00:42.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:42.427\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:44.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:44.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.903076171875, 632.3405151367188, 541.1587524414062, 587.7852783203125, 569.36767578125]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:44.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.914505970629 is higher than -592.9315932648092, setting new best score to -592.914505970629\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:44.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.931593 --> 592.914506).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 578.165527  [    1/ 1184]\n",
      "train loss: 597.501770  [  101/ 1184]\n",
      "train loss: 584.663086  [  201/ 1184]\n",
      "train loss: 554.737915  [  301/ 1184]\n",
      "train loss: 582.706848  [  401/ 1184]\n",
      "train loss: 645.700012  [  501/ 1184]\n",
      "train loss: 632.918335  [  601/ 1184]\n",
      "train loss: 545.360474  [  701/ 1184]\n",
      "train loss: 603.808228  [  801/ 1184]\n",
      "train loss: 574.214844  [  901/ 1184]\n",
      "train loss: 571.891296  [ 1001/ 1184]\n",
      "train loss: 598.016479  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:00:54.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:54.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:56.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:56.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.8897094726562, 632.2916870117188, 541.1905517578125, 587.8412475585938, 569.4404907226562]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:56.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.922671779198 is lower than -592.914505970629, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:00:56.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 570.706238  [    1/ 1184]\n",
      "train loss: 598.331177  [  101/ 1184]\n",
      "train loss: 536.229370  [  201/ 1184]\n",
      "train loss: 579.027344  [  301/ 1184]\n",
      "train loss: 577.635193  [  401/ 1184]\n",
      "train loss: 621.056213  [  501/ 1184]\n",
      "train loss: 541.450806  [  601/ 1184]\n",
      "train loss: 562.265381  [  701/ 1184]\n",
      "train loss: 594.638733  [  801/ 1184]\n",
      "train loss: 629.072998  [  901/ 1184]\n",
      "train loss: 581.687134  [ 1001/ 1184]\n",
      "train loss: 632.656189  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:01:06.468\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:06.469\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:08.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:08.201\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.8819580078125, 632.3023071289062, 541.1572875976562, 587.7552490234375, 569.3842163085938]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:08.202\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.8907990660848 is higher than -592.914505970629, setting new best score to -592.8907990660848\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:08.204\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.914506 --> 592.890799).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 578.606262  [    1/ 1184]\n",
      "train loss: 628.021118  [  101/ 1184]\n",
      "train loss: 539.159241  [  201/ 1184]\n",
      "train loss: 599.226562  [  301/ 1184]\n",
      "train loss: 606.975098  [  401/ 1184]\n",
      "train loss: 618.907166  [  501/ 1184]\n",
      "train loss: 620.527649  [  601/ 1184]\n",
      "train loss: 616.578064  [  701/ 1184]\n",
      "train loss: 572.353455  [  801/ 1184]\n",
      "train loss: 609.413086  [  901/ 1184]\n",
      "train loss: 642.282654  [ 1001/ 1184]\n",
      "train loss: 576.416687  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:01:18.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:18.599\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:20.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:20.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.8287963867188, 632.2774658203125, 541.1328735351562, 587.786376953125, 569.3491821289062]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:20.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.8802241458169 is higher than -592.8907990660848, setting new best score to -592.8802241458169\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:20.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.890799 --> 592.880224).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 609.181213  [    1/ 1184]\n",
      "train loss: 600.483459  [  101/ 1184]\n",
      "train loss: 604.769165  [  201/ 1184]\n",
      "train loss: 566.520264  [  301/ 1184]\n",
      "train loss: 609.774902  [  401/ 1184]\n",
      "train loss: 587.935425  [  501/ 1184]\n",
      "train loss: 592.660156  [  601/ 1184]\n",
      "train loss: 592.226257  [  701/ 1184]\n",
      "train loss: 576.017212  [  801/ 1184]\n",
      "train loss: 569.301575  [  901/ 1184]\n",
      "train loss: 528.139404  [ 1001/ 1184]\n",
      "train loss: 569.397461  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:01:30.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:30.780\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:32.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:32.386\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.7740478515625, 632.2941284179688, 541.1273193359375, 587.7607421875, 569.35009765625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:32.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.8470903227601 is higher than -592.8802241458169, setting new best score to -592.8470903227601\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:32.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.880224 --> 592.847090).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 589.379028  [    1/ 1184]\n",
      "train loss: 580.089478  [  101/ 1184]\n",
      "train loss: 617.690369  [  201/ 1184]\n",
      "train loss: 593.279358  [  301/ 1184]\n",
      "train loss: 611.353333  [  401/ 1184]\n",
      "train loss: 581.654175  [  501/ 1184]\n",
      "train loss: 621.703186  [  601/ 1184]\n",
      "train loss: 652.808655  [  701/ 1184]\n",
      "train loss: 616.223267  [  801/ 1184]\n",
      "train loss: 610.071411  [  901/ 1184]\n",
      "train loss: 582.166138  [ 1001/ 1184]\n",
      "train loss: 641.017883  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:01:43.958\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:43.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:45.546\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:45.547\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.7932739257812, 632.2546997070312, 541.1104125976562, 587.743408203125, 569.2716674804688]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:45.548\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.8403159612342 is higher than -592.8470903227601, setting new best score to -592.8403159612342\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:45.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.847090 --> 592.840316).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 560.118469  [    1/ 1184]\n",
      "train loss: 623.759888  [  101/ 1184]\n",
      "train loss: 650.735840  [  201/ 1184]\n",
      "train loss: 639.163513  [  301/ 1184]\n",
      "train loss: 539.959656  [  401/ 1184]\n",
      "train loss: 608.224487  [  501/ 1184]\n",
      "train loss: 595.083557  [  601/ 1184]\n",
      "train loss: 606.246948  [  701/ 1184]\n",
      "train loss: 617.974976  [  801/ 1184]\n",
      "train loss: 638.000732  [  901/ 1184]\n",
      "train loss: 675.375671  [ 1001/ 1184]\n",
      "train loss: 558.575562  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:01:56.013\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:56.014\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:57.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:57.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.7647094726562, 632.2657470703125, 541.0494384765625, 587.7022094726562, 569.2772216796875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:57.607\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.8230399216278 is higher than -592.8403159612342, setting new best score to -592.8230399216278\u001b[0m\n",
      "\u001b[32m2023-11-26 21:01:57.608\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.840316 --> 592.823040).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 621.718445  [    1/ 1184]\n",
      "train loss: 611.949402  [  101/ 1184]\n",
      "train loss: 566.301147  [  201/ 1184]\n",
      "train loss: 666.663818  [  301/ 1184]\n",
      "train loss: 610.085571  [  401/ 1184]\n",
      "train loss: 558.302124  [  501/ 1184]\n",
      "train loss: 544.646118  [  601/ 1184]\n",
      "train loss: 569.226624  [  701/ 1184]\n",
      "train loss: 545.302795  [  801/ 1184]\n",
      "train loss: 603.290710  [  901/ 1184]\n",
      "train loss: 593.808594  [ 1001/ 1184]\n",
      "train loss: 588.713013  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:02:08.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:08.128\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:09.716\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:09.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.722412109375, 632.184814453125, 541.0068359375, 587.6141357421875, 569.2342529296875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:09.717\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.7832181906398 is higher than -592.8230399216278, setting new best score to -592.7832181906398\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:09.719\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.823040 --> 592.783218).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 656.545959  [    1/ 1184]\n",
      "train loss: 560.621094  [  101/ 1184]\n",
      "train loss: 597.604492  [  201/ 1184]\n",
      "train loss: 605.354370  [  301/ 1184]\n",
      "train loss: 640.342285  [  401/ 1184]\n",
      "train loss: 570.406799  [  501/ 1184]\n",
      "train loss: 576.340820  [  601/ 1184]\n",
      "train loss: 615.340027  [  701/ 1184]\n",
      "train loss: 610.736450  [  801/ 1184]\n",
      "train loss: 576.551575  [  901/ 1184]\n",
      "train loss: 525.262939  [ 1001/ 1184]\n",
      "train loss: 566.052429  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:02:20.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:20.241\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:21.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:21.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.7894897460938, 632.1505126953125, 541.0098266601562, 587.7027587890625, 569.2828979492188]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:21.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.7934531682654 is lower than -592.7832181906398, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:21.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 594.185181  [    1/ 1184]\n",
      "train loss: 614.763916  [  101/ 1184]\n",
      "train loss: 607.616211  [  201/ 1184]\n",
      "train loss: 555.412415  [  301/ 1184]\n",
      "train loss: 624.205627  [  401/ 1184]\n",
      "train loss: 662.465515  [  501/ 1184]\n",
      "train loss: 649.838867  [  601/ 1184]\n",
      "train loss: 542.859863  [  701/ 1184]\n",
      "train loss: 567.447388  [  801/ 1184]\n",
      "train loss: 649.273987  [  901/ 1184]\n",
      "train loss: 580.259583  [ 1001/ 1184]\n",
      "train loss: 657.180420  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:02:33.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:33.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:34.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:34.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.72998046875, 632.1266479492188, 541.020263671875, 587.6744384765625, 569.2361450195312]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:34.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.7719657801374 is higher than -592.7832181906398, setting new best score to -592.7719657801374\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:34.640\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.783218 --> 592.771966).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 591.281067  [    1/ 1184]\n",
      "train loss: 601.817627  [  101/ 1184]\n",
      "train loss: 564.473389  [  201/ 1184]\n",
      "train loss: 666.125671  [  301/ 1184]\n",
      "train loss: 595.606873  [  401/ 1184]\n",
      "train loss: 636.823303  [  501/ 1184]\n",
      "train loss: 578.818909  [  601/ 1184]\n",
      "train loss: 641.990601  [  701/ 1184]\n",
      "train loss: 563.122864  [  801/ 1184]\n",
      "train loss: 565.526917  [  901/ 1184]\n",
      "train loss: 660.054443  [ 1001/ 1184]\n",
      "train loss: 603.274414  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:02:45.162\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:45.163\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:46.765\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:46.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.6922607421875, 632.1932983398438, 540.9539794921875, 587.6414794921875, 569.2035522460938]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:46.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.7500706926177 is higher than -592.7719657801374, setting new best score to -592.7500706926177\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:46.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.771966 --> 592.750071).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 641.592041  [    1/ 1184]\n",
      "train loss: 611.467651  [  101/ 1184]\n",
      "train loss: 558.650330  [  201/ 1184]\n",
      "train loss: 603.320435  [  301/ 1184]\n",
      "train loss: 617.201355  [  401/ 1184]\n",
      "train loss: 617.448914  [  501/ 1184]\n",
      "train loss: 624.745361  [  601/ 1184]\n",
      "train loss: 606.325439  [  701/ 1184]\n",
      "train loss: 614.669128  [  801/ 1184]\n",
      "train loss: 630.353638  [  901/ 1184]\n",
      "train loss: 590.728271  [ 1001/ 1184]\n",
      "train loss: 594.646729  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:02:57.345\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:57.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:58.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:58.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.5624389648438, 632.0189208984375, 540.97216796875, 587.5130004882812, 569.1439208984375]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:58.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.7049347310127 is higher than -592.7500706926177, setting new best score to -592.7049347310127\u001b[0m\n",
      "\u001b[32m2023-11-26 21:02:58.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.750071 --> 592.704935).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 613.543884  [    1/ 1184]\n",
      "train loss: 626.959595  [  101/ 1184]\n",
      "train loss: 629.390808  [  201/ 1184]\n",
      "train loss: 589.785950  [  301/ 1184]\n",
      "train loss: 604.801575  [  401/ 1184]\n",
      "train loss: 582.033569  [  501/ 1184]\n",
      "train loss: 574.465454  [  601/ 1184]\n",
      "train loss: 585.173950  [  701/ 1184]\n",
      "train loss: 640.319092  [  801/ 1184]\n",
      "train loss: 584.659119  [  901/ 1184]\n",
      "train loss: 604.560974  [ 1001/ 1184]\n",
      "train loss: 611.892273  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:03:09.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:09.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:10.912\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:10.913\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.6407470703125, 632.0621337890625, 540.9945068359375, 587.5941162109375, 569.2061157226562]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:10.914\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.7252525619314 is lower than -592.7049347310127, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:10.915\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 571.310791  [    1/ 1184]\n",
      "train loss: 622.148804  [  101/ 1184]\n",
      "train loss: 590.537659  [  201/ 1184]\n",
      "train loss: 579.272095  [  301/ 1184]\n",
      "train loss: 544.913330  [  401/ 1184]\n",
      "train loss: 584.265137  [  501/ 1184]\n",
      "train loss: 568.778625  [  601/ 1184]\n",
      "train loss: 594.057373  [  701/ 1184]\n",
      "train loss: 596.951965  [  801/ 1184]\n",
      "train loss: 613.314575  [  901/ 1184]\n",
      "train loss: 604.605103  [ 1001/ 1184]\n",
      "train loss: 602.215881  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:03:21.126\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:21.127\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:22.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:22.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.5416259765625, 632.0335083007812, 540.9273681640625, 587.5218505859375, 569.0908813476562]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:22.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.6995685818829 is higher than -592.7049347310127, setting new best score to -592.6995685818829\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:22.701\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.704935 --> 592.699569).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 527.494019  [    1/ 1184]\n",
      "train loss: 574.734497  [  101/ 1184]\n",
      "train loss: 655.561279  [  201/ 1184]\n",
      "train loss: 531.878906  [  301/ 1184]\n",
      "train loss: 589.618286  [  401/ 1184]\n",
      "train loss: 565.793518  [  501/ 1184]\n",
      "train loss: 601.812256  [  601/ 1184]\n",
      "train loss: 584.361267  [  701/ 1184]\n",
      "train loss: 536.788696  [  801/ 1184]\n",
      "train loss: 620.434631  [  901/ 1184]\n",
      "train loss: 620.516724  [ 1001/ 1184]\n",
      "train loss: 589.828979  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:03:32.934\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:32.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:34.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:34.516\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.4994506835938, 632.0963134765625, 540.936279296875, 587.5220336914062, 569.117431640625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:34.517\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.6767170193829 is higher than -592.6995685818829, setting new best score to -592.6767170193829\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:34.518\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.699569 --> 592.676717).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 612.218689  [    1/ 1184]\n",
      "train loss: 613.252625  [  101/ 1184]\n",
      "train loss: 606.253906  [  201/ 1184]\n",
      "train loss: 599.319763  [  301/ 1184]\n",
      "train loss: 638.627441  [  401/ 1184]\n",
      "train loss: 572.368652  [  501/ 1184]\n",
      "train loss: 614.067810  [  601/ 1184]\n",
      "train loss: 579.194031  [  701/ 1184]\n",
      "train loss: 626.427002  [  801/ 1184]\n",
      "train loss: 560.835815  [  901/ 1184]\n",
      "train loss: 572.456848  [ 1001/ 1184]\n",
      "train loss: 592.257324  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:03:44.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:44.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:46.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:46.312\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.5159301757812, 632.1434936523438, 540.91748046875, 587.4987182617188, 569.11474609375]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:46.313\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.676497910898 is higher than -592.6767170193829, setting new best score to -592.676497910898\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:46.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.676717 --> 592.676498).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 548.656006  [    1/ 1184]\n",
      "train loss: 552.194580  [  101/ 1184]\n",
      "train loss: 566.076782  [  201/ 1184]\n",
      "train loss: 580.156067  [  301/ 1184]\n",
      "train loss: 598.359985  [  401/ 1184]\n",
      "train loss: 602.524536  [  501/ 1184]\n",
      "train loss: 675.634766  [  601/ 1184]\n",
      "train loss: 675.959839  [  701/ 1184]\n",
      "train loss: 612.724854  [  801/ 1184]\n",
      "train loss: 630.322205  [  901/ 1184]\n",
      "train loss: 570.539490  [ 1001/ 1184]\n",
      "train loss: 586.235840  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:03:56.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:56.398\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:58.018\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:58.019\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.5, 632.0952758789062, 540.9227905273438, 587.5076293945312, 569.095703125]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:58.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.6673574713212 is higher than -592.676497910898, setting new best score to -592.6673574713212\u001b[0m\n",
      "\u001b[32m2023-11-26 21:03:58.020\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.676498 --> 592.667357).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 583.922852  [    1/ 1184]\n",
      "train loss: 613.662964  [  101/ 1184]\n",
      "train loss: 612.090576  [  201/ 1184]\n",
      "train loss: 540.394531  [  301/ 1184]\n",
      "train loss: 538.195374  [  401/ 1184]\n",
      "train loss: 607.304810  [  501/ 1184]\n",
      "train loss: 675.826660  [  601/ 1184]\n",
      "train loss: 629.273682  [  701/ 1184]\n",
      "train loss: 519.889526  [  801/ 1184]\n",
      "train loss: 554.979126  [  901/ 1184]\n",
      "train loss: 623.484924  [ 1001/ 1184]\n",
      "train loss: 601.228760  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:04:08.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:08.271\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:09.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:09.802\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.4539184570312, 632.0449829101562, 540.877197265625, 587.4569091796875, 569.076416015625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:09.803\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.6391194403926 is higher than -592.6673574713212, setting new best score to -592.6391194403926\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:09.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.667357 --> 592.639119).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 537.220947  [    1/ 1184]\n",
      "train loss: 564.628296  [  101/ 1184]\n",
      "train loss: 615.809631  [  201/ 1184]\n",
      "train loss: 577.827026  [  301/ 1184]\n",
      "train loss: 622.173950  [  401/ 1184]\n",
      "train loss: 615.323364  [  501/ 1184]\n",
      "train loss: 590.131042  [  601/ 1184]\n",
      "train loss: 639.155029  [  701/ 1184]\n",
      "train loss: 587.377380  [  801/ 1184]\n",
      "train loss: 661.505371  [  901/ 1184]\n",
      "train loss: 654.677429  [ 1001/ 1184]\n",
      "train loss: 586.744629  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:04:20.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:20.079\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:21.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:21.604\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.467529296875, 632.0230712890625, 540.8490600585938, 587.4801025390625, 569.089111328125]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:21.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.6356610648239 is higher than -592.6391194403926, setting new best score to -592.6356610648239\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:21.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.639119 --> 592.635661).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 610.778137  [    1/ 1184]\n",
      "train loss: 572.246277  [  101/ 1184]\n",
      "train loss: 583.174683  [  201/ 1184]\n",
      "train loss: 613.408691  [  301/ 1184]\n",
      "train loss: 585.729187  [  401/ 1184]\n",
      "train loss: 585.978760  [  501/ 1184]\n",
      "train loss: 620.739014  [  601/ 1184]\n",
      "train loss: 613.882629  [  701/ 1184]\n",
      "train loss: 578.716125  [  801/ 1184]\n",
      "train loss: 606.560181  [  901/ 1184]\n",
      "train loss: 611.497314  [ 1001/ 1184]\n",
      "train loss: 553.714966  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:04:31.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:31.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:33.499\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:33.500\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.4852905273438, 631.9602661132812, 540.7872924804688, 587.4019165039062, 569.0670166015625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:33.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.5976931801325 is higher than -592.6356610648239, setting new best score to -592.5976931801325\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:33.502\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.635661 --> 592.597693).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 639.029785  [    1/ 1184]\n",
      "train loss: 660.521729  [  101/ 1184]\n",
      "train loss: 659.243591  [  201/ 1184]\n",
      "train loss: 600.045166  [  301/ 1184]\n",
      "train loss: 586.232544  [  401/ 1184]\n",
      "train loss: 610.219727  [  501/ 1184]\n",
      "train loss: 585.026245  [  601/ 1184]\n",
      "train loss: 616.937805  [  701/ 1184]\n",
      "train loss: 636.249695  [  801/ 1184]\n",
      "train loss: 670.962402  [  901/ 1184]\n",
      "train loss: 591.504578  [ 1001/ 1184]\n",
      "train loss: 595.547607  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:04:43.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:43.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:45.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:45.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.4248046875, 632.0107421875, 540.7918701171875, 587.4208374023438, 569.017578125]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:45.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.5811982360067 is higher than -592.5976931801325, setting new best score to -592.5811982360067\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:45.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.597693 --> 592.581198).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 557.589722  [    1/ 1184]\n",
      "train loss: 575.659180  [  101/ 1184]\n",
      "train loss: 651.482300  [  201/ 1184]\n",
      "train loss: 600.824463  [  301/ 1184]\n",
      "train loss: 565.106445  [  401/ 1184]\n",
      "train loss: 595.630737  [  501/ 1184]\n",
      "train loss: 571.210876  [  601/ 1184]\n",
      "train loss: 565.579346  [  701/ 1184]\n",
      "train loss: 619.877136  [  801/ 1184]\n",
      "train loss: 657.648376  [  901/ 1184]\n",
      "train loss: 612.308777  [ 1001/ 1184]\n",
      "train loss: 615.212708  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:04:55.538\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:55.539\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:57.188\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:57.189\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.4649658203125, 631.9901733398438, 540.7988891601562, 587.4205932617188, 569.0198364257812]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:57.190\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.584691996514 is lower than -592.5811982360067, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:04:57.191\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 616.454895  [    1/ 1184]\n",
      "train loss: 633.168945  [  101/ 1184]\n",
      "train loss: 586.961426  [  201/ 1184]\n",
      "train loss: 582.533630  [  301/ 1184]\n",
      "train loss: 617.289856  [  401/ 1184]\n",
      "train loss: 621.032837  [  501/ 1184]\n",
      "train loss: 616.930420  [  601/ 1184]\n",
      "train loss: 626.100952  [  701/ 1184]\n",
      "train loss: 592.923523  [  801/ 1184]\n",
      "train loss: 638.443970  [  901/ 1184]\n",
      "train loss: 578.345947  [ 1001/ 1184]\n",
      "train loss: 593.303894  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:05:07.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:07.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:08.899\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:08.900\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.4010620117188, 631.9278564453125, 540.7589721679688, 587.4163818359375, 569.0238647460938]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:08.901\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.5611692790744 is higher than -592.5811982360067, setting new best score to -592.5611692790744\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:08.902\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.581198 --> 592.561169).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 652.285461  [    1/ 1184]\n",
      "train loss: 704.695251  [  101/ 1184]\n",
      "train loss: 545.793823  [  201/ 1184]\n",
      "train loss: 523.353210  [  301/ 1184]\n",
      "train loss: 541.211060  [  401/ 1184]\n",
      "train loss: 573.959534  [  501/ 1184]\n",
      "train loss: 597.330872  [  601/ 1184]\n",
      "train loss: 587.241028  [  701/ 1184]\n",
      "train loss: 558.286011  [  801/ 1184]\n",
      "train loss: 571.605652  [  901/ 1184]\n",
      "train loss: 615.897461  [ 1001/ 1184]\n",
      "train loss: 616.524353  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:05:19.156\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:19.157\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:20.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:20.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.3678588867188, 631.945556640625, 540.7160034179688, 587.3763427734375, 568.9703369140625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:20.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.5333326122429 is higher than -592.5611692790744, setting new best score to -592.5333326122429\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:20.692\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.561169 --> 592.533333).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 575.549438  [    1/ 1184]\n",
      "train loss: 567.540955  [  101/ 1184]\n",
      "train loss: 551.805542  [  201/ 1184]\n",
      "train loss: 586.021729  [  301/ 1184]\n",
      "train loss: 655.619263  [  401/ 1184]\n",
      "train loss: 617.985474  [  501/ 1184]\n",
      "train loss: 651.131348  [  601/ 1184]\n",
      "train loss: 607.766174  [  701/ 1184]\n",
      "train loss: 575.560242  [  801/ 1184]\n",
      "train loss: 586.260803  [  901/ 1184]\n",
      "train loss: 603.565857  [ 1001/ 1184]\n",
      "train loss: 562.344543  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:05:31.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:31.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:32.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:32.792\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.41162109375, 632.0093383789062, 540.7582397460938, 587.3135375976562, 569.0029907226562]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:32.793\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.5452966617632 is lower than -592.5333326122429, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:32.794\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 664.963257  [    1/ 1184]\n",
      "train loss: 586.236694  [  101/ 1184]\n",
      "train loss: 568.197876  [  201/ 1184]\n",
      "train loss: 622.950928  [  301/ 1184]\n",
      "train loss: 541.115051  [  401/ 1184]\n",
      "train loss: 527.980225  [  501/ 1184]\n",
      "train loss: 623.834595  [  601/ 1184]\n",
      "train loss: 559.853516  [  701/ 1184]\n",
      "train loss: 590.148804  [  801/ 1184]\n",
      "train loss: 623.526428  [  901/ 1184]\n",
      "train loss: 591.640137  [ 1001/ 1184]\n",
      "train loss: 573.740112  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:05:43.152\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:43.153\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:44.686\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:44.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.347412109375, 632.0029296875, 540.7490234375, 587.4299926757812, 569.0211181640625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:44.687\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.5766137231755 is lower than -592.5333326122429, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:44.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 554.913513  [    1/ 1184]\n",
      "train loss: 558.656372  [  101/ 1184]\n",
      "train loss: 640.424683  [  201/ 1184]\n",
      "train loss: 598.454041  [  301/ 1184]\n",
      "train loss: 585.793457  [  401/ 1184]\n",
      "train loss: 593.833252  [  501/ 1184]\n",
      "train loss: 519.046326  [  601/ 1184]\n",
      "train loss: 609.018066  [  701/ 1184]\n",
      "train loss: 577.820679  [  801/ 1184]\n",
      "train loss: 558.569519  [  901/ 1184]\n",
      "train loss: 590.975891  [ 1001/ 1184]\n",
      "train loss: 573.194275  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:05:54.996\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:54.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:56.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:56.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.3269653320312, 631.9636840820312, 540.7100830078125, 587.3396606445312, 568.96435546875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:56.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.5355418531201 is lower than -592.5333326122429, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:05:56.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 3 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 636.423950  [    1/ 1184]\n",
      "train loss: 608.137634  [  101/ 1184]\n",
      "train loss: 560.628845  [  201/ 1184]\n",
      "train loss: 644.961670  [  301/ 1184]\n",
      "train loss: 644.824402  [  401/ 1184]\n",
      "train loss: 550.935059  [  501/ 1184]\n",
      "train loss: 601.087219  [  601/ 1184]\n",
      "train loss: 605.307434  [  701/ 1184]\n",
      "train loss: 573.084717  [  801/ 1184]\n",
      "train loss: 555.655212  [  901/ 1184]\n",
      "train loss: 543.937622  [ 1001/ 1184]\n",
      "train loss: 574.272217  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:06:06.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:06.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:08.436\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:08.437\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.290771484375, 631.9288940429688, 540.6761474609375, 587.2867431640625, 568.9462890625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:08.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.5053760383703 is higher than -592.5333326122429, setting new best score to -592.5053760383703\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:08.439\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.533333 --> 592.505376).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 573.267822  [    1/ 1184]\n",
      "train loss: 615.989746  [  101/ 1184]\n",
      "train loss: 707.292480  [  201/ 1184]\n",
      "train loss: 592.386475  [  301/ 1184]\n",
      "train loss: 549.167847  [  401/ 1184]\n",
      "train loss: 638.679932  [  501/ 1184]\n",
      "train loss: 645.214478  [  601/ 1184]\n",
      "train loss: 577.116272  [  701/ 1184]\n",
      "train loss: 649.211487  [  801/ 1184]\n",
      "train loss: 550.994324  [  901/ 1184]\n",
      "train loss: 636.178589  [ 1001/ 1184]\n",
      "train loss: 575.218384  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:06:18.605\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:18.606\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:20.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:20.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.2127685546875, 631.9256591796875, 540.6705932617188, 587.2348022460938, 568.91455078125]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:20.466\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.4842401045787 is higher than -592.5053760383703, setting new best score to -592.4842401045787\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:20.467\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.505376 --> 592.484240).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 614.656006  [    1/ 1184]\n",
      "train loss: 622.499512  [  101/ 1184]\n",
      "train loss: 625.856873  [  201/ 1184]\n",
      "train loss: 535.044922  [  301/ 1184]\n",
      "train loss: 567.026184  [  401/ 1184]\n",
      "train loss: 592.111084  [  501/ 1184]\n",
      "train loss: 594.054016  [  601/ 1184]\n",
      "train loss: 568.941833  [  701/ 1184]\n",
      "train loss: 587.757141  [  801/ 1184]\n",
      "train loss: 578.440796  [  901/ 1184]\n",
      "train loss: 624.755920  [ 1001/ 1184]\n",
      "train loss: 572.633789  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:06:30.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:30.702\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:32.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:32.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.302734375, 631.9926147460938, 540.6385498046875, 587.2942504882812, 568.8525390625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:32.343\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.4947918469393 is lower than -592.4842401045787, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:32.344\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 667.323303  [    1/ 1184]\n",
      "train loss: 574.830688  [  101/ 1184]\n",
      "train loss: 557.693665  [  201/ 1184]\n",
      "train loss: 617.130127  [  301/ 1184]\n",
      "train loss: 607.494568  [  401/ 1184]\n",
      "train loss: 621.312195  [  501/ 1184]\n",
      "train loss: 532.277588  [  601/ 1184]\n",
      "train loss: 577.857849  [  701/ 1184]\n",
      "train loss: 638.400757  [  801/ 1184]\n",
      "train loss: 580.971436  [  901/ 1184]\n",
      "train loss: 621.932983  [ 1001/ 1184]\n",
      "train loss: 612.731628  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:06:42.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:42.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:44.197\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:44.198\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.2871704101562, 631.9208984375, 540.655517578125, 587.314697265625, 568.921630859375]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:44.199\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.4893381625791 is lower than -592.4842401045787, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:44.200\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 588.779541  [    1/ 1184]\n",
      "train loss: 614.820679  [  101/ 1184]\n",
      "train loss: 607.107422  [  201/ 1184]\n",
      "train loss: 585.721619  [  301/ 1184]\n",
      "train loss: 590.218262  [  401/ 1184]\n",
      "train loss: 628.371460  [  501/ 1184]\n",
      "train loss: 618.056091  [  601/ 1184]\n",
      "train loss: 542.366943  [  701/ 1184]\n",
      "train loss: 630.848083  [  801/ 1184]\n",
      "train loss: 604.532349  [  901/ 1184]\n",
      "train loss: 590.750061  [ 1001/ 1184]\n",
      "train loss: 654.457336  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:06:54.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:54.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:55.959\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:55.960\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.3172607421875, 631.9348754882812, 540.6666870117188, 587.370849609375, 568.876220703125]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:55.961\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.4759455813637 is higher than -592.4842401045787, setting new best score to -592.4759455813637\u001b[0m\n",
      "\u001b[32m2023-11-26 21:06:55.962\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.484240 --> 592.475946).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 581.751160  [    1/ 1184]\n",
      "train loss: 626.635376  [  101/ 1184]\n",
      "train loss: 601.636536  [  201/ 1184]\n",
      "train loss: 564.047791  [  301/ 1184]\n",
      "train loss: 561.962952  [  401/ 1184]\n",
      "train loss: 598.220947  [  501/ 1184]\n",
      "train loss: 598.025085  [  601/ 1184]\n",
      "train loss: 578.064392  [  701/ 1184]\n",
      "train loss: 591.156799  [  801/ 1184]\n",
      "train loss: 607.503479  [  901/ 1184]\n",
      "train loss: 613.096924  [ 1001/ 1184]\n",
      "train loss: 584.557556  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:07:06.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:06.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:08.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:08.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.2251586914062, 631.8768920898438, 540.6602783203125, 587.3231811523438, 568.8681030273438]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:08.322\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.4593366019334 is higher than -592.4759455813637, setting new best score to -592.4593366019334\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:08.324\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.475946 --> 592.459337).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 547.480713  [    1/ 1184]\n",
      "train loss: 611.631165  [  101/ 1184]\n",
      "train loss: 560.488770  [  201/ 1184]\n",
      "train loss: 572.094482  [  301/ 1184]\n",
      "train loss: 624.484741  [  401/ 1184]\n",
      "train loss: 586.669617  [  501/ 1184]\n",
      "train loss: 633.761780  [  601/ 1184]\n",
      "train loss: 561.711670  [  701/ 1184]\n",
      "train loss: 581.274048  [  801/ 1184]\n",
      "train loss: 559.946899  [  901/ 1184]\n",
      "train loss: 551.878357  [ 1001/ 1184]\n",
      "train loss: 573.239014  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:07:18.706\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:18.707\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:20.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:20.462\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.2839965820312, 631.9059448242188, 540.662353515625, 587.2877807617188, 568.8667602539062]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:20.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.4723454342612 is lower than -592.4593366019334, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:20.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 576.981689  [    1/ 1184]\n",
      "train loss: 557.722168  [  101/ 1184]\n",
      "train loss: 653.041077  [  201/ 1184]\n",
      "train loss: 539.957336  [  301/ 1184]\n",
      "train loss: 511.729279  [  401/ 1184]\n",
      "train loss: 548.817566  [  501/ 1184]\n",
      "train loss: 523.363281  [  601/ 1184]\n",
      "train loss: 544.238525  [  701/ 1184]\n",
      "train loss: 603.019958  [  801/ 1184]\n",
      "train loss: 558.057251  [  901/ 1184]\n",
      "train loss: 579.502930  [ 1001/ 1184]\n",
      "train loss: 595.171204  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:07:30.638\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:30.639\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:32.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:32.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.2783813476562, 631.8419189453125, 540.59814453125, 587.2532348632812, 568.8797607421875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:32.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.430639262139 is higher than -592.4593366019334, setting new best score to -592.430639262139\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:32.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.459337 --> 592.430639).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 567.291870  [    1/ 1184]\n",
      "train loss: 617.701843  [  101/ 1184]\n",
      "train loss: 638.687744  [  201/ 1184]\n",
      "train loss: 581.432434  [  301/ 1184]\n",
      "train loss: 570.903809  [  401/ 1184]\n",
      "train loss: 592.681396  [  501/ 1184]\n",
      "train loss: 620.657349  [  601/ 1184]\n",
      "train loss: 636.887817  [  701/ 1184]\n",
      "train loss: 586.104797  [  801/ 1184]\n",
      "train loss: 586.013733  [  901/ 1184]\n",
      "train loss: 614.787720  [ 1001/ 1184]\n",
      "train loss: 585.033325  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:07:42.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:42.610\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:44.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:44.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.2070922851562, 631.8378295898438, 540.582763671875, 587.2179565429688, 568.8661499023438]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:44.248\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.3959386125396 is higher than -592.430639262139, setting new best score to -592.3959386125396\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:44.249\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.430639 --> 592.395939).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 607.827026  [    1/ 1184]\n",
      "train loss: 559.492920  [  101/ 1184]\n",
      "train loss: 590.801758  [  201/ 1184]\n",
      "train loss: 691.033936  [  301/ 1184]\n",
      "train loss: 649.970520  [  401/ 1184]\n",
      "train loss: 572.378113  [  501/ 1184]\n",
      "train loss: 543.108765  [  601/ 1184]\n",
      "train loss: 631.575012  [  701/ 1184]\n",
      "train loss: 527.116882  [  801/ 1184]\n",
      "train loss: 598.523071  [  901/ 1184]\n",
      "train loss: 549.231445  [ 1001/ 1184]\n",
      "train loss: 615.213257  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:07:54.472\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:54.473\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:56.135\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:56.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.1988525390625, 631.7808837890625, 540.5582275390625, 587.2498779296875, 568.8416137695312]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:56.136\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.3969838589053 is lower than -592.3959386125396, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:07:56.137\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 631.447876  [    1/ 1184]\n",
      "train loss: 637.635437  [  101/ 1184]\n",
      "train loss: 618.405945  [  201/ 1184]\n",
      "train loss: 606.901245  [  301/ 1184]\n",
      "train loss: 597.951477  [  401/ 1184]\n",
      "train loss: 599.901733  [  501/ 1184]\n",
      "train loss: 620.505127  [  601/ 1184]\n",
      "train loss: 690.158691  [  701/ 1184]\n",
      "train loss: 623.498230  [  801/ 1184]\n",
      "train loss: 619.035706  [  901/ 1184]\n",
      "train loss: 581.470825  [ 1001/ 1184]\n",
      "train loss: 535.654419  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:08:06.425\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:06.426\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:08.059\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:08.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.1558227539062, 631.8181762695312, 540.60595703125, 587.2192993164062, 568.8707885742188]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:08.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.4056415799298 is lower than -592.3959386125396, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:08.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 562.998230  [    1/ 1184]\n",
      "train loss: 565.915283  [  101/ 1184]\n",
      "train loss: 603.426880  [  201/ 1184]\n",
      "train loss: 638.924500  [  301/ 1184]\n",
      "train loss: 534.515076  [  401/ 1184]\n",
      "train loss: 621.772217  [  501/ 1184]\n",
      "train loss: 634.847656  [  601/ 1184]\n",
      "train loss: 626.402893  [  701/ 1184]\n",
      "train loss: 551.844727  [  801/ 1184]\n",
      "train loss: 570.437683  [  901/ 1184]\n",
      "train loss: 548.969666  [ 1001/ 1184]\n",
      "train loss: 569.690613  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:08:18.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:18.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:19.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:19.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.1422119140625, 631.7869262695312, 540.523193359375, 587.189208984375, 568.8016357421875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:19.938\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.3862945170342 is higher than -592.3959386125396, setting new best score to -592.3862945170342\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:19.939\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.395939 --> 592.386295).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 668.784058  [    1/ 1184]\n",
      "train loss: 637.660095  [  101/ 1184]\n",
      "train loss: 566.240295  [  201/ 1184]\n",
      "train loss: 621.769531  [  301/ 1184]\n",
      "train loss: 654.203430  [  401/ 1184]\n",
      "train loss: 545.420959  [  501/ 1184]\n",
      "train loss: 645.024902  [  601/ 1184]\n",
      "train loss: 593.000854  [  701/ 1184]\n",
      "train loss: 661.993164  [  801/ 1184]\n",
      "train loss: 622.824524  [  901/ 1184]\n",
      "train loss: 605.570984  [ 1001/ 1184]\n",
      "train loss: 575.742554  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:08:30.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:30.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:31.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:31.849\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.1701049804688, 631.8179321289062, 540.5718994140625, 587.1854248046875, 568.8588256835938]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:31.850\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.3836784266218 is higher than -592.3862945170342, setting new best score to -592.3836784266218\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:31.851\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.386295 --> 592.383678).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 547.188538  [    1/ 1184]\n",
      "train loss: 581.323914  [  101/ 1184]\n",
      "train loss: 603.965820  [  201/ 1184]\n",
      "train loss: 619.124084  [  301/ 1184]\n",
      "train loss: 593.031006  [  401/ 1184]\n",
      "train loss: 647.019409  [  501/ 1184]\n",
      "train loss: 573.860840  [  601/ 1184]\n",
      "train loss: 594.111023  [  701/ 1184]\n",
      "train loss: 575.280701  [  801/ 1184]\n",
      "train loss: 594.641663  [  901/ 1184]\n",
      "train loss: 619.455017  [ 1001/ 1184]\n",
      "train loss: 634.829407  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:08:42.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:42.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:43.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:43.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.1943359375, 631.7737426757812, 540.5486450195312, 587.1815185546875, 568.7670288085938]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:43.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.3872543141812 is lower than -592.3836784266218, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:43.992\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 590.264893  [    1/ 1184]\n",
      "train loss: 661.659119  [  101/ 1184]\n",
      "train loss: 619.798828  [  201/ 1184]\n",
      "train loss: 546.921509  [  301/ 1184]\n",
      "train loss: 643.152039  [  401/ 1184]\n",
      "train loss: 676.972168  [  501/ 1184]\n",
      "train loss: 611.349976  [  601/ 1184]\n",
      "train loss: 550.609558  [  701/ 1184]\n",
      "train loss: 605.352783  [  801/ 1184]\n",
      "train loss: 634.526001  [  901/ 1184]\n",
      "train loss: 615.135864  [ 1001/ 1184]\n",
      "train loss: 600.376770  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:08:54.302\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:54.303\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:55.845\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:55.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.1693115234375, 631.743408203125, 540.45703125, 587.13623046875, 568.7425537109375]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:55.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.3326081481162 is higher than -592.3836784266218, setting new best score to -592.3326081481162\u001b[0m\n",
      "\u001b[32m2023-11-26 21:08:55.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.383678 --> 592.332608).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 668.646484  [    1/ 1184]\n",
      "train loss: 539.027649  [  101/ 1184]\n",
      "train loss: 625.884766  [  201/ 1184]\n",
      "train loss: 576.404846  [  301/ 1184]\n",
      "train loss: 562.404846  [  401/ 1184]\n",
      "train loss: 577.688782  [  501/ 1184]\n",
      "train loss: 556.353882  [  601/ 1184]\n",
      "train loss: 589.696167  [  701/ 1184]\n",
      "train loss: 604.252380  [  801/ 1184]\n",
      "train loss: 599.769653  [  901/ 1184]\n",
      "train loss: 572.576050  [ 1001/ 1184]\n",
      "train loss: 588.547485  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:09:06.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:06.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:07.788\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:07.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.1305541992188, 631.780517578125, 540.5128173828125, 587.112060546875, 568.8134765625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:07.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.3406671837915 is lower than -592.3326081481162, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:07.791\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 607.431702  [    1/ 1184]\n",
      "train loss: 568.419006  [  101/ 1184]\n",
      "train loss: 598.482727  [  201/ 1184]\n",
      "train loss: 583.009094  [  301/ 1184]\n",
      "train loss: 642.598389  [  401/ 1184]\n",
      "train loss: 586.122131  [  501/ 1184]\n",
      "train loss: 647.017090  [  601/ 1184]\n",
      "train loss: 580.473999  [  701/ 1184]\n",
      "train loss: 604.228577  [  801/ 1184]\n",
      "train loss: 628.052185  [  901/ 1184]\n",
      "train loss: 541.424438  [ 1001/ 1184]\n",
      "train loss: 637.704529  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:09:18.154\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:18.155\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:19.682\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:19.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.2346801757812, 631.7521362304688, 540.5078125, 587.179443359375, 568.8012084960938]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:19.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.3438846636423 is lower than -592.3326081481162, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:19.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 558.693481  [    1/ 1184]\n",
      "train loss: 607.019897  [  101/ 1184]\n",
      "train loss: 616.077209  [  201/ 1184]\n",
      "train loss: 570.584351  [  301/ 1184]\n",
      "train loss: 631.073364  [  401/ 1184]\n",
      "train loss: 569.194214  [  501/ 1184]\n",
      "train loss: 562.974976  [  601/ 1184]\n",
      "train loss: 590.426392  [  701/ 1184]\n",
      "train loss: 635.219360  [  801/ 1184]\n",
      "train loss: 578.173950  [  901/ 1184]\n",
      "train loss: 548.853088  [ 1001/ 1184]\n",
      "train loss: 529.623779  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:09:30.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:30.150\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:31.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:31.740\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.1056518554688, 631.7637939453125, 540.4656372070312, 587.1541748046875, 568.80615234375]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:31.741\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.3257350487045 is higher than -592.3326081481162, setting new best score to -592.3257350487045\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:31.742\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.332608 --> 592.325735).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 608.802917  [    1/ 1184]\n",
      "train loss: 557.319214  [  101/ 1184]\n",
      "train loss: 584.805481  [  201/ 1184]\n",
      "train loss: 559.882202  [  301/ 1184]\n",
      "train loss: 599.458313  [  401/ 1184]\n",
      "train loss: 588.329590  [  501/ 1184]\n",
      "train loss: 536.419434  [  601/ 1184]\n",
      "train loss: 557.580872  [  701/ 1184]\n",
      "train loss: 564.937805  [  801/ 1184]\n",
      "train loss: 611.933411  [  901/ 1184]\n",
      "train loss: 585.285400  [ 1001/ 1184]\n",
      "train loss: 547.861877  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:09:42.232\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:42.233\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:43.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:43.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.101806640625, 631.7530517578125, 540.4431762695312, 587.1050415039062, 568.776611328125]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:43.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.2990929712223 is higher than -592.3257350487045, setting new best score to -592.2990929712223\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:43.770\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.325735 --> 592.299093).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 518.435364  [    1/ 1184]\n",
      "train loss: 599.847473  [  101/ 1184]\n",
      "train loss: 593.453735  [  201/ 1184]\n",
      "train loss: 597.537537  [  301/ 1184]\n",
      "train loss: 611.861206  [  401/ 1184]\n",
      "train loss: 583.900208  [  501/ 1184]\n",
      "train loss: 605.317749  [  601/ 1184]\n",
      "train loss: 621.722046  [  701/ 1184]\n",
      "train loss: 579.771973  [  801/ 1184]\n",
      "train loss: 523.495667  [  901/ 1184]\n",
      "train loss: 654.945496  [ 1001/ 1184]\n",
      "train loss: 645.570129  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:09:54.167\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:54.168\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:55.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:55.698\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.1325073242188, 631.6563110351562, 540.4346923828125, 587.1455078125, 568.76171875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:55.699\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.3044581159761 is lower than -592.2990929712223, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:09:55.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 580.972900  [    1/ 1184]\n",
      "train loss: 589.788574  [  101/ 1184]\n",
      "train loss: 607.061890  [  201/ 1184]\n",
      "train loss: 578.168518  [  301/ 1184]\n",
      "train loss: 615.052551  [  401/ 1184]\n",
      "train loss: 558.983093  [  501/ 1184]\n",
      "train loss: 599.463257  [  601/ 1184]\n",
      "train loss: 501.600250  [  701/ 1184]\n",
      "train loss: 576.276489  [  801/ 1184]\n",
      "train loss: 583.184692  [  901/ 1184]\n",
      "train loss: 605.109863  [ 1001/ 1184]\n",
      "train loss: 638.272705  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:10:06.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:06.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:07.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:07.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.074951171875, 631.7217407226562, 540.45556640625, 587.1475830078125, 568.7434692382812]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:07.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.2944074027146 is higher than -592.2990929712223, setting new best score to -592.2944074027146\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:07.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.299093 --> 592.294407).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 612.501099  [    1/ 1184]\n",
      "train loss: 643.278076  [  101/ 1184]\n",
      "train loss: 617.958801  [  201/ 1184]\n",
      "train loss: 620.129883  [  301/ 1184]\n",
      "train loss: 651.924133  [  401/ 1184]\n",
      "train loss: 571.514404  [  501/ 1184]\n",
      "train loss: 570.101807  [  601/ 1184]\n",
      "train loss: 608.781860  [  701/ 1184]\n",
      "train loss: 556.910034  [  801/ 1184]\n",
      "train loss: 611.656799  [  901/ 1184]\n",
      "train loss: 561.989136  [ 1001/ 1184]\n",
      "train loss: 622.488953  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:10:17.987\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:17.988\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:19.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:19.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.1151733398438, 631.684814453125, 540.43701171875, 587.1533203125, 568.7388916015625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:19.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.2884777986551 is higher than -592.2944074027146, setting new best score to -592.2884777986551\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:19.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.294407 --> 592.288478).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 602.575562  [    1/ 1184]\n",
      "train loss: 567.826355  [  101/ 1184]\n",
      "train loss: 616.033569  [  201/ 1184]\n",
      "train loss: 585.682373  [  301/ 1184]\n",
      "train loss: 572.745178  [  401/ 1184]\n",
      "train loss: 559.473206  [  501/ 1184]\n",
      "train loss: 625.515137  [  601/ 1184]\n",
      "train loss: 538.772339  [  701/ 1184]\n",
      "train loss: 633.794434  [  801/ 1184]\n",
      "train loss: 662.727539  [  901/ 1184]\n",
      "train loss: 651.948853  [ 1001/ 1184]\n",
      "train loss: 649.323669  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:10:29.990\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:29.991\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:31.541\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:31.542\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.1420288085938, 631.6500854492188, 540.4083251953125, 587.09716796875, 568.7354736328125]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:31.543\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.2697046980073 is higher than -592.2884777986551, setting new best score to -592.2697046980073\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:31.544\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.288478 --> 592.269705).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 610.070007  [    1/ 1184]\n",
      "train loss: 627.007690  [  101/ 1184]\n",
      "train loss: 625.014526  [  201/ 1184]\n",
      "train loss: 605.325867  [  301/ 1184]\n",
      "train loss: 598.226501  [  401/ 1184]\n",
      "train loss: 576.679810  [  501/ 1184]\n",
      "train loss: 598.581543  [  601/ 1184]\n",
      "train loss: 624.217468  [  701/ 1184]\n",
      "train loss: 592.386353  [  801/ 1184]\n",
      "train loss: 571.127563  [  901/ 1184]\n",
      "train loss: 580.134644  [ 1001/ 1184]\n",
      "train loss: 653.759766  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:10:42.088\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:42.089\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:43.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:43.624\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.0755615234375, 631.6915283203125, 540.4063110351562, 587.1256103515625, 568.7994384765625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:43.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.2855664217019 is lower than -592.2697046980073, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:43.625\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 521.281677  [    1/ 1184]\n",
      "train loss: 534.898071  [  101/ 1184]\n",
      "train loss: 663.907776  [  201/ 1184]\n",
      "train loss: 526.143433  [  301/ 1184]\n",
      "train loss: 596.208923  [  401/ 1184]\n",
      "train loss: 573.918335  [  501/ 1184]\n",
      "train loss: 642.188599  [  601/ 1184]\n",
      "train loss: 657.868164  [  701/ 1184]\n",
      "train loss: 574.135925  [  801/ 1184]\n",
      "train loss: 675.484680  [  901/ 1184]\n",
      "train loss: 577.811584  [ 1001/ 1184]\n",
      "train loss: 610.760010  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:10:53.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:53.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:55.521\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:55.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.1069946289062, 631.5610961914062, 540.3775634765625, 587.12109375, 568.7529296875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:55.522\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.2545677474783 is higher than -592.2697046980073, setting new best score to -592.2545677474783\u001b[0m\n",
      "\u001b[32m2023-11-26 21:10:55.523\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.269705 --> 592.254568).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 526.786011  [    1/ 1184]\n",
      "train loss: 551.357422  [  101/ 1184]\n",
      "train loss: 616.491333  [  201/ 1184]\n",
      "train loss: 624.593018  [  301/ 1184]\n",
      "train loss: 606.916260  [  401/ 1184]\n",
      "train loss: 643.677124  [  501/ 1184]\n",
      "train loss: 626.237366  [  601/ 1184]\n",
      "train loss: 583.661499  [  701/ 1184]\n",
      "train loss: 572.537292  [  801/ 1184]\n",
      "train loss: 606.613220  [  901/ 1184]\n",
      "train loss: 578.196167  [ 1001/ 1184]\n",
      "train loss: 571.521423  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:11:05.887\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:05.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:07.430\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:07.431\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.0863037109375, 631.6157836914062, 540.3778686523438, 587.0571899414062, 568.7171020507812]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:07.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.2265024692198 is higher than -592.2545677474783, setting new best score to -592.2265024692198\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:07.432\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.254568 --> 592.226502).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 584.352783  [    1/ 1184]\n",
      "train loss: 655.758545  [  101/ 1184]\n",
      "train loss: 568.626953  [  201/ 1184]\n",
      "train loss: 688.115173  [  301/ 1184]\n",
      "train loss: 550.046265  [  401/ 1184]\n",
      "train loss: 587.347473  [  501/ 1184]\n",
      "train loss: 599.670044  [  601/ 1184]\n",
      "train loss: 582.506897  [  701/ 1184]\n",
      "train loss: 563.321228  [  801/ 1184]\n",
      "train loss: 603.265076  [  901/ 1184]\n",
      "train loss: 645.222534  [ 1001/ 1184]\n",
      "train loss: 620.959473  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:11:17.789\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:17.790\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:19.378\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:19.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.0864868164062, 631.6366577148438, 540.3135986328125, 587.0570068359375, 568.6952514648438]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:19.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.228950056245 is lower than -592.2265024692198, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:19.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 573.809814  [    1/ 1184]\n",
      "train loss: 582.919434  [  101/ 1184]\n",
      "train loss: 553.160156  [  201/ 1184]\n",
      "train loss: 611.940002  [  301/ 1184]\n",
      "train loss: 619.293701  [  401/ 1184]\n",
      "train loss: 595.000610  [  501/ 1184]\n",
      "train loss: 543.461670  [  601/ 1184]\n",
      "train loss: 641.784912  [  701/ 1184]\n",
      "train loss: 521.065796  [  801/ 1184]\n",
      "train loss: 582.363220  [  901/ 1184]\n",
      "train loss: 578.759949  [ 1001/ 1184]\n",
      "train loss: 547.046631  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:11:29.694\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:29.695\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:31.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:31.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.0819091796875, 631.631591796875, 540.3453369140625, 587.0758666992188, 568.7714233398438]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:31.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.2358369078818 is lower than -592.2265024692198, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:31.335\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 517.244385  [    1/ 1184]\n",
      "train loss: 646.320435  [  101/ 1184]\n",
      "train loss: 650.581055  [  201/ 1184]\n",
      "train loss: 621.069519  [  301/ 1184]\n",
      "train loss: 620.407715  [  401/ 1184]\n",
      "train loss: 638.261597  [  501/ 1184]\n",
      "train loss: 586.552612  [  601/ 1184]\n",
      "train loss: 628.945007  [  701/ 1184]\n",
      "train loss: 610.440063  [  801/ 1184]\n",
      "train loss: 574.206055  [  901/ 1184]\n",
      "train loss: 592.885803  [ 1001/ 1184]\n",
      "train loss: 572.134521  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:11:41.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:41.690\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:43.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:43.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.1092529296875, 631.599609375, 540.3272094726562, 587.052490234375, 568.719482421875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:43.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.2223971209949 is higher than -592.2265024692198, setting new best score to -592.2223971209949\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:43.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.226502 --> 592.222397).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 631.057129  [    1/ 1184]\n",
      "train loss: 643.093689  [  101/ 1184]\n",
      "train loss: 628.639771  [  201/ 1184]\n",
      "train loss: 665.095520  [  301/ 1184]\n",
      "train loss: 562.311035  [  401/ 1184]\n",
      "train loss: 543.862183  [  501/ 1184]\n",
      "train loss: 580.215210  [  601/ 1184]\n",
      "train loss: 621.125000  [  701/ 1184]\n",
      "train loss: 586.382080  [  801/ 1184]\n",
      "train loss: 557.165466  [  901/ 1184]\n",
      "train loss: 666.860352  [ 1001/ 1184]\n",
      "train loss: 622.532715  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:11:53.497\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:53.498\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:55.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:55.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.052978515625, 631.534423828125, 540.279541015625, 587.0046997070312, 568.7090454101562]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:55.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.1859060553056 is higher than -592.2223971209949, setting new best score to -592.1859060553056\u001b[0m\n",
      "\u001b[32m2023-11-26 21:11:55.231\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.222397 --> 592.185906).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 553.258545  [    1/ 1184]\n",
      "train loss: 568.487122  [  101/ 1184]\n",
      "train loss: 616.970886  [  201/ 1184]\n",
      "train loss: 637.265198  [  301/ 1184]\n",
      "train loss: 587.231506  [  401/ 1184]\n",
      "train loss: 580.832397  [  501/ 1184]\n",
      "train loss: 656.312988  [  601/ 1184]\n",
      "train loss: 529.772522  [  701/ 1184]\n",
      "train loss: 586.320557  [  801/ 1184]\n",
      "train loss: 542.041199  [  901/ 1184]\n",
      "train loss: 660.713684  [ 1001/ 1184]\n",
      "train loss: 593.343140  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:12:05.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:05.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:07.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:07.147\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.0765380859375, 631.5558471679688, 540.3253173828125, 587.0457763671875, 568.709228515625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:07.148\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.1982751773883 is lower than -592.1859060553056, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:07.149\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 583.196411  [    1/ 1184]\n",
      "train loss: 690.111511  [  101/ 1184]\n",
      "train loss: 562.636902  [  201/ 1184]\n",
      "train loss: 593.026489  [  301/ 1184]\n",
      "train loss: 639.353821  [  401/ 1184]\n",
      "train loss: 610.038147  [  501/ 1184]\n",
      "train loss: 603.494690  [  601/ 1184]\n",
      "train loss: 627.714722  [  701/ 1184]\n",
      "train loss: 606.244812  [  801/ 1184]\n",
      "train loss: 612.682861  [  901/ 1184]\n",
      "train loss: 641.799927  [ 1001/ 1184]\n",
      "train loss: 554.200012  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:12:17.443\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:17.444\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:19.069\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:19.070\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.1016845703125, 631.5394897460938, 540.3128662109375, 587.011474609375, 568.6431884765625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:19.071\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.1816244777245 is higher than -592.1859060553056, setting new best score to -592.1816244777245\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:19.072\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.185906 --> 592.181624).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 579.670654  [    1/ 1184]\n",
      "train loss: 640.036255  [  101/ 1184]\n",
      "train loss: 592.958862  [  201/ 1184]\n",
      "train loss: 531.125916  [  301/ 1184]\n",
      "train loss: 610.033997  [  401/ 1184]\n",
      "train loss: 598.387268  [  501/ 1184]\n",
      "train loss: 544.186707  [  601/ 1184]\n",
      "train loss: 598.787903  [  701/ 1184]\n",
      "train loss: 566.047180  [  801/ 1184]\n",
      "train loss: 609.328552  [  901/ 1184]\n",
      "train loss: 669.040649  [ 1001/ 1184]\n",
      "train loss: 571.709900  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:12:29.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:29.520\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:31.143\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:31.144\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.9989624023438, 631.472412109375, 540.2800903320312, 587.0036010742188, 568.6885986328125]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:31.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.1841914309731 is lower than -592.1816244777245, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:31.146\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 567.042297  [    1/ 1184]\n",
      "train loss: 584.545471  [  101/ 1184]\n",
      "train loss: 646.487793  [  201/ 1184]\n",
      "train loss: 556.134705  [  301/ 1184]\n",
      "train loss: 588.833130  [  401/ 1184]\n",
      "train loss: 651.825134  [  501/ 1184]\n",
      "train loss: 589.279663  [  601/ 1184]\n",
      "train loss: 641.327271  [  701/ 1184]\n",
      "train loss: 605.842896  [  801/ 1184]\n",
      "train loss: 541.792236  [  901/ 1184]\n",
      "train loss: 588.155640  [ 1001/ 1184]\n",
      "train loss: 614.064453  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:12:41.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:41.587\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:43.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:43.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.9957885742188, 631.462158203125, 540.2506103515625, 586.93310546875, 568.6531982421875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:43.238\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.1548057845877 is higher than -592.1816244777245, setting new best score to -592.1548057845877\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:43.239\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.181624 --> 592.154806).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 559.045471  [    1/ 1184]\n",
      "train loss: 549.294189  [  101/ 1184]\n",
      "train loss: 608.002686  [  201/ 1184]\n",
      "train loss: 591.981567  [  301/ 1184]\n",
      "train loss: 593.686523  [  401/ 1184]\n",
      "train loss: 539.457581  [  501/ 1184]\n",
      "train loss: 574.412903  [  601/ 1184]\n",
      "train loss: 599.527466  [  701/ 1184]\n",
      "train loss: 612.663879  [  801/ 1184]\n",
      "train loss: 619.573669  [  901/ 1184]\n",
      "train loss: 654.936340  [ 1001/ 1184]\n",
      "train loss: 587.976440  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:12:53.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:53.583\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:55.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:55.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [608.0739135742188, 631.5551147460938, 540.2722778320312, 586.9793701171875, 568.67724609375]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:55.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.1821057283425 is lower than -592.1548057845877, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:12:55.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 668.838623  [    1/ 1184]\n",
      "train loss: 611.721191  [  101/ 1184]\n",
      "train loss: 635.136108  [  201/ 1184]\n",
      "train loss: 590.445679  [  301/ 1184]\n",
      "train loss: 646.057556  [  401/ 1184]\n",
      "train loss: 648.026489  [  501/ 1184]\n",
      "train loss: 673.779297  [  601/ 1184]\n",
      "train loss: 586.734192  [  701/ 1184]\n",
      "train loss: 586.692017  [  801/ 1184]\n",
      "train loss: 634.415527  [  901/ 1184]\n",
      "train loss: 630.156799  [ 1001/ 1184]\n",
      "train loss: 619.070618  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:13:05.549\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:05.550\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:07.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:07.193\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.9596557617188, 631.4810180664062, 540.234619140625, 586.9495849609375, 568.6934814453125]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:07.194\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.1587124981457 is lower than -592.1548057845877, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:07.195\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 555.433533  [    1/ 1184]\n",
      "train loss: 592.120483  [  101/ 1184]\n",
      "train loss: 642.128296  [  201/ 1184]\n",
      "train loss: 545.609497  [  301/ 1184]\n",
      "train loss: 606.152344  [  401/ 1184]\n",
      "train loss: 612.157593  [  501/ 1184]\n",
      "train loss: 627.152710  [  601/ 1184]\n",
      "train loss: 578.251282  [  701/ 1184]\n",
      "train loss: 604.898865  [  801/ 1184]\n",
      "train loss: 569.227417  [  901/ 1184]\n",
      "train loss: 603.431152  [ 1001/ 1184]\n",
      "train loss: 571.399353  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:13:17.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:17.503\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:19.100\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:19.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.903076171875, 631.4542846679688, 540.2214965820312, 586.9580688476562, 568.727783203125]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:19.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.1314775297914 is higher than -592.1548057845877, setting new best score to -592.1314775297914\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:19.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.154806 --> 592.131478).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 611.065918  [    1/ 1184]\n",
      "train loss: 570.369019  [  101/ 1184]\n",
      "train loss: 592.284607  [  201/ 1184]\n",
      "train loss: 543.456543  [  301/ 1184]\n",
      "train loss: 587.063477  [  401/ 1184]\n",
      "train loss: 591.360779  [  501/ 1184]\n",
      "train loss: 557.907532  [  601/ 1184]\n",
      "train loss: 571.862061  [  701/ 1184]\n",
      "train loss: 613.370361  [  801/ 1184]\n",
      "train loss: 618.587097  [  901/ 1184]\n",
      "train loss: 627.614990  [ 1001/ 1184]\n",
      "train loss: 609.228638  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:13:29.449\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:29.450\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:31.058\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:31.060\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.886962890625, 631.474609375, 540.1712036132812, 586.92919921875, 568.6793823242188]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:31.061\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.1135270903383 is higher than -592.1314775297914, setting new best score to -592.1135270903383\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:31.062\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.131478 --> 592.113527).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 638.072388  [    1/ 1184]\n",
      "train loss: 595.449524  [  101/ 1184]\n",
      "train loss: 551.393494  [  201/ 1184]\n",
      "train loss: 654.767029  [  301/ 1184]\n",
      "train loss: 616.281799  [  401/ 1184]\n",
      "train loss: 571.511536  [  501/ 1184]\n",
      "train loss: 560.113220  [  601/ 1184]\n",
      "train loss: 614.571960  [  701/ 1184]\n",
      "train loss: 595.206360  [  801/ 1184]\n",
      "train loss: 608.048889  [  901/ 1184]\n",
      "train loss: 564.180664  [ 1001/ 1184]\n",
      "train loss: 541.588745  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:13:41.615\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:41.616\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:43.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:43.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.9472045898438, 631.4757080078125, 540.207763671875, 586.9594116210938, 568.6388549804688]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:43.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.118395455276 is lower than -592.1135270903383, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:43.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 534.467957  [    1/ 1184]\n",
      "train loss: 584.205933  [  101/ 1184]\n",
      "train loss: 653.249390  [  201/ 1184]\n",
      "train loss: 663.041565  [  301/ 1184]\n",
      "train loss: 586.846130  [  401/ 1184]\n",
      "train loss: 622.702332  [  501/ 1184]\n",
      "train loss: 589.847534  [  601/ 1184]\n",
      "train loss: 577.958618  [  701/ 1184]\n",
      "train loss: 568.738281  [  801/ 1184]\n",
      "train loss: 571.670715  [  901/ 1184]\n",
      "train loss: 583.444397  [ 1001/ 1184]\n",
      "train loss: 664.503357  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:13:53.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:53.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:55.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:55.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.9769897460938, 631.4822998046875, 540.175048828125, 586.8716430664062, 568.6307373046875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:55.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.1071036423309 is higher than -592.1135270903383, setting new best score to -592.1071036423309\u001b[0m\n",
      "\u001b[32m2023-11-26 21:13:55.181\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.113527 --> 592.107104).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 524.395691  [    1/ 1184]\n",
      "train loss: 610.808716  [  101/ 1184]\n",
      "train loss: 547.222595  [  201/ 1184]\n",
      "train loss: 607.834045  [  301/ 1184]\n",
      "train loss: 578.718262  [  401/ 1184]\n",
      "train loss: 644.412598  [  501/ 1184]\n",
      "train loss: 631.881104  [  601/ 1184]\n",
      "train loss: 619.563721  [  701/ 1184]\n",
      "train loss: 575.985718  [  801/ 1184]\n",
      "train loss: 549.185608  [  901/ 1184]\n",
      "train loss: 613.341125  [ 1001/ 1184]\n",
      "train loss: 569.867920  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:14:05.560\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:05.561\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:07.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:07.281\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.9205932617188, 631.458984375, 540.1610107421875, 586.95458984375, 568.6444091796875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:07.282\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.1180259994313 is lower than -592.1071036423309, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:07.283\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 619.119080  [    1/ 1184]\n",
      "train loss: 558.280273  [  101/ 1184]\n",
      "train loss: 560.166321  [  201/ 1184]\n",
      "train loss: 579.007263  [  301/ 1184]\n",
      "train loss: 594.829407  [  401/ 1184]\n",
      "train loss: 597.409973  [  501/ 1184]\n",
      "train loss: 561.870667  [  601/ 1184]\n",
      "train loss: 626.948914  [  701/ 1184]\n",
      "train loss: 628.497314  [  801/ 1184]\n",
      "train loss: 583.339905  [  901/ 1184]\n",
      "train loss: 594.188721  [ 1001/ 1184]\n",
      "train loss: 604.877502  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:14:17.579\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:17.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:19.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:19.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.8311767578125, 631.401611328125, 540.1040649414062, 586.81298828125, 568.6013793945312]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:19.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.0818009388597 is higher than -592.1071036423309, setting new best score to -592.0818009388597\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:19.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.107104 --> 592.081801).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 615.079102  [    1/ 1184]\n",
      "train loss: 578.446655  [  101/ 1184]\n",
      "train loss: 566.882935  [  201/ 1184]\n",
      "train loss: 588.366089  [  301/ 1184]\n",
      "train loss: 619.337341  [  401/ 1184]\n",
      "train loss: 652.768799  [  501/ 1184]\n",
      "train loss: 566.176392  [  601/ 1184]\n",
      "train loss: 578.785522  [  701/ 1184]\n",
      "train loss: 586.228394  [  801/ 1184]\n",
      "train loss: 589.930847  [  901/ 1184]\n",
      "train loss: 613.724548  [ 1001/ 1184]\n",
      "train loss: 584.417358  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:14:29.509\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:29.510\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:31.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:31.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.8726806640625, 631.4779663085938, 540.0906372070312, 586.8779907226562, 568.6550903320312]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:31.132\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.0904510884345 is lower than -592.0818009388597, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:31.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 595.070251  [    1/ 1184]\n",
      "train loss: 544.535095  [  101/ 1184]\n",
      "train loss: 575.710144  [  201/ 1184]\n",
      "train loss: 601.625671  [  301/ 1184]\n",
      "train loss: 552.110901  [  401/ 1184]\n",
      "train loss: 591.809753  [  501/ 1184]\n",
      "train loss: 553.300415  [  601/ 1184]\n",
      "train loss: 602.352600  [  701/ 1184]\n",
      "train loss: 572.154419  [  801/ 1184]\n",
      "train loss: 617.390564  [  901/ 1184]\n",
      "train loss: 586.036987  [ 1001/ 1184]\n",
      "train loss: 535.940491  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:14:41.463\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:41.464\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:43.105\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:43.106\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.8294677734375, 631.4418334960938, 540.0669555664062, 586.88623046875, 568.634765625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:43.107\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.0572676646559 is higher than -592.0818009388597, setting new best score to -592.0572676646559\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:43.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.081801 --> 592.057268).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 543.184021  [    1/ 1184]\n",
      "train loss: 605.040771  [  101/ 1184]\n",
      "train loss: 587.059937  [  201/ 1184]\n",
      "train loss: 618.582092  [  301/ 1184]\n",
      "train loss: 599.999634  [  401/ 1184]\n",
      "train loss: 595.064453  [  501/ 1184]\n",
      "train loss: 654.607788  [  601/ 1184]\n",
      "train loss: 566.186218  [  701/ 1184]\n",
      "train loss: 536.772461  [  801/ 1184]\n",
      "train loss: 615.570068  [  901/ 1184]\n",
      "train loss: 556.843750  [ 1001/ 1184]\n",
      "train loss: 595.254028  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:14:53.409\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:53.410\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:55.051\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:55.052\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.8598022460938, 631.4219360351562, 540.1431274414062, 586.9559326171875, 568.6221313476562]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:55.053\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.0801247898536 is lower than -592.0572676646559, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:14:55.054\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 576.812561  [    1/ 1184]\n",
      "train loss: 550.355774  [  101/ 1184]\n",
      "train loss: 591.217346  [  201/ 1184]\n",
      "train loss: 598.980225  [  301/ 1184]\n",
      "train loss: 565.118225  [  401/ 1184]\n",
      "train loss: 653.986511  [  501/ 1184]\n",
      "train loss: 647.882141  [  601/ 1184]\n",
      "train loss: 586.741577  [  701/ 1184]\n",
      "train loss: 619.557312  [  801/ 1184]\n",
      "train loss: 610.214294  [  901/ 1184]\n",
      "train loss: 567.312927  [ 1001/ 1184]\n",
      "train loss: 578.213318  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:15:05.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:05.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:07.024\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:07.025\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.84228515625, 631.4216918945312, 540.1285400390625, 586.8787231445312, 568.5848388671875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:07.026\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.0532589683049 is higher than -592.0572676646559, setting new best score to -592.0532589683049\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:07.027\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.057268 --> 592.053259).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 618.434082  [    1/ 1184]\n",
      "train loss: 621.011475  [  101/ 1184]\n",
      "train loss: 534.744446  [  201/ 1184]\n",
      "train loss: 611.323547  [  301/ 1184]\n",
      "train loss: 573.128296  [  401/ 1184]\n",
      "train loss: 498.355896  [  501/ 1184]\n",
      "train loss: 595.558228  [  601/ 1184]\n",
      "train loss: 563.484924  [  701/ 1184]\n",
      "train loss: 599.420044  [  801/ 1184]\n",
      "train loss: 587.320862  [  901/ 1184]\n",
      "train loss: 625.584717  [ 1001/ 1184]\n",
      "train loss: 580.788147  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:15:17.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:17.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:18.797\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:18.798\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.7986450195312, 631.3865356445312, 540.07666015625, 586.8560791015625, 568.5860595703125]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:18.799\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.048264206512 is higher than -592.0532589683049, setting new best score to -592.048264206512\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:18.800\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.053259 --> 592.048264).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 603.154358  [    1/ 1184]\n",
      "train loss: 610.155090  [  101/ 1184]\n",
      "train loss: 629.128174  [  201/ 1184]\n",
      "train loss: 591.129883  [  301/ 1184]\n",
      "train loss: 586.532104  [  401/ 1184]\n",
      "train loss: 620.984741  [  501/ 1184]\n",
      "train loss: 548.364685  [  601/ 1184]\n",
      "train loss: 589.193726  [  701/ 1184]\n",
      "train loss: 606.256226  [  801/ 1184]\n",
      "train loss: 580.870605  [  901/ 1184]\n",
      "train loss: 612.315063  [ 1001/ 1184]\n",
      "train loss: 606.718872  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:15:29.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:29.582\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:31.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:31.383\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.7745361328125, 631.33154296875, 540.0704956054688, 586.779541015625, 568.554443359375]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:31.384\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -592.0159084658079 is higher than -592.048264206512, setting new best score to -592.0159084658079\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:31.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.048264 --> 592.015908).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 574.426697  [    1/ 1184]\n",
      "train loss: 587.391663  [  101/ 1184]\n",
      "train loss: 597.981873  [  201/ 1184]\n",
      "train loss: 583.829224  [  301/ 1184]\n",
      "train loss: 646.236145  [  401/ 1184]\n",
      "train loss: 559.124268  [  501/ 1184]\n",
      "train loss: 612.201355  [  601/ 1184]\n",
      "train loss: 574.628906  [  701/ 1184]\n",
      "train loss: 621.210510  [  801/ 1184]\n",
      "train loss: 624.113831  [  901/ 1184]\n",
      "train loss: 572.140381  [ 1001/ 1184]\n",
      "train loss: 534.570190  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:15:41.817\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:41.818\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:43.348\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:43.349\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.8506469726562, 631.349853515625, 540.0562744140625, 586.8241577148438, 568.5396728515625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:43.350\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.0449961988231 is lower than -592.0159084658079, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:43.351\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 600.107788  [    1/ 1184]\n",
      "train loss: 560.593323  [  101/ 1184]\n",
      "train loss: 581.681152  [  201/ 1184]\n",
      "train loss: 680.985901  [  301/ 1184]\n",
      "train loss: 586.908447  [  401/ 1184]\n",
      "train loss: 628.020996  [  501/ 1184]\n",
      "train loss: 616.035156  [  601/ 1184]\n",
      "train loss: 623.262634  [  701/ 1184]\n",
      "train loss: 614.733032  [  801/ 1184]\n",
      "train loss: 596.602051  [  901/ 1184]\n",
      "train loss: 593.905151  [ 1001/ 1184]\n",
      "train loss: 634.608887  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:15:53.632\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:53.633\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:55.251\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:55.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.7835083007812, 631.3350830078125, 540.0103149414062, 586.7434692382812, 568.4521484375]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:55.252\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -591.982361303402 is higher than -592.0159084658079, setting new best score to -591.982361303402\u001b[0m\n",
      "\u001b[32m2023-11-26 21:15:55.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (592.015908 --> 591.982361).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 611.611572  [    1/ 1184]\n",
      "train loss: 655.991150  [  101/ 1184]\n",
      "train loss: 599.075134  [  201/ 1184]\n",
      "train loss: 622.133911  [  301/ 1184]\n",
      "train loss: 547.022217  [  401/ 1184]\n",
      "train loss: 581.938477  [  501/ 1184]\n",
      "train loss: 569.286438  [  601/ 1184]\n",
      "train loss: 552.793518  [  701/ 1184]\n",
      "train loss: 592.791565  [  801/ 1184]\n",
      "train loss: 570.768188  [  901/ 1184]\n",
      "train loss: 666.244507  [ 1001/ 1184]\n",
      "train loss: 564.070129  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:16:05.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:05.594\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:07.235\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:07.236\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.854248046875, 631.3095703125, 540.1099853515625, 586.854248046875, 568.4966430664062]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:07.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.0501017510137 is lower than -591.982361303402, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:07.237\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 606.032043  [    1/ 1184]\n",
      "train loss: 593.687805  [  101/ 1184]\n",
      "train loss: 649.769531  [  201/ 1184]\n",
      "train loss: 582.391968  [  301/ 1184]\n",
      "train loss: 600.125610  [  401/ 1184]\n",
      "train loss: 568.039978  [  501/ 1184]\n",
      "train loss: 609.494019  [  601/ 1184]\n",
      "train loss: 612.853943  [  701/ 1184]\n",
      "train loss: 604.629578  [  801/ 1184]\n",
      "train loss: 672.296814  [  901/ 1184]\n",
      "train loss: 679.836060  [ 1001/ 1184]\n",
      "train loss: 575.968262  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:16:17.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:17.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:19.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:19.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.8349609375, 631.3301391601562, 540.0383911132812, 586.736328125, 568.4923706054688]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:19.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.9936946820609 is lower than -591.982361303402, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:19.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 616.270081  [    1/ 1184]\n",
      "train loss: 599.514099  [  101/ 1184]\n",
      "train loss: 614.543640  [  201/ 1184]\n",
      "train loss: 545.300110  [  301/ 1184]\n",
      "train loss: 576.837280  [  401/ 1184]\n",
      "train loss: 601.664917  [  501/ 1184]\n",
      "train loss: 524.634399  [  601/ 1184]\n",
      "train loss: 497.879364  [  701/ 1184]\n",
      "train loss: 602.915161  [  801/ 1184]\n",
      "train loss: 597.635620  [  901/ 1184]\n",
      "train loss: 592.034302  [ 1001/ 1184]\n",
      "train loss: 582.833252  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:16:29.506\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:29.507\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:31.130\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:31.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.7666015625, 631.2708740234375, 540.0734252929688, 586.71875, 568.5238037109375]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:31.131\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.0054651187945 is lower than -591.982361303402, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:31.133\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 3 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 624.234985  [    1/ 1184]\n",
      "train loss: 607.809998  [  101/ 1184]\n",
      "train loss: 551.826965  [  201/ 1184]\n",
      "train loss: 559.515564  [  301/ 1184]\n",
      "train loss: 558.070801  [  401/ 1184]\n",
      "train loss: 651.706970  [  501/ 1184]\n",
      "train loss: 568.202698  [  601/ 1184]\n",
      "train loss: 635.501953  [  701/ 1184]\n",
      "train loss: 585.841064  [  801/ 1184]\n",
      "train loss: 590.954895  [  901/ 1184]\n",
      "train loss: 592.919373  [ 1001/ 1184]\n",
      "train loss: 576.744995  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:16:41.485\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:41.486\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:43.113\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:43.114\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.8670043945312, 631.3111572265625, 540.0592651367188, 586.697021484375, 568.5364990234375]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:43.115\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -592.0037204404421 is lower than -591.982361303402, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:43.116\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 4 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 669.081055  [    1/ 1184]\n",
      "train loss: 571.069824  [  101/ 1184]\n",
      "train loss: 557.444214  [  201/ 1184]\n",
      "train loss: 588.700317  [  301/ 1184]\n",
      "train loss: 596.381104  [  401/ 1184]\n",
      "train loss: 564.186707  [  501/ 1184]\n",
      "train loss: 604.069885  [  601/ 1184]\n",
      "train loss: 547.500671  [  701/ 1184]\n",
      "train loss: 579.764954  [  801/ 1184]\n",
      "train loss: 595.275085  [  901/ 1184]\n",
      "train loss: 621.237427  [ 1001/ 1184]\n",
      "train loss: 566.423950  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:16:53.387\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:53.388\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:54.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:54.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.7459716796875, 631.2849731445312, 540.042724609375, 586.62939453125, 568.52734375]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:54.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -591.971248732941 is higher than -591.982361303402, setting new best score to -591.971248732941\u001b[0m\n",
      "\u001b[32m2023-11-26 21:16:54.923\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (591.982361 --> 591.971249).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 608.626465  [    1/ 1184]\n",
      "train loss: 650.613708  [  101/ 1184]\n",
      "train loss: 573.344604  [  201/ 1184]\n",
      "train loss: 655.686584  [  301/ 1184]\n",
      "train loss: 551.328430  [  401/ 1184]\n",
      "train loss: 597.829102  [  501/ 1184]\n",
      "train loss: 639.934509  [  601/ 1184]\n",
      "train loss: 661.973267  [  701/ 1184]\n",
      "train loss: 603.275024  [  801/ 1184]\n",
      "train loss: 599.104370  [  901/ 1184]\n",
      "train loss: 610.237793  [ 1001/ 1184]\n",
      "train loss: 606.235474  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:17:05.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:05.623\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:07.297\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:07.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.8085327148438, 631.2872314453125, 539.9818115234375, 586.6904296875, 568.5576171875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:07.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -591.9701959923852 is higher than -591.971248732941, setting new best score to -591.9701959923852\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:07.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (591.971249 --> 591.970196).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 615.392944  [    1/ 1184]\n",
      "train loss: 546.764343  [  101/ 1184]\n",
      "train loss: 540.718384  [  201/ 1184]\n",
      "train loss: 624.517822  [  301/ 1184]\n",
      "train loss: 597.696655  [  401/ 1184]\n",
      "train loss: 533.289795  [  501/ 1184]\n",
      "train loss: 567.294189  [  601/ 1184]\n",
      "train loss: 606.385315  [  701/ 1184]\n",
      "train loss: 652.077942  [  801/ 1184]\n",
      "train loss: 600.718750  [  901/ 1184]\n",
      "train loss: 524.331482  [ 1001/ 1184]\n",
      "train loss: 591.427734  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:17:17.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:17.779\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:19.308\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:19.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.8167724609375, 631.3316650390625, 540.0424194335938, 586.6558837890625, 568.4780883789062]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:19.310\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.9704158734671 is lower than -591.9701959923852, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:19.311\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 594.353027  [    1/ 1184]\n",
      "train loss: 605.547180  [  101/ 1184]\n",
      "train loss: 608.834595  [  201/ 1184]\n",
      "train loss: 587.023682  [  301/ 1184]\n",
      "train loss: 626.418335  [  401/ 1184]\n",
      "train loss: 579.576050  [  501/ 1184]\n",
      "train loss: 583.528137  [  601/ 1184]\n",
      "train loss: 618.558228  [  701/ 1184]\n",
      "train loss: 564.229919  [  801/ 1184]\n",
      "train loss: 626.288330  [  901/ 1184]\n",
      "train loss: 660.270020  [ 1001/ 1184]\n",
      "train loss: 573.986450  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:17:29.644\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:29.645\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:31.339\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:31.340\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.7527465820312, 631.3179321289062, 540.020263671875, 586.609375, 568.522216796875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:31.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.9780152139784 is lower than -591.9701959923852, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:31.342\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 532.524231  [    1/ 1184]\n",
      "train loss: 598.762390  [  101/ 1184]\n",
      "train loss: 591.760315  [  201/ 1184]\n",
      "train loss: 628.615173  [  301/ 1184]\n",
      "train loss: 601.406677  [  401/ 1184]\n",
      "train loss: 572.457336  [  501/ 1184]\n",
      "train loss: 646.157715  [  601/ 1184]\n",
      "train loss: 550.739624  [  701/ 1184]\n",
      "train loss: 589.054871  [  801/ 1184]\n",
      "train loss: 562.512451  [  901/ 1184]\n",
      "train loss: 615.903564  [ 1001/ 1184]\n",
      "train loss: 615.923706  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:17:41.720\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:41.721\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:43.257\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:43.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.81298828125, 631.2882080078125, 540.0037841796875, 586.6049194335938, 568.48095703125]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:43.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -591.9536178395718 is higher than -591.9701959923852, setting new best score to -591.9536178395718\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:43.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (591.970196 --> 591.953618).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 563.297302  [    1/ 1184]\n",
      "train loss: 612.734253  [  101/ 1184]\n",
      "train loss: 604.557373  [  201/ 1184]\n",
      "train loss: 648.290161  [  301/ 1184]\n",
      "train loss: 551.574341  [  401/ 1184]\n",
      "train loss: 625.661560  [  501/ 1184]\n",
      "train loss: 537.795105  [  601/ 1184]\n",
      "train loss: 555.895386  [  701/ 1184]\n",
      "train loss: 548.592102  [  801/ 1184]\n",
      "train loss: 515.177490  [  901/ 1184]\n",
      "train loss: 667.751465  [ 1001/ 1184]\n",
      "train loss: 524.546997  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:17:53.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:53.603\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:55.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:55.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.8353881835938, 631.3240966796875, 540.0094604492188, 586.6918334960938, 568.5194091796875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:55.307\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.9613939502572 is lower than -591.9536178395718, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:17:55.309\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 647.197754  [    1/ 1184]\n",
      "train loss: 558.681580  [  101/ 1184]\n",
      "train loss: 639.438477  [  201/ 1184]\n",
      "train loss: 635.033936  [  301/ 1184]\n",
      "train loss: 681.420532  [  401/ 1184]\n",
      "train loss: 656.074463  [  501/ 1184]\n",
      "train loss: 573.708618  [  601/ 1184]\n",
      "train loss: 581.356262  [  701/ 1184]\n",
      "train loss: 595.136841  [  801/ 1184]\n",
      "train loss: 545.697449  [  901/ 1184]\n",
      "train loss: 590.269409  [ 1001/ 1184]\n",
      "train loss: 600.223022  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:18:05.688\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:05.689\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:07.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:07.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.82080078125, 631.2451782226562, 540.01708984375, 586.6656494140625, 568.512451171875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:07.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -591.9394427722013 is higher than -591.9536178395718, setting new best score to -591.9394427722013\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:07.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (591.953618 --> 591.939443).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 561.787964  [    1/ 1184]\n",
      "train loss: 632.566101  [  101/ 1184]\n",
      "train loss: 558.746704  [  201/ 1184]\n",
      "train loss: 626.568176  [  301/ 1184]\n",
      "train loss: 648.821777  [  401/ 1184]\n",
      "train loss: 606.825378  [  501/ 1184]\n",
      "train loss: 620.507812  [  601/ 1184]\n",
      "train loss: 643.034241  [  701/ 1184]\n",
      "train loss: 586.934448  [  801/ 1184]\n",
      "train loss: 583.354858  [  901/ 1184]\n",
      "train loss: 580.921509  [ 1001/ 1184]\n",
      "train loss: 554.920654  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:18:17.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:17.572\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:19.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:19.263\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.7718505859375, 631.3236694335938, 540.0001220703125, 586.7130737304688, 568.5458374023438]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:19.264\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.9642660020273 is lower than -591.9394427722013, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:19.265\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 603.182190  [    1/ 1184]\n",
      "train loss: 606.691589  [  101/ 1184]\n",
      "train loss: 597.556824  [  201/ 1184]\n",
      "train loss: 564.047546  [  301/ 1184]\n",
      "train loss: 637.396729  [  401/ 1184]\n",
      "train loss: 632.730347  [  501/ 1184]\n",
      "train loss: 620.841980  [  601/ 1184]\n",
      "train loss: 627.143127  [  701/ 1184]\n",
      "train loss: 633.343750  [  801/ 1184]\n",
      "train loss: 552.966492  [  901/ 1184]\n",
      "train loss: 580.424377  [ 1001/ 1184]\n",
      "train loss: 585.741272  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:18:29.580\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:29.581\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:31.243\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:31.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.7418212890625, 631.260986328125, 540.009521484375, 586.6746215820312, 568.5093994140625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:31.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -591.9259295886076 is higher than -591.9394427722013, setting new best score to -591.9259295886076\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:31.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (591.939443 --> 591.925930).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 596.644958  [    1/ 1184]\n",
      "train loss: 645.101685  [  101/ 1184]\n",
      "train loss: 651.307190  [  201/ 1184]\n",
      "train loss: 579.709839  [  301/ 1184]\n",
      "train loss: 541.845215  [  401/ 1184]\n",
      "train loss: 623.433838  [  501/ 1184]\n",
      "train loss: 540.108582  [  601/ 1184]\n",
      "train loss: 571.571655  [  701/ 1184]\n",
      "train loss: 575.919495  [  801/ 1184]\n",
      "train loss: 589.557983  [  901/ 1184]\n",
      "train loss: 624.942078  [ 1001/ 1184]\n",
      "train loss: 665.706482  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:18:41.732\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:41.733\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:43.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:43.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.8048706054688, 631.2595825195312, 539.997314453125, 586.733642578125, 568.4793701171875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:43.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.941730508925 is lower than -591.9259295886076, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:43.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 616.560547  [    1/ 1184]\n",
      "train loss: 569.404419  [  101/ 1184]\n",
      "train loss: 614.040222  [  201/ 1184]\n",
      "train loss: 635.412659  [  301/ 1184]\n",
      "train loss: 636.254028  [  401/ 1184]\n",
      "train loss: 596.132812  [  501/ 1184]\n",
      "train loss: 566.428223  [  601/ 1184]\n",
      "train loss: 615.673279  [  701/ 1184]\n",
      "train loss: 577.986267  [  801/ 1184]\n",
      "train loss: 579.465515  [  901/ 1184]\n",
      "train loss: 557.869751  [ 1001/ 1184]\n",
      "train loss: 587.911926  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:18:53.558\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:53.559\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:55.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:55.366\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.8021240234375, 631.2139892578125, 540.021240234375, 586.651123046875, 568.4860229492188]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:55.367\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -591.9200091011917 is higher than -591.9259295886076, setting new best score to -591.9200091011917\u001b[0m\n",
      "\u001b[32m2023-11-26 21:18:55.368\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (591.925930 --> 591.920009).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 622.884827  [    1/ 1184]\n",
      "train loss: 580.533997  [  101/ 1184]\n",
      "train loss: 615.825317  [  201/ 1184]\n",
      "train loss: 566.019470  [  301/ 1184]\n",
      "train loss: 543.479126  [  401/ 1184]\n",
      "train loss: 654.182251  [  501/ 1184]\n",
      "train loss: 583.386230  [  601/ 1184]\n",
      "train loss: 629.783325  [  701/ 1184]\n",
      "train loss: 566.401428  [  801/ 1184]\n",
      "train loss: 600.373962  [  901/ 1184]\n",
      "train loss: 616.770264  [ 1001/ 1184]\n",
      "train loss: 604.608276  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:19:05.846\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:05.847\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:07.379\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:07.380\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.799560546875, 631.1799926757812, 539.9774169921875, 586.6531372070312, 568.4924926757812]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:07.381\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -591.9147099362144 is higher than -591.9200091011917, setting new best score to -591.9147099362144\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:07.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (591.920009 --> 591.914710).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 590.126770  [    1/ 1184]\n",
      "train loss: 618.846130  [  101/ 1184]\n",
      "train loss: 606.226929  [  201/ 1184]\n",
      "train loss: 633.959229  [  301/ 1184]\n",
      "train loss: 563.405151  [  401/ 1184]\n",
      "train loss: 632.948120  [  501/ 1184]\n",
      "train loss: 613.156128  [  601/ 1184]\n",
      "train loss: 577.403748  [  701/ 1184]\n",
      "train loss: 570.387939  [  801/ 1184]\n",
      "train loss: 600.599426  [  901/ 1184]\n",
      "train loss: 619.232544  [ 1001/ 1184]\n",
      "train loss: 630.390625  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:19:17.868\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:17.869\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:19.399\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:19.400\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.7721557617188, 631.203125, 539.9713745117188, 586.70654296875, 568.5035400390625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:19.401\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.9147484888005 is lower than -591.9147099362144, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:19.402\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 648.817749  [    1/ 1184]\n",
      "train loss: 604.334290  [  101/ 1184]\n",
      "train loss: 627.149780  [  201/ 1184]\n",
      "train loss: 642.574341  [  301/ 1184]\n",
      "train loss: 562.092896  [  401/ 1184]\n",
      "train loss: 586.474548  [  501/ 1184]\n",
      "train loss: 591.004578  [  601/ 1184]\n",
      "train loss: 643.964172  [  701/ 1184]\n",
      "train loss: 588.808594  [  801/ 1184]\n",
      "train loss: 532.011414  [  901/ 1184]\n",
      "train loss: 594.670288  [ 1001/ 1184]\n",
      "train loss: 561.077881  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:19:30.169\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:30.170\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:31.766\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:31.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.7349243164062, 631.224853515625, 540.01513671875, 586.6624145507812, 568.5217895507812]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:31.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.9297816023042 is lower than -591.9147099362144, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:31.769\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 618.709717  [    1/ 1184]\n",
      "train loss: 529.883118  [  101/ 1184]\n",
      "train loss: 610.626099  [  201/ 1184]\n",
      "train loss: 579.677917  [  301/ 1184]\n",
      "train loss: 640.116699  [  401/ 1184]\n",
      "train loss: 473.189636  [  501/ 1184]\n",
      "train loss: 579.293457  [  601/ 1184]\n",
      "train loss: 573.002136  [  701/ 1184]\n",
      "train loss: 579.528503  [  801/ 1184]\n",
      "train loss: 555.249329  [  901/ 1184]\n",
      "train loss: 515.235962  [ 1001/ 1184]\n",
      "train loss: 617.593506  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:19:42.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:42.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:43.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:43.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.75, 631.15380859375, 539.962890625, 586.6476440429688, 568.5186157226562]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:43.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -591.9007513504994 is higher than -591.9147099362144, setting new best score to -591.9007513504994\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:43.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (591.914710 --> 591.900751).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 612.316223  [    1/ 1184]\n",
      "train loss: 596.203430  [  101/ 1184]\n",
      "train loss: 557.127014  [  201/ 1184]\n",
      "train loss: 552.263733  [  301/ 1184]\n",
      "train loss: 590.906921  [  401/ 1184]\n",
      "train loss: 547.077881  [  501/ 1184]\n",
      "train loss: 537.820557  [  601/ 1184]\n",
      "train loss: 582.520630  [  701/ 1184]\n",
      "train loss: 595.803711  [  801/ 1184]\n",
      "train loss: 541.655457  [  901/ 1184]\n",
      "train loss: 564.208252  [ 1001/ 1184]\n",
      "train loss: 573.614380  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:19:54.305\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:54.306\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:55.836\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:55.837\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.742431640625, 631.209716796875, 539.9912109375, 586.6044311523438, 568.4833984375]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:55.838\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -591.8997710795342 is higher than -591.9007513504994, setting new best score to -591.8997710795342\u001b[0m\n",
      "\u001b[32m2023-11-26 21:19:55.839\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (591.900751 --> 591.899771).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 564.322205  [    1/ 1184]\n",
      "train loss: 581.280762  [  101/ 1184]\n",
      "train loss: 556.840637  [  201/ 1184]\n",
      "train loss: 633.945007  [  301/ 1184]\n",
      "train loss: 603.179321  [  401/ 1184]\n",
      "train loss: 610.863525  [  501/ 1184]\n",
      "train loss: 593.012451  [  601/ 1184]\n",
      "train loss: 529.029236  [  701/ 1184]\n",
      "train loss: 657.250977  [  801/ 1184]\n",
      "train loss: 583.110413  [  901/ 1184]\n",
      "train loss: 561.195740  [ 1001/ 1184]\n",
      "train loss: 570.193970  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:20:06.359\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:06.360\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:07.919\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:07.920\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.7390747070312, 631.2363891601562, 540.0010375976562, 586.6814575195312, 568.4861450195312]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:07.921\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.9019252342514 is lower than -591.8997710795342, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:07.922\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 589.818359  [    1/ 1184]\n",
      "train loss: 577.460266  [  101/ 1184]\n",
      "train loss: 547.087524  [  201/ 1184]\n",
      "train loss: 623.116516  [  301/ 1184]\n",
      "train loss: 604.678284  [  401/ 1184]\n",
      "train loss: 586.325439  [  501/ 1184]\n",
      "train loss: 618.018616  [  601/ 1184]\n",
      "train loss: 555.774780  [  701/ 1184]\n",
      "train loss: 610.072327  [  801/ 1184]\n",
      "train loss: 575.594482  [  901/ 1184]\n",
      "train loss: 621.677063  [ 1001/ 1184]\n",
      "train loss: 533.304138  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:20:18.333\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:18.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:19.888\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:19.889\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.8067016601562, 631.1799926757812, 539.9573974609375, 586.6465454101562, 568.4701538085938]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:19.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.9050653771509 is lower than -591.8997710795342, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:19.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 603.875610  [    1/ 1184]\n",
      "train loss: 577.955261  [  101/ 1184]\n",
      "train loss: 537.742126  [  201/ 1184]\n",
      "train loss: 619.621338  [  301/ 1184]\n",
      "train loss: 519.513367  [  401/ 1184]\n",
      "train loss: 554.001160  [  501/ 1184]\n",
      "train loss: 613.673035  [  601/ 1184]\n",
      "train loss: 642.119141  [  701/ 1184]\n",
      "train loss: 561.057617  [  801/ 1184]\n",
      "train loss: 670.088562  [  901/ 1184]\n",
      "train loss: 589.107300  [ 1001/ 1184]\n",
      "train loss: 606.963196  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:20:30.562\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:30.563\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:32.285\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:32.286\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.7311401367188, 631.1861572265625, 539.9403076171875, 586.6046142578125, 568.442138671875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:32.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -591.8658420224733 is higher than -591.8997710795342, setting new best score to -591.8658420224733\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:32.287\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (591.899771 --> 591.865842).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 574.061523  [    1/ 1184]\n",
      "train loss: 586.021667  [  101/ 1184]\n",
      "train loss: 635.483826  [  201/ 1184]\n",
      "train loss: 595.353149  [  301/ 1184]\n",
      "train loss: 595.708435  [  401/ 1184]\n",
      "train loss: 598.551086  [  501/ 1184]\n",
      "train loss: 630.148010  [  601/ 1184]\n",
      "train loss: 633.387085  [  701/ 1184]\n",
      "train loss: 595.678101  [  801/ 1184]\n",
      "train loss: 570.553589  [  901/ 1184]\n",
      "train loss: 567.514832  [ 1001/ 1184]\n",
      "train loss: 583.724060  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:20:42.782\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:42.783\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:44.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:44.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.7066650390625, 631.21484375, 539.9830322265625, 586.662353515625, 568.4049682617188]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:44.319\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.8931632126433 is lower than -591.8658420224733, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:44.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 650.144653  [    1/ 1184]\n",
      "train loss: 514.518921  [  101/ 1184]\n",
      "train loss: 610.011719  [  201/ 1184]\n",
      "train loss: 584.250549  [  301/ 1184]\n",
      "train loss: 590.160400  [  401/ 1184]\n",
      "train loss: 672.634827  [  501/ 1184]\n",
      "train loss: 643.122925  [  601/ 1184]\n",
      "train loss: 619.822205  [  701/ 1184]\n",
      "train loss: 615.503357  [  801/ 1184]\n",
      "train loss: 593.990601  [  901/ 1184]\n",
      "train loss: 657.036438  [ 1001/ 1184]\n",
      "train loss: 564.353760  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:20:54.696\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:54.697\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:56.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:56.290\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.7005004882812, 631.235595703125, 539.9273681640625, 586.6197509765625, 568.4324340820312]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:56.291\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.8669737996935 is lower than -591.8658420224733, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:20:56.293\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 650.410034  [    1/ 1184]\n",
      "train loss: 580.876587  [  101/ 1184]\n",
      "train loss: 578.264038  [  201/ 1184]\n",
      "train loss: 618.983582  [  301/ 1184]\n",
      "train loss: 521.885681  [  401/ 1184]\n",
      "train loss: 615.061401  [  501/ 1184]\n",
      "train loss: 596.250427  [  601/ 1184]\n",
      "train loss: 602.326599  [  701/ 1184]\n",
      "train loss: 604.317871  [  801/ 1184]\n",
      "train loss: 561.513550  [  901/ 1184]\n",
      "train loss: 632.812195  [ 1001/ 1184]\n",
      "train loss: 586.875061  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:21:06.642\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:06.643\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:08.172\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:08.173\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.65087890625, 631.1834716796875, 539.915283203125, 586.5689086914062, 568.4215087890625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:08.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -591.8480931535552 is higher than -591.8658420224733, setting new best score to -591.8480931535552\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:08.174\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (591.865842 --> 591.848093).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 598.641479  [    1/ 1184]\n",
      "train loss: 587.874207  [  101/ 1184]\n",
      "train loss: 572.347900  [  201/ 1184]\n",
      "train loss: 610.039978  [  301/ 1184]\n",
      "train loss: 619.305847  [  401/ 1184]\n",
      "train loss: 635.992859  [  501/ 1184]\n",
      "train loss: 601.510498  [  601/ 1184]\n",
      "train loss: 594.497009  [  701/ 1184]\n",
      "train loss: 598.217224  [  801/ 1184]\n",
      "train loss: 634.424805  [  901/ 1184]\n",
      "train loss: 653.629028  [ 1001/ 1184]\n",
      "train loss: 605.787781  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:21:18.529\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:18.530\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:20.226\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:20.227\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.7374267578125, 631.2371215820312, 539.9448852539062, 586.611083984375, 568.4741821289062]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:20.228\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.8658893054045 is lower than -591.8480931535552, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:20.229\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 578.401550  [    1/ 1184]\n",
      "train loss: 582.280701  [  101/ 1184]\n",
      "train loss: 615.591675  [  201/ 1184]\n",
      "train loss: 567.885681  [  301/ 1184]\n",
      "train loss: 523.813354  [  401/ 1184]\n",
      "train loss: 545.599915  [  501/ 1184]\n",
      "train loss: 560.008057  [  601/ 1184]\n",
      "train loss: 621.679810  [  701/ 1184]\n",
      "train loss: 588.766907  [  801/ 1184]\n",
      "train loss: 595.722412  [  901/ 1184]\n",
      "train loss: 608.473816  [ 1001/ 1184]\n",
      "train loss: 624.473938  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:21:30.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:30.576\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:32.216\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:32.217\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.7261962890625, 631.2564697265625, 539.956298828125, 586.6079711914062, 568.4688720703125]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:32.218\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.8904687036442 is lower than -591.8480931535552, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:32.219\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 626.416016  [    1/ 1184]\n",
      "train loss: 621.079590  [  101/ 1184]\n",
      "train loss: 542.015808  [  201/ 1184]\n",
      "train loss: 636.781006  [  301/ 1184]\n",
      "train loss: 625.069214  [  401/ 1184]\n",
      "train loss: 603.643921  [  501/ 1184]\n",
      "train loss: 566.756226  [  601/ 1184]\n",
      "train loss: 573.463196  [  701/ 1184]\n",
      "train loss: 556.489441  [  801/ 1184]\n",
      "train loss: 552.114075  [  901/ 1184]\n",
      "train loss: 672.831726  [ 1001/ 1184]\n",
      "train loss: 506.703552  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:21:42.728\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:42.729\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:44.258\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:44.259\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.7173461914062, 631.2089233398438, 539.8950805664062, 586.5971069335938, 568.4305419921875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:44.260\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.8484337142751 is lower than -591.8480931535552, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:44.261\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 3 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 623.163635  [    1/ 1184]\n",
      "train loss: 526.929321  [  101/ 1184]\n",
      "train loss: 621.362915  [  201/ 1184]\n",
      "train loss: 608.846008  [  301/ 1184]\n",
      "train loss: 559.665833  [  401/ 1184]\n",
      "train loss: 615.201782  [  501/ 1184]\n",
      "train loss: 562.844055  [  601/ 1184]\n",
      "train loss: 571.573059  [  701/ 1184]\n",
      "train loss: 581.315552  [  801/ 1184]\n",
      "train loss: 558.346558  [  901/ 1184]\n",
      "train loss: 561.132080  [ 1001/ 1184]\n",
      "train loss: 562.672485  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:21:54.653\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:54.654\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:56.244\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:56.245\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.6670532226562, 631.1990966796875, 539.9366455078125, 586.580810546875, 568.4334716796875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:56.246\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -591.8408505210393 is higher than -591.8480931535552, setting new best score to -591.8408505210393\u001b[0m\n",
      "\u001b[32m2023-11-26 21:21:56.247\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (591.848093 --> 591.840851).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 562.075439  [    1/ 1184]\n",
      "train loss: 555.955200  [  101/ 1184]\n",
      "train loss: 580.217346  [  201/ 1184]\n",
      "train loss: 620.744873  [  301/ 1184]\n",
      "train loss: 603.378174  [  401/ 1184]\n",
      "train loss: 616.611511  [  501/ 1184]\n",
      "train loss: 606.002686  [  601/ 1184]\n",
      "train loss: 587.425903  [  701/ 1184]\n",
      "train loss: 648.934448  [  801/ 1184]\n",
      "train loss: 566.656921  [  901/ 1184]\n",
      "train loss: 607.189331  [ 1001/ 1184]\n",
      "train loss: 654.698730  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:22:06.683\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:06.684\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:08.221\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:08.222\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.6458740234375, 631.1537475585938, 539.8919677734375, 586.5252075195312, 568.3804931640625]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:08.223\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.8421885816357 is lower than -591.8408505210393, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:08.224\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 566.735718  [    1/ 1184]\n",
      "train loss: 546.170776  [  101/ 1184]\n",
      "train loss: 640.865906  [  201/ 1184]\n",
      "train loss: 594.257935  [  301/ 1184]\n",
      "train loss: 575.835510  [  401/ 1184]\n",
      "train loss: 634.441650  [  501/ 1184]\n",
      "train loss: 657.607300  [  601/ 1184]\n",
      "train loss: 573.609985  [  701/ 1184]\n",
      "train loss: 582.950317  [  801/ 1184]\n",
      "train loss: 690.003357  [  901/ 1184]\n",
      "train loss: 550.001465  [ 1001/ 1184]\n",
      "train loss: 613.444946  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:22:18.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:18.621\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:20.315\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:20.316\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.61181640625, 631.2184448242188, 539.846435546875, 586.5958251953125, 568.3768310546875]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:20.317\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -591.8293952265872 is higher than -591.8408505210393, setting new best score to -591.8293952265872\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:20.318\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (591.840851 --> 591.829395).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 596.759521  [    1/ 1184]\n",
      "train loss: 628.554260  [  101/ 1184]\n",
      "train loss: 570.205933  [  201/ 1184]\n",
      "train loss: 580.223755  [  301/ 1184]\n",
      "train loss: 602.896545  [  401/ 1184]\n",
      "train loss: 562.037231  [  501/ 1184]\n",
      "train loss: 563.905457  [  601/ 1184]\n",
      "train loss: 634.811279  [  701/ 1184]\n",
      "train loss: 547.266846  [  801/ 1184]\n",
      "train loss: 616.301819  [  901/ 1184]\n",
      "train loss: 610.219360  [ 1001/ 1184]\n",
      "train loss: 623.726685  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:22:30.786\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:30.787\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:32.331\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:32.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.6574096679688, 631.191162109375, 539.8432006835938, 586.5947875976562, 568.35693359375]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:32.332\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -591.8251736797864 is higher than -591.8293952265872, setting new best score to -591.8251736797864\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:32.334\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (591.829395 --> 591.825174).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 566.451904  [    1/ 1184]\n",
      "train loss: 565.089111  [  101/ 1184]\n",
      "train loss: 577.331787  [  201/ 1184]\n",
      "train loss: 610.040649  [  301/ 1184]\n",
      "train loss: 600.859985  [  401/ 1184]\n",
      "train loss: 544.440918  [  501/ 1184]\n",
      "train loss: 598.655762  [  601/ 1184]\n",
      "train loss: 611.571228  [  701/ 1184]\n",
      "train loss: 562.340454  [  801/ 1184]\n",
      "train loss: 588.934814  [  901/ 1184]\n",
      "train loss: 649.289001  [ 1001/ 1184]\n",
      "train loss: 610.302124  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:22:42.775\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:42.776\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:44.363\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:44.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.573486328125, 631.2542724609375, 539.82275390625, 586.5300903320312, 568.3841552734375]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:44.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.8280242533623 is lower than -591.8251736797864, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:44.365\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 617.483093  [    1/ 1184]\n",
      "train loss: 591.984985  [  101/ 1184]\n",
      "train loss: 584.614197  [  201/ 1184]\n",
      "train loss: 580.820679  [  301/ 1184]\n",
      "train loss: 604.435059  [  401/ 1184]\n",
      "train loss: 579.881653  [  501/ 1184]\n",
      "train loss: 613.409058  [  601/ 1184]\n",
      "train loss: 594.450989  [  701/ 1184]\n",
      "train loss: 540.908569  [  801/ 1184]\n",
      "train loss: 640.488281  [  901/ 1184]\n",
      "train loss: 584.884766  [ 1001/ 1184]\n",
      "train loss: 641.697449  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:22:54.767\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:54.768\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:56.298\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:56.299\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.5659790039062, 631.1553344726562, 539.8992309570312, 586.542236328125, 568.3218383789062]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:56.300\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -591.8034766861155 is higher than -591.8251736797864, setting new best score to -591.8034766861155\u001b[0m\n",
      "\u001b[32m2023-11-26 21:22:56.301\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (591.825174 --> 591.803477).  Saving model ...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 641.466003  [    1/ 1184]\n",
      "train loss: 585.566101  [  101/ 1184]\n",
      "train loss: 548.684937  [  201/ 1184]\n",
      "train loss: 664.730713  [  301/ 1184]\n",
      "train loss: 544.281311  [  401/ 1184]\n",
      "train loss: 585.500488  [  501/ 1184]\n",
      "train loss: 568.708923  [  601/ 1184]\n",
      "train loss: 572.203491  [  701/ 1184]\n",
      "train loss: 598.754578  [  801/ 1184]\n",
      "train loss: 630.204468  [  901/ 1184]\n",
      "train loss: 571.799500  [ 1001/ 1184]\n",
      "train loss: 609.878784  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:23:06.738\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:23:06.739\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:23:08.277\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:23:08.278\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.5912475585938, 631.2034912109375, 539.8768920898438, 586.5242919921875, 568.3804321289062]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:23:08.279\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.835740178748 is lower than -591.8034766861155, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:23:08.280\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 1 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 573.447876  [    1/ 1184]\n",
      "train loss: 586.446960  [  101/ 1184]\n",
      "train loss: 626.090210  [  201/ 1184]\n",
      "train loss: 547.929382  [  301/ 1184]\n",
      "train loss: 605.107910  [  401/ 1184]\n",
      "train loss: 568.391724  [  501/ 1184]\n",
      "train loss: 586.916870  [  601/ 1184]\n",
      "train loss: 602.143982  [  701/ 1184]\n",
      "train loss: 623.383789  [  801/ 1184]\n",
      "train loss: 528.793701  [  901/ 1184]\n",
      "train loss: 601.283691  [ 1001/ 1184]\n",
      "train loss: 552.064026  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:23:18.730\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:23:18.731\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:23:20.266\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:23:20.267\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.56494140625, 631.1932373046875, 539.860107421875, 586.4642333984375, 568.3346557617188]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:23:20.268\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m157\u001b[0m - \u001b[1mcurrent score -591.8049815503857 is lower than -591.8034766861155, incrementing patience counter\u001b[0m\n",
      "\u001b[32m2023-11-26 21:23:20.269\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m159\u001b[0m - \u001b[1mEarlyStopping counter: 2 out of 5\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss: 626.283752  [    1/ 1184]\n",
      "train loss: 583.819336  [  101/ 1184]\n",
      "train loss: 579.230103  [  201/ 1184]\n",
      "train loss: 578.072021  [  301/ 1184]\n",
      "train loss: 624.515381  [  401/ 1184]\n",
      "train loss: 638.566223  [  501/ 1184]\n",
      "train loss: 598.621582  [  601/ 1184]\n",
      "train loss: 627.205933  [  701/ 1184]\n",
      "train loss: 607.109192  [  801/ 1184]\n",
      "train loss: 594.777466  [  901/ 1184]\n",
      "train loss: 574.675720  [ 1001/ 1184]\n",
      "train loss: 554.625122  [ 1101/ 1184]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-26 21:23:30.710\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m75\u001b[0m - \u001b[1mSaving a single batch of data\u001b[0m\n",
      "\u001b[32m2023-11-26 21:23:30.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m76\u001b[0m - \u001b[1mNumpy shape: (32, 784)\u001b[0m\n",
      "\u001b[32m2023-11-26 21:23:32.369\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m87\u001b[0m - \u001b[1mSize of batch validation: 395\u001b[0m\n",
      "\u001b[32m2023-11-26 21:23:32.370\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m_run_single_loop\u001b[0m:\u001b[36m88\u001b[0m - \u001b[1mFirst 5 rows of batch validation loss: [607.6260986328125, 631.1261596679688, 539.846923828125, 586.5072021484375, 568.3600463867188]\u001b[0m\n",
      "\u001b[32m2023-11-26 21:23:32.371\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36m__call__\u001b[0m:\u001b[36m163\u001b[0m - \u001b[1mcurrent score -591.7961561758307 is higher than -591.8034766861155, setting new best score to -591.7961561758307\u001b[0m\n",
      "\u001b[32m2023-11-26 21:23:32.372\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36msave_checkpoint\u001b[0m:\u001b[36m171\u001b[0m - \u001b[1mValidation loss decreased (591.803477 --> 591.796156).  Saving model ...\u001b[0m\n",
      "\u001b[32m2023-11-26 21:23:32.385\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.helpers.training\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mEarly stopping is set: loading best model from /Users/ryanstevens/Documents/github/torch_practice/data/models/static/latentDim=256_batchSize=32/checkpoint.pt\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 75\u001b[0m\n\u001b[1;32m     66\u001b[0m early_stopping\u001b[39m=\u001b[39mtraining\u001b[39m.\u001b[39mEarlyStopping(\n\u001b[1;32m     67\u001b[0m     patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, \n\u001b[1;32m     68\u001b[0m     verbose\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, \n\u001b[1;32m     69\u001b[0m     path\u001b[39m=\u001b[39mpath_to_early_stopping_folder\n\u001b[1;32m     70\u001b[0m )\n\u001b[1;32m     72\u001b[0m \u001b[39m# Initialize model training\u001b[39;00m\n\u001b[1;32m     73\u001b[0m model_trainer\u001b[39m=\u001b[39mtraining\u001b[39m.\u001b[39mModelTrainer(\n\u001b[1;32m     74\u001b[0m     model\u001b[39m=\u001b[39mencoder_decoder_model,\n\u001b[0;32m---> 75\u001b[0m     optimizer\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39;49moptim\u001b[39m.\u001b[39;49mAdam(encoder_decoder_model\u001b[39m.\u001b[39;49mparameters(), lr\u001b[39m=\u001b[39;49mLR),\n\u001b[1;32m     76\u001b[0m     loss_fn\u001b[39m=\u001b[39mLOSS_FN,\n\u001b[1;32m     77\u001b[0m     train_loader\u001b[39m=\u001b[39mtrain,\n\u001b[1;32m     78\u001b[0m     val_loader\u001b[39m=\u001b[39mval,\n\u001b[1;32m     79\u001b[0m     epochs\u001b[39m=\u001b[39mEPOCHS,\n\u001b[1;32m     80\u001b[0m     early_stopping\u001b[39m=\u001b[39mearly_stopping,\n\u001b[1;32m     81\u001b[0m     path_to_batch_prediction_folder\u001b[39m=\u001b[39mpath_to_batch_prediction_folder\n\u001b[1;32m     82\u001b[0m )\n\u001b[1;32m     84\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[1;32m     85\u001b[0m model_trainer\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/Documents/github/torch_practice/.venv/lib/python3.10/site-packages/torch/optim/adam.py:45\u001b[0m, in \u001b[0;36mAdam.__init__\u001b[0;34m(self, params, lr, betas, eps, weight_decay, amsgrad, foreach, maximize, capturable, differentiable, fused)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid weight_decay value: \u001b[39m\u001b[39m{\u001b[39;00mweight_decay\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m defaults \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(lr\u001b[39m=\u001b[39mlr, betas\u001b[39m=\u001b[39mbetas, eps\u001b[39m=\u001b[39meps,\n\u001b[1;32m     42\u001b[0m                 weight_decay\u001b[39m=\u001b[39mweight_decay, amsgrad\u001b[39m=\u001b[39mamsgrad,\n\u001b[1;32m     43\u001b[0m                 maximize\u001b[39m=\u001b[39mmaximize, foreach\u001b[39m=\u001b[39mforeach, capturable\u001b[39m=\u001b[39mcapturable,\n\u001b[1;32m     44\u001b[0m                 differentiable\u001b[39m=\u001b[39mdifferentiable, fused\u001b[39m=\u001b[39mfused)\n\u001b[0;32m---> 45\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(params, defaults)\n\u001b[1;32m     47\u001b[0m \u001b[39mif\u001b[39;00m fused:\n\u001b[1;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m differentiable:\n",
      "File \u001b[0;32m~/Documents/github/torch_practice/.venv/lib/python3.10/site-packages/torch/optim/optimizer.py:261\u001b[0m, in \u001b[0;36mOptimizer.__init__\u001b[0;34m(self, params, defaults)\u001b[0m\n\u001b[1;32m    259\u001b[0m param_groups \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(params)\n\u001b[1;32m    260\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(param_groups) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 261\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39moptimizer got an empty parameter list\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    262\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(param_groups[\u001b[39m0\u001b[39m], \u001b[39mdict\u001b[39m):\n\u001b[1;32m    263\u001b[0m     param_groups \u001b[39m=\u001b[39m [{\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m: param_groups}]\n",
      "\u001b[0;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "import sys; sys.path.insert(0, '/Users/ryanstevens/Documents/github/torch_practice/')\n",
    "from src.helpers import data\n",
    "from src.helpers import models, training\n",
    "import torch.nn as nn\n",
    "import numpy as np \n",
    "import torch\n",
    "from importlib import reload\n",
    "from pathlib import Path\n",
    "reload(models)\n",
    "reload(training)\n",
    "reload(data)\n",
    "\n",
    "# Set parameters\n",
    "INPUT_DIM=28**2\n",
    "LOSS_FN=nn.CrossEntropyLoss()\n",
    "EPOCHS=200\n",
    "LR=1e-4\n",
    "\n",
    "losses=[]\n",
    "for batch_size in [\n",
    "    4, \n",
    "    16, \n",
    "    32]:\n",
    "    \n",
    "    # Load dataset \n",
    "    train, val, test = data.load_and_preprocess_data(debug=False, batch_size=batch_size)\n",
    "\n",
    "    # Save the first batch from the validation dataset\n",
    "    path_to_val_batch_prediction_folder = f'/Users/ryanstevens/Documents/github/torch_practice/data/batch_predictions/validation_data/batchSize={batch_size}'\n",
    "    Path(path_to_val_batch_prediction_folder).mkdir(parents=True, exist_ok=True)\n",
    "    first_batch_X_val, first_batch_y_val = next(iter(val))\n",
    "\n",
    "    with open(Path(path_to_val_batch_prediction_folder) / 'y.npy', 'wb') as f:\n",
    "        np.save(f, first_batch_y_val.numpy())\n",
    "    \n",
    "    with open(Path(path_to_val_batch_prediction_folder) / 'X.npy', 'wb') as f:\n",
    "        np.save(f, first_batch_X_val.numpy())\n",
    "\n",
    "    for latent_dim, compression_per_layer in [\n",
    "        # (1, 16), \n",
    "        # (64, 2), \n",
    "        (128, 2),\n",
    "        (256, 2), \n",
    "        (28*28, 2)\n",
    "    ]:\n",
    "        if latent_dim == 1 and batch_size == 16:\n",
    "            continue \n",
    "\n",
    "        # Create path to batch predictions\n",
    "        path_to_batch_prediction_folder = f'/Users/ryanstevens/Documents/github/torch_practice/data/batch_predictions/static/latentDim={latent_dim}_batchSize={batch_size}'\n",
    "        path_to_early_stopping_folder=f'/Users/ryanstevens/Documents/github/torch_practice/data/models/static/latentDim={latent_dim}_batchSize={batch_size}'\n",
    "        Path(path_to_batch_prediction_folder).mkdir(parents=True, exist_ok=True)\n",
    "        Path(path_to_early_stopping_folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Create encoder-decoder\n",
    "        encoder_decoder_model = models.StaticEncoderDecoder(\n",
    "            input_dim=INPUT_DIM,\n",
    "            latent_dim=latent_dim,\n",
    "            head_layer=nn.Sigmoid(),\n",
    "            compression_per_layer=compression_per_layer,\n",
    "        )\n",
    "\n",
    "        # Initialize early stopping\n",
    "        early_stopping=training.EarlyStopping(\n",
    "            patience=5, \n",
    "            verbose=True, \n",
    "            path=path_to_early_stopping_folder\n",
    "        )\n",
    "\n",
    "        # Initialize model training\n",
    "        model_trainer=training.ModelTrainer(\n",
    "            model=encoder_decoder_model,\n",
    "            optimizer=torch.optim.Adam(encoder_decoder_model.parameters(), lr=LR),\n",
    "            loss_fn=LOSS_FN,\n",
    "            train_loader=train,\n",
    "            val_loader=val,\n",
    "            epochs=EPOCHS,\n",
    "            early_stopping=early_stopping,\n",
    "            path_to_batch_prediction_folder=path_to_batch_prediction_folder\n",
    "        )\n",
    "\n",
    "        # Train model\n",
    "        model_trainer.train()\n",
    "\n",
    "        # Persist training and validation losses\n",
    "        losses.append(\n",
    "            {\n",
    "                'train_losses': model_trainer.train_losses,\n",
    "                'val_losses': model_trainer.val_losses,\n",
    "                'test_losses': [LOSS_FN(model_trainer.best_model(X), X) for _, (X, _) in enumerate(test)],\n",
    "                'latent_dim': latent_dim\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%markdown\n",
    "\n",
    "## Analyzing model performance\n",
    "\n",
    "### Model Losses\n",
    "\n",
    "We first explore the relationship between the bottleneck layer and the train, validation, and test losses. We see the general pattern discussed earlier.\n",
    "\n",
    "Also, it's interesting to have a look at some reconstructed images, we persisted images for the validation set across the batches / epochs. Below, we've created a grid of gifs. The columns are the size of the bottleneck layer, the rows are the batch sizes. \n",
    "\n",
    "## Anomaly Detection\n",
    "We can now use this simple autoencoder for anomaly detection. Let's simply plot "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
